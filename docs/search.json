[
  {
    "objectID": "Other/working_with_rmd.html",
    "href": "Other/working_with_rmd.html",
    "title": "Working with R Markdown",
    "section": "",
    "text": "R Markdown (.Rmd) is a file format that allows you to save and execute R code within a document. It combines your code, the output of that code (graphs, tables, values), and your written commentary into a single nice-looking report (HTML, PDF, or Word)."
  },
  {
    "objectID": "Other/working_with_rmd.html#the-yaml-header",
    "href": "Other/working_with_rmd.html#the-yaml-header",
    "title": "Working with R Markdown",
    "section": "1. The YAML Header",
    "text": "1. The YAML Header\nThis is the block of text at the very top of the file, enclosed by three dashes (---). It controls the document‚Äôs settings.\n---\ntitle: \"Homework 1\"\nauthor: \"Your Name\"\ndate: \"2024-01-01\"\noutput: html_document\n---\nWhat you do: Change the author and date to your own."
  },
  {
    "objectID": "Other/working_with_rmd.html#text-markdown",
    "href": "Other/working_with_rmd.html#text-markdown",
    "title": "Working with R Markdown",
    "section": "2. Text (Markdown)",
    "text": "2. Text (Markdown)\nYou can type normal text anywhere in the document (outside of the code chunks). You can use Markdown syntax to format your text:\n\nBold: **text** -&gt; text\nItalic: *text* -&gt; text\nHeaders: # for main titles, ## for section titles."
  },
  {
    "objectID": "Other/working_with_rmd.html#code-chunks",
    "href": "Other/working_with_rmd.html#code-chunks",
    "title": "Working with R Markdown",
    "section": "3. Code Chunks",
    "text": "3. Code Chunks\nThis is where your R code lives. A code chunk looks like this:\n`r ''````{r}\n# This is a comment inside code\nmean(c(1, 2, 3))\n```\n\nInsert a Chunk: You can type it manually or use the shortcut Ctrl + Alt + I (Windows) or Cmd + Option + I (Mac).\nRun a Chunk: Click the green ‚ÄúPlay‚Äù button at the top right of the chunk to run the code and see the output immediately below it."
  },
  {
    "objectID": "Other/aboutDrL.html",
    "href": "Other/aboutDrL.html",
    "title": "About Dr.¬†Joshua Lambert",
    "section": "",
    "text": "Dr.¬†Joshua Lambert holds a Ph.D.¬†in Biostatistics and Epidemiology from the University of Kentucky (2017).\nHe has also earned master‚Äôs degrees in Statistics and Mathematics from University of Kentucky and Murray State University.\nCurrently, Dr.¬†Lambert serves as an Associate Professor at the College of Nursing, University of Cincinnati."
  },
  {
    "objectID": "Other/aboutDrL.html#education-and-academic-positions",
    "href": "Other/aboutDrL.html#education-and-academic-positions",
    "title": "About Dr.¬†Joshua Lambert",
    "section": "",
    "text": "Dr.¬†Joshua Lambert holds a Ph.D.¬†in Biostatistics and Epidemiology from the University of Kentucky (2017).\nHe has also earned master‚Äôs degrees in Statistics and Mathematics from University of Kentucky and Murray State University.\nCurrently, Dr.¬†Lambert serves as an Associate Professor at the College of Nursing, University of Cincinnati."
  },
  {
    "objectID": "Other/aboutDrL.html#research-support-and-grants",
    "href": "Other/aboutDrL.html#research-support-and-grants",
    "title": "About Dr.¬†Joshua Lambert",
    "section": "Research Support and Grants",
    "text": "Research Support and Grants\n\nDr.¬†Lambert‚Äôs research endeavors have been supported by various grants, including prestigious federal and private funding agencies.\nNotably, he serves as Principal Investigator (PI) on projects funded by the National Library of Medicine and Co-Investigator (Co-I) on grants from the National Institute of Diabetes and Digestive and Kidney Diseases, among others.\nHis research spans diverse topics, from identifying clinically protective effects of existing drugs against COVID-19 to exploring outcomes in patients with acute kidney injury.\nMethodologically he works on subset selection for regression models, interaction identification when exhuastive search is not possible, and Pareto Frontier based solutions in Machine Learning and Statistics."
  },
  {
    "objectID": "Other/aboutDrL.html#publications-and-presentations",
    "href": "Other/aboutDrL.html#publications-and-presentations",
    "title": "About Dr.¬†Joshua Lambert",
    "section": "Publications and Presentations",
    "text": "Publications and Presentations\n\nDr.¬†Lambert has authored numerous peer-reviewed publications covering a wide range of topics in healthcare statistics including predictive modeling, opioid exposure, and acute kidney injury.\nHis scholarly work extends beyond publications to include invited presentations at esteemed conferences and institutions and showcasing his expertise and leadership in the field.\nAdditionally, he has contributed technical reports addressing critical public health issues such as drug overdose deaths and suicide attempts in Kentucky.\nResearchGate\nGoogle Scholar\nORCiD"
  },
  {
    "objectID": "Other/aboutDrL.html#teaching-and-academic-engagement",
    "href": "Other/aboutDrL.html#teaching-and-academic-engagement",
    "title": "About Dr.¬†Joshua Lambert",
    "section": "Teaching and Academic Engagement",
    "text": "Teaching and Academic Engagement\n\nIn addition to his research pursuits, Dr.¬†Lambert is actively involved in teaching and mentoring future healthcare professionals.\nHe has held positions as a lecturer in Mathematics and Statistics at various universities, fostering a passion for statistical literacy among students.\nDr.¬†Lambert‚Äôs commitment to education is further evidenced by his presentations on statistical methodologies at academic conferences and workshops.\nDr.¬†Lambert teaches NPHD9040 (Multivariate Analysis) and NPHD9042 (Multivariate Analysis) for the PhD program in the College of Nursing at the University of Cincinnati."
  },
  {
    "objectID": "Other/aboutDrL.html#contact-information",
    "href": "Other/aboutDrL.html#contact-information",
    "title": "About Dr.¬†Joshua Lambert",
    "section": "Contact Information",
    "text": "Contact Information\n\nDr.¬†Joshua Lambert can be reached at his academic office in Procter Hall.\nEmail: joshua.lambert@uc.edu"
  },
  {
    "objectID": "Lectures/preliminaries.html",
    "href": "Lectures/preliminaries.html",
    "title": "Preliminaries",
    "section": "",
    "text": "Download R Code for this Lecture"
  },
  {
    "objectID": "Lectures/preliminaries.html#preliminary-steps-for-data-analysis",
    "href": "Lectures/preliminaries.html#preliminary-steps-for-data-analysis",
    "title": "Preliminaries",
    "section": "Preliminary Steps for Data Analysis",
    "text": "Preliminary Steps for Data Analysis\nBefore conducting statistical analyses in R, it‚Äôs crucial to follow these steps:\n\nDefine Your Research Question and Hypothesis\n\nResearch Question: Start with a clear, concise research question relevant to your primary interest.\nHypothesis: Formulate a testable statement that answers your research question.\n\nNull Hypothesis (H‚ÇÄ): Represents no effect or difference.\nAlternative Hypothesis (H‚Çê): Represents an effect or difference.\n\n\nExample: - Research Question: Does a new pain management intervention reduce pain scores compared to standard care? - H‚ÇÄ: The mean pain score is the same for both groups. - H‚Çê: The mean pain score differs between groups.\n\n\nPick Appropriate Variables and Measures\n\nIdentify key variables relevant to your research question.\nChoose between continuous or categorical variables based on the type of data available.\n\nContinuous Variables: Unlimited set of values (e.g., weight, age, blood pressure).\nCategorical Variables: Limited set of values (e.g., treatment status, diagnosis).\n\nOrdinal: Ordered categories (e.g., pain rating - low, medium, high).\nNominal: Unordered categories (e.g., sex - male, female).\nDichotomous: Only two levels (e.g., yes/no, treatment/control).\n\n\n\n\nüí° R Tip: In R, categorical variables should be stored as factors. Use factor() to convert character variables to factors, especially for ordinal data where you can specify the order.\n\n\n# Convert to factor\npain_level &lt;- factor(c(\"low\", \"medium\", \"high\", \"low\", \"high\"))\n\n# Ordered factor (for ordinal data)\npain_level &lt;- factor(c(\"low\", \"medium\", \"high\", \"low\", \"high\"),\n                     levels = c(\"low\", \"medium\", \"high\"),\n                     ordered = TRUE)\n\n\n\nUnderstand the P-Value: Pros and Cons\n\nThe p-value is a statistical measure that helps assess evidence against the null hypothesis.\nPros:\n\nEasy to interpret.\nHelps determine statistical significance.\n\nCons:\n\nOften misinterpreted (e.g., ‚Äúsignificant‚Äù does not always imply clinical relevance).\nCan be misleading in the presence of small sample sizes.\nDoes not measure effect size or practical importance.\n\n\n\nüí° R Tip: In R, p-values are typically found in the output of statistical tests. Look for columns labeled Pr(&gt;|t|), p-value, or similar. A common threshold is p &lt; 0.05 for statistical significance.\n\n\n\nDetermine Sample Size and Power\n\nSample Size: Ensure that the proposed sample is large enough to answer your research question confidently.\nPower Analysis: Conduct a power analysis to determine the minimum sample size required.\n\nPower: Probability of rejecting a false null hypothesis (typically 0.80 or 80%).\nType I Error (Œ±): Probability of a false positive (usually 0.05).\nType II Error (Œ≤): Probability of a false negative (usually 0.20).\n\nFactors Influencing Power:\n\nEffect size\nSignificance level\nSample size\n\n\n\nPower Analysis in R\nR has the pwr package for power calculations:\n\n# Install the package (only once)\ninstall.packages(\"pwr\")\n\n# Load the package\nlibrary(pwr)\n\n# Example: Power analysis for t-test\n# What sample size do we need to detect a medium effect (d=0.5)\n# with 80% power at alpha=0.05?\npwr.t.test(d = 0.5,           # Effect size (Cohen's d)\n           sig.level = 0.05,   # Alpha\n           power = 0.80,       # Desired power\n           type = \"two.sample\")\n\n# Example: What power do we have with n=30 per group?\npwr.t.test(n = 30,\n           d = 0.5,\n           sig.level = 0.05,\n           type = \"two.sample\")\n\n\nüí° R Tip: Common effect sizes (Cohen‚Äôs d): small = 0.2, medium = 0.5, large = 0.8. The pwr package has functions for many test types: pwr.t.test(), pwr.anova.test(), pwr.chisq.test(), etc.\n\n\n\n\nWorking with Data in R\n\nSetting Up Your Workspace\n\n# Check your current working directory\ngetwd()\n\n# Set working directory to where your data is stored\nsetwd(\"C:/Users/YourName/Documents/NPHD9040\")\n\n# Or use RStudio: Session ‚Üí Set Working Directory ‚Üí Choose Directory\n\n\nüí° R Tip: Keep all files for a project in one folder. This makes it easier to manage your data, scripts, and output.\n\n\n\nReading Data into R\nFor a more detailed guide on importing different file types (including using the RStudio GUI), see the Getting Started with R module.\n\n# Read CSV file\nmy_data &lt;- read.csv(\"patient_data.csv\")\n\n# Select file interactively\n# my_data &lt;- read.csv(file.choose())\n\n# Read CSV with specific options\nmy_data &lt;- read.csv(\"patient_data.csv\",\n                    header = TRUE,        # First row contains column names\n                    stringsAsFactors = FALSE)  # Don't auto-convert to factors\n\n# For Excel files, use readxl package\nlibrary(readxl)\nmy_data &lt;- read_excel(\"patient_data.xlsx\")\n\n# View the data\nView(my_data)  # Opens in spreadsheet viewer\nhead(my_data)  # First 6 rows\ntail(my_data)  # Last 6 rows\n\n\n\n\nTaking Your Data on a Date: Exploratory Data Analysis\n\nCollect Consistent and High-Quality Data:\n\nUse secure electronic records whenever possible (e.g., REDCap).\nConsult the Institutional Review Board (IRB) before beginning data collection.\nTake note of possible biases or skewed observations that may affect results.\n\nTransform and Organize Data:\n\nRaw Data: Direct data collected from your research.\nTidy Data: Organized and transformed version of raw data.\nApply necessary transformations (e.g., standardization) to clean your data.\n\nConduct Exploratory Data Analysis:\n\nSummarize your data using basic descriptive statistics.\nVisualize your data through various graphs (e.g., histograms, box plots).\nIdentify potential differences and insights within or between groups.\n\n\n\nDescriptive Statistics in R\n\n# Summary statistics for all variables\nsummary(my_data)\n\n# Mean, median, standard deviation for a specific variable\nmean(my_data$age)\nmedian(my_data$age)\nsd(my_data$age)\n\n# Remove missing values with na.rm = TRUE\nmean(my_data$age, na.rm = TRUE)\n\n# Frequency table for categorical variables\ntable(my_data$treatment_group)\n\n# Cross-tabulation\ntable(my_data$treatment_group, my_data$outcome_category)\n\n# Proportions\nprop.table(table(my_data$treatment_group))\n\n\nüí° R Tip: Use str(my_data) to see the structure of your data frame. This shows variable names, types, and first few values - very helpful for understanding your data!\n\n\n\nChecking for Missing Data\n\n# Check for missing values\nsum(is.na(my_data))  # Total missing values\n\n# Missing values per variable\ncolSums(is.na(my_data))\n\n# Identify rows with any missing values\nmy_data[!complete.cases(my_data), ]\n\n# Remove rows with missing values (use with caution!)\nmy_data_complete &lt;- na.omit(my_data)"
  },
  {
    "objectID": "Lectures/preliminaries.html#comprehensive-example-complete-exploratory-analysis",
    "href": "Lectures/preliminaries.html#comprehensive-example-complete-exploratory-analysis",
    "title": "Preliminaries",
    "section": "Comprehensive Example: Complete Exploratory Analysis",
    "text": "Comprehensive Example: Complete Exploratory Analysis\nLet‚Äôs walk through a complete exploratory data analysis workflow in R:\n\n# ============================================\n# Exploratory Data Analysis Example\n# Research Question: Do pain scores differ by treatment group?\n# ============================================\n\n# Step 1: Create sample data (normally you'd read from a file)\nset.seed(123)  # For reproducibility\npain_study &lt;- data.frame(\n  patient_id = 1:60,\n  age = round(rnorm(60, mean = 55, sd = 12)),\n  sex = sample(c(\"Male\", \"Female\"), 60, replace = TRUE),\n  treatment = rep(c(\"Standard\", \"Intervention A\", \"Intervention B\"), each = 20),\n  baseline_pain = round(rnorm(60, mean = 7, sd = 1.5), 1),\n  followup_pain = c(\n    round(rnorm(20, mean = 6.5, sd = 1.5), 1),  # Standard\n    round(rnorm(20, mean = 4.5, sd = 1.5), 1),  # Intervention A\n    round(rnorm(20, mean = 3.8, sd = 1.5), 1)   # Intervention B\n  )\n)\n\n# Step 2: Examine the data structure\ncat(\"Data Structure:\\n\")\n\nData Structure:\n\nstr(pain_study)\n\n'data.frame':   60 obs. of  6 variables:\n $ patient_id   : int  1 2 3 4 5 6 7 8 9 10 ...\n $ age          : num  48 52 74 56 57 76 61 40 47 50 ...\n $ sex          : chr  \"Male\" \"Female\" \"Male\" \"Male\" ...\n $ treatment    : chr  \"Standard\" \"Standard\" \"Standard\" \"Standard\" ...\n $ baseline_pain: num  8.5 7.8 7.4 6.1 9 6.1 10.3 9.3 6.6 5.5 ...\n $ followup_pain: num  7.7 7.7 7 5 6.3 6.1 7.3 5.9 8 5.9 ...\n\ncat(\"\\n\\nFirst few rows:\\n\")\n\n\n\nFirst few rows:\n\nhead(pain_study)\n\n  patient_id age    sex treatment baseline_pain followup_pain\n1          1  48   Male  Standard           8.5           7.7\n2          2  52 Female  Standard           7.8           7.7\n3          3  74   Male  Standard           7.4           7.0\n4          4  56   Male  Standard           6.1           5.0\n5          5  57   Male  Standard           9.0           6.3\n6          6  76 Female  Standard           6.1           6.1\n\n# Step 3: Check for missing data\ncat(\"\\n\\nMissing values per variable:\\n\")\n\n\n\nMissing values per variable:\n\ncolSums(is.na(pain_study))\n\n   patient_id           age           sex     treatment baseline_pain \n            0             0             0             0             0 \nfollowup_pain \n            0 \n\n# Step 4: Convert categorical variables to factors\npain_study$sex &lt;- factor(pain_study$sex)\npain_study$treatment &lt;- factor(pain_study$treatment)\n\n# Step 5: Descriptive statistics - Overall\ncat(\"\\n\\nOverall Summary Statistics:\\n\")\n\n\n\nOverall Summary Statistics:\n\nsummary(pain_study)\n\n   patient_id         age            sex              treatment \n Min.   : 1.00   Min.   :31.00   Female:33   Intervention A:20  \n 1st Qu.:15.75   1st Qu.:48.75   Male  :27   Intervention B:20  \n Median :30.50   Median :55.50               Standard      :20  \n Mean   :30.50   Mean   :55.73                                  \n 3rd Qu.:45.25   3rd Qu.:63.00                                  \n Max.   :60.00   Max.   :81.00                                  \n baseline_pain    followup_pain   \n Min.   : 3.900   Min.   : 1.800  \n 1st Qu.: 5.675   1st Qu.: 3.625  \n Median : 6.600   Median : 4.650  \n Mean   : 6.797   Mean   : 5.063  \n 3rd Qu.: 7.800   3rd Qu.: 6.325  \n Max.   :10.300   Max.   :11.400  \n\n# Step 6: Descriptive statistics by group\ncat(\"\\n\\nMean Follow-up Pain by Treatment:\\n\")\n\n\n\nMean Follow-up Pain by Treatment:\n\ntapply(pain_study$followup_pain, pain_study$treatment, mean)\n\nIntervention A Intervention B       Standard \n          4.54           3.83           6.82 \n\ncat(\"\\n\\nSD of Follow-up Pain by Treatment:\\n\")\n\n\n\nSD of Follow-up Pain by Treatment:\n\ntapply(pain_study$followup_pain, pain_study$treatment, sd)\n\nIntervention A Intervention B       Standard \n      1.220181       1.598387       1.502489 \n\n# Step 7: Create pain reduction variable\npain_study$pain_reduction &lt;- pain_study$baseline_pain - pain_study$followup_pain\n\ncat(\"\\n\\nMean Pain Reduction by Treatment:\\n\")\n\n\n\nMean Pain Reduction by Treatment:\n\ntapply(pain_study$pain_reduction, pain_study$treatment, mean)\n\nIntervention A Intervention B       Standard \n         2.145          2.845          0.210 \n\n# Step 8: Frequency tables\ncat(\"\\n\\nSample Size by Treatment:\\n\")\n\n\n\nSample Size by Treatment:\n\ntable(pain_study$treatment)\n\n\nIntervention A Intervention B       Standard \n            20             20             20 \n\ncat(\"\\n\\nSample Size by Treatment and Sex:\\n\")\n\n\n\nSample Size by Treatment and Sex:\n\ntable(pain_study$treatment, pain_study$sex)\n\n                \n                 Female Male\n  Intervention A     10   10\n  Intervention B     12    8\n  Standard           11    9\n\n# Step 9: Visualize the data\npar(mfrow = c(2, 2))  # 2x2 grid of plots\n\n# Histogram of age\nhist(pain_study$age, \n     main = \"Distribution of Age\",\n     xlab = \"Age (years)\",\n     col = \"lightblue\",\n     border = \"white\")\n\n# Boxplot of follow-up pain by treatment\nboxplot(followup_pain ~ treatment,\n        data = pain_study,\n        main = \"Follow-up Pain by Treatment\",\n        xlab = \"Treatment Group\",\n        ylab = \"Pain Score\",\n        col = c(\"lightcoral\", \"lightgreen\", \"lightblue\"))\n\n# Boxplot of pain reduction by treatment\nboxplot(pain_reduction ~ treatment,\n        data = pain_study,\n        main = \"Pain Reduction by Treatment\",\n        xlab = \"Treatment Group\",\n        ylab = \"Pain Reduction\",\n        col = c(\"lightcoral\", \"lightgreen\", \"lightblue\"))\n\n# Scatter plot of baseline vs follow-up pain\nplot(pain_study$baseline_pain, pain_study$followup_pain,\n     main = \"Baseline vs Follow-up Pain\",\n     xlab = \"Baseline Pain\",\n     ylab = \"Follow-up Pain\",\n     pch = 19,\n     col = as.numeric(pain_study$treatment))\nlegend(\"topright\", \n       legend = levels(pain_study$treatment),\n       col = 1:3,\n       pch = 19)\n\n\n\n\n\n\n\n# Reset plot layout\npar(mfrow = c(1, 1))\n\n# Step 10: Check assumptions visually\n# Normality of pain reduction\ncat(\"\\n\\nShapiro-Wilk Test for Normality (Pain Reduction):\\n\")\n\n\n\nShapiro-Wilk Test for Normality (Pain Reduction):\n\nshapiro.test(pain_study$pain_reduction)\n\n\n    Shapiro-Wilk normality test\n\ndata:  pain_study$pain_reduction\nW = 0.99173, p-value = 0.9575\n\n# Q-Q plot for normality\nqqnorm(pain_study$pain_reduction)\nqqline(pain_study$pain_reduction, col = \"red\")\n\n\n\n\n\n\n\n# Step 11: Save cleaned data (optional)\n# write.csv(pain_study, \"pain_study_cleaned.csv\", row.names = FALSE)\n\ncat(\"\\n\\n=== Exploratory Analysis Complete ===\\n\")\n\n\n\n=== Exploratory Analysis Complete ===\n\ncat(\"Next steps: Proceed with formal statistical testing in the [Introduction to ANOVA](introduction-to-anova.qmd) lecture.\\n\")\n\nNext steps: Proceed with formal statistical testing in the [Introduction to ANOVA](introduction-to-anova.qmd) lecture."
  },
  {
    "objectID": "Lectures/preliminaries.html#key-takeaways",
    "href": "Lectures/preliminaries.html#key-takeaways",
    "title": "Preliminaries",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n‚úÖ Always start with a clear research question and hypothesis\n‚úÖ Understand your variables and their measurement scales\n‚úÖ Conduct power analysis before data collection\n‚úÖ Explore your data thoroughly before formal testing\n‚úÖ Check for missing data and outliers\n‚úÖ Visualize your data to understand distributions and relationships\n‚úÖ Document your process in R scripts for reproducibility\n\nüí° R Tip: Save your R code in a script file (.R) as you work. This creates a complete record of your analysis that you can run again later or share with colleagues. Use comments (#) liberally to explain what each section does!"
  },
  {
    "objectID": "Lectures/preliminaries.html#conclusion",
    "href": "Lectures/preliminaries.html#conclusion",
    "title": "Preliminaries",
    "section": "Conclusion",
    "text": "Conclusion\nFollowing these preliminary steps will ensure a solid foundation for statistical analysis. Carefully consider each step, from hypothesis formulation to data collection and exploration. Being thorough in the preliminaries will enhance the validity and reliability of your findings.\nRemember: R makes your analysis reproducible. Every step is documented in code, which means you (or others) can verify and replicate your work!"
  },
  {
    "objectID": "Lectures/introduction-to-simple-linear-regression.html",
    "href": "Lectures/introduction-to-simple-linear-regression.html",
    "title": "Introduction to Simple Linear Regression",
    "section": "",
    "text": "Download R Code for this Lecture"
  },
  {
    "objectID": "Lectures/introduction-to-simple-linear-regression.html#objectives",
    "href": "Lectures/introduction-to-simple-linear-regression.html#objectives",
    "title": "Introduction to Simple Linear Regression",
    "section": "Objectives",
    "text": "Objectives\n\nUnderstand the fundamentals of Simple Linear Regression\nLearn the definition and purpose of Simple Linear Regression\nIdentify key concepts and assumptions of Simple Linear Regression\nVisualize the relationship between variables\nCalculate and interpret correlation coefficients\nFormulate the regression equation\nEstimate the regression coefficients\nTest the significance of the regression coefficients\nCalculate confidence intervals for the coefficients\nUnderstand the coefficient of determination (R-squared)\nPerform residual analysis and diagnostic plots\nInterpret regression coefficients\nCheck assumptions\nExplore examples of Simple Linear Regression in nursing research"
  },
  {
    "objectID": "Lectures/introduction-to-simple-linear-regression.html#definition-and-purpose-of-simple-linear-regression",
    "href": "Lectures/introduction-to-simple-linear-regression.html#definition-and-purpose-of-simple-linear-regression",
    "title": "Introduction to Simple Linear Regression",
    "section": "Definition and Purpose of Simple Linear Regression",
    "text": "Definition and Purpose of Simple Linear Regression\nSimple Linear Regression is a statistical method used to model the relationship between a single independent variable (predictor) and a continuous dependent variable (outcome). It aims to predict the dependent variable based on the values of the independent variable.\n\nKey Concepts and Assumptions of Simple Linear Regression\n\nLinearity: The relationship between the predictor and outcome is linear.\nIndependence: Observations are independent.\nHomoscedasticity: The variance of residuals is constant.\nNormality: Residuals are normally distributed."
  },
  {
    "objectID": "Lectures/introduction-to-simple-linear-regression.html#visualizing-the-relationship-between-variables",
    "href": "Lectures/introduction-to-simple-linear-regression.html#visualizing-the-relationship-between-variables",
    "title": "Introduction to Simple Linear Regression",
    "section": "Visualizing the Relationship Between Variables",
    "text": "Visualizing the Relationship Between Variables\nUse scatter plots to visualize the relationship between the predictor and outcome variables. For more on creating these visualizations in R, see the Graphing Your Data lecture.\n\nExample Visualization in R\n\n# Scatter plot in R\nset.seed(123)\nx &lt;- rnorm(100)\ny &lt;- 3 * x + rnorm(100)\n\nplot(x, y, main = \"Scatter Plot of Predictor vs. Outcome\", xlab = \"Predictor (x)\", ylab = \"Outcome (y)\", col = \"blue\")"
  },
  {
    "objectID": "Lectures/introduction-to-simple-linear-regression.html#calculating-and-interpreting-correlation-coefficients",
    "href": "Lectures/introduction-to-simple-linear-regression.html#calculating-and-interpreting-correlation-coefficients",
    "title": "Introduction to Simple Linear Regression",
    "section": "Calculating and Interpreting Correlation Coefficients",
    "text": "Calculating and Interpreting Correlation Coefficients\n\nPearson Correlation Coefficient (( r ))\nMeasures the strength and direction of the linear relationship between two continuous variables.\n\n\nFormula\n\\[\nr = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum (x_i - \\bar{x})^2 \\sum (y_i - \\bar{y})^2}}\n\\]\n\n\nInterpretation\n\n( r = +1 ): Perfect positive correlation\n( r = -1 ): Perfect negative correlation\n( r = 0 ): No correlation"
  },
  {
    "objectID": "Lectures/introduction-to-simple-linear-regression.html#formulating-the-regression-equation",
    "href": "Lectures/introduction-to-simple-linear-regression.html#formulating-the-regression-equation",
    "title": "Introduction to Simple Linear Regression",
    "section": "Formulating the Regression Equation",
    "text": "Formulating the Regression Equation\nThe regression equation represents the linear relationship between the predictor (( x )) and outcome (( y )).\n\nEquation\n\\[\ny = \\beta_0 + \\beta_1 x\n\\] where: - ( _0 ): Intercept (constant) - ( _1 ): Slope (coefficient)"
  },
  {
    "objectID": "Lectures/introduction-to-simple-linear-regression.html#estimating-the-regression-coefficients",
    "href": "Lectures/introduction-to-simple-linear-regression.html#estimating-the-regression-coefficients",
    "title": "Introduction to Simple Linear Regression",
    "section": "Estimating the Regression Coefficients",
    "text": "Estimating the Regression Coefficients\nThe coefficients are estimated using the method of least squares, which minimizes the sum of squared residuals.\n\nFormula\n\nSlope (Coefficient): \\[\n\\beta_1 = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum (x_i - \\bar{x})^2}\n\\]\nIntercept (Constant): \\[\n\\beta_0 = \\bar{y} - \\beta_1 \\bar{x}\n\\]"
  },
  {
    "objectID": "Lectures/introduction-to-simple-linear-regression.html#testing-the-significance-of-the-regression-coefficients",
    "href": "Lectures/introduction-to-simple-linear-regression.html#testing-the-significance-of-the-regression-coefficients",
    "title": "Introduction to Simple Linear Regression",
    "section": "Testing the Significance of the Regression Coefficients",
    "text": "Testing the Significance of the Regression Coefficients\n\nHypothesis Testing\n\nNull Hypothesis (( H_0 )): The coefficient is not significantly different from zero (( _1 = 0 )).\nAlternative Hypothesis (( H_1 )): The coefficient is significantly different from zero (( _1 )).\n\n\n\nt-Test\nThe significance of the coefficients is tested using a t-test.\n\n\nFormula\n\\[\nt = \\frac{\\hat{\\beta}}{SE(\\hat{\\beta})}\n\\] where: - ( ): Estimated coefficient - ( SE() ): Standard error of the coefficient"
  },
  {
    "objectID": "Lectures/introduction-to-simple-linear-regression.html#confidence-intervals-for-the-coefficients",
    "href": "Lectures/introduction-to-simple-linear-regression.html#confidence-intervals-for-the-coefficients",
    "title": "Introduction to Simple Linear Regression",
    "section": "Confidence Intervals for the Coefficients",
    "text": "Confidence Intervals for the Coefficients\nA confidence interval provides a range within which the true coefficient is likely to fall.\n\nFormula\n\\[\n\\hat{\\beta} \\pm t^* \\cdot SE(\\hat{\\beta})\n\\] where: - ( t^* ): Critical value from the t-distribution"
  },
  {
    "objectID": "Lectures/introduction-to-simple-linear-regression.html#coefficient-of-determination-r-squared",
    "href": "Lectures/introduction-to-simple-linear-regression.html#coefficient-of-determination-r-squared",
    "title": "Introduction to Simple Linear Regression",
    "section": "Coefficient of Determination (R-squared)",
    "text": "Coefficient of Determination (R-squared)\nMeasures the proportion of the variance in the outcome variable explained by the predictor.\n\nFormula\n\\[\nR^2 = \\frac{\\sum (\\hat{y} - \\bar{y})^2}{\\sum (y_i - \\bar{y})^2}\n\\]"
  },
  {
    "objectID": "Lectures/introduction-to-simple-linear-regression.html#residual-analysis-and-diagnostic-plots",
    "href": "Lectures/introduction-to-simple-linear-regression.html#residual-analysis-and-diagnostic-plots",
    "title": "Introduction to Simple Linear Regression",
    "section": "Residual Analysis and Diagnostic Plots",
    "text": "Residual Analysis and Diagnostic Plots\n\nResidual Plots\nPlot residuals against the predicted values to check for homoscedasticity and non-linearity.\n\n\nQ-Q Plot\nCheck the normality of residuals by plotting them against a normal distribution.\n\n\nExample in R\n\n# Residual plots and Q-Q plot in R\nfit &lt;- lm(y ~ x)\n\n# Residual vs. Fitted plot\nplot(fit, which = 1, main = \"Residuals vs. Fitted\")\n\n# Q-Q plot\nplot(fit, which = 2, main = \"Q-Q Plot\")"
  },
  {
    "objectID": "Lectures/introduction-to-simple-linear-regression.html#interpretation-of-regression-coefficients",
    "href": "Lectures/introduction-to-simple-linear-regression.html#interpretation-of-regression-coefficients",
    "title": "Introduction to Simple Linear Regression",
    "section": "Interpretation of Regression Coefficients",
    "text": "Interpretation of Regression Coefficients\n\n**Intercept (( _0 )):** The expected value of the outcome when the predictor is zero.\n**Slope (( _1 )):** The expected change in the outcome for a one-unit increase in the predictor."
  },
  {
    "objectID": "Lectures/introduction-to-simple-linear-regression.html#checking-assumptions",
    "href": "Lectures/introduction-to-simple-linear-regression.html#checking-assumptions",
    "title": "Introduction to Simple Linear Regression",
    "section": "Checking Assumptions",
    "text": "Checking Assumptions\n\nLinearity: Residual vs.¬†Fitted plot should show a random pattern.\nIndependence: Observations should be independent.\nHomoscedasticity: Residual vs.¬†Fitted plot should show constant variance.\nNormality: Q-Q plot should show residuals roughly following a straight line."
  },
  {
    "objectID": "Lectures/introduction-to-simple-linear-regression.html#examples-of-simple-linear-regression-in-nursing-research",
    "href": "Lectures/introduction-to-simple-linear-regression.html#examples-of-simple-linear-regression-in-nursing-research",
    "title": "Introduction to Simple Linear Regression",
    "section": "Examples of Simple Linear Regression in Nursing Research",
    "text": "Examples of Simple Linear Regression in Nursing Research\n\nExample 1: Evaluating the Relationship Between BMI and Blood Pressure\n\nResearch Question: How does BMI affect blood pressure in adults?\nPredictor (x): BMI\nOutcome (y): Blood Pressure\n\ndownload example data (CSV)\n\n# Example in R\n# Simulated data\nset.seed(123)\nBMI &lt;- rnorm(100, mean = 25, sd = 3)\nBP &lt;- 2 * BMI + rnorm(100, sd = 5)\n\n# Simple Linear Regression\nfit1 &lt;- lm(BP ~ BMI)\nsummary(fit1)\n\n# Plot\nplot(BMI, BP, main = \"BMI vs. Blood Pressure\", xlab = \"BMI\", ylab = \"Blood Pressure\")\nabline(fit1, col = \"red\")"
  },
  {
    "objectID": "Lectures/introduction-to-multiple-linear-regression.html",
    "href": "Lectures/introduction-to-multiple-linear-regression.html",
    "title": "Introduction to Multiple Linear Regression",
    "section": "",
    "text": "Download R Code for this Lecture"
  },
  {
    "objectID": "Lectures/introduction-to-multiple-linear-regression.html#objectives",
    "href": "Lectures/introduction-to-multiple-linear-regression.html#objectives",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Objectives",
    "text": "Objectives\n\nUnderstand the fundamentals of Multiple Linear Regression\nLearn the definition and purpose of Multiple Linear Regression\nIdentify key concepts and assumptions\nFormulate the regression equation\nEstimate the regression coefficients\nTest the significance of the regression coefficients\nCalculate confidence intervals for the coefficients\nUnderstand the coefficient of determination (R-squared)\nAdjust R-squared and interpret the F-statistic\nInterpret the regression results\nIdentify and handle multicollinearity\nExplore variable selection techniques\nCheck assumptions and perform diagnostics\nExplore examples of Multiple Linear Regression in nursing research"
  },
  {
    "objectID": "Lectures/introduction-to-multiple-linear-regression.html#definition-and-purpose-of-multiple-linear-regression",
    "href": "Lectures/introduction-to-multiple-linear-regression.html#definition-and-purpose-of-multiple-linear-regression",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Definition and Purpose of Multiple Linear Regression",
    "text": "Definition and Purpose of Multiple Linear Regression\nMultiple Linear Regression (MLR) is a statistical technique that models the relationship between two or more independent variables (predictors) and a continuous dependent variable (outcome). It is used to predict the outcome variable based on the values of the independent variables and to understand the impact of each predictor on the outcome.\n\nKey Concepts and Assumptions\n\nLinearity: The relationship between the predictors and the outcome is linear.\nIndependence: Observations are independent of each other.\nHomoscedasticity: The variance of residuals (errors) is constant across all levels of the independent variables.\nNo multicollinearity: Independent variables are not too highly correlated.\nNormality: Residuals should be normally distributed."
  },
  {
    "objectID": "Lectures/introduction-to-multiple-linear-regression.html#formulating-the-regression-equation",
    "href": "Lectures/introduction-to-multiple-linear-regression.html#formulating-the-regression-equation",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Formulating the Regression Equation",
    "text": "Formulating the Regression Equation\nThe multiple linear regression equation is expressed as: \\[\ny = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\dots + \\beta_nx_n + \\epsilon\n\\] where: - ( y ): Dependent variable - ( _0 ): Y-intercept - ( _1, _2, , _n ): Coefficients of predictors ( x_1, x_2, , x_n ) - ( ): Random error"
  },
  {
    "objectID": "Lectures/introduction-to-multiple-linear-regression.html#estimating-the-regression-coefficients",
    "href": "Lectures/introduction-to-multiple-linear-regression.html#estimating-the-regression-coefficients",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Estimating the Regression Coefficients",
    "text": "Estimating the Regression Coefficients\nRegression coefficients are estimated using the method of least squares, which minimizes the sum of the squared differences between observed and predicted values.\n\nFormula\n\nCoefficient (( )): \\[\n\\beta = (X^TX)^{-1}X^Ty\n\\]"
  },
  {
    "objectID": "Lectures/introduction-to-multiple-linear-regression.html#testing-the-significance-of-the-regression-coefficients",
    "href": "Lectures/introduction-to-multiple-linear-regression.html#testing-the-significance-of-the-regression-coefficients",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Testing the Significance of the Regression Coefficients",
    "text": "Testing the Significance of the Regression Coefficients\nStatistical tests (typically t-tests) are used to determine whether each coefficient significantly differs from zero, indicating a significant relationship between the predictor and the outcome.\n\nFormula\n\\[\nt = \\frac{\\hat{\\beta}}{SE(\\hat{\\beta})}\n\\]"
  },
  {
    "objectID": "Lectures/introduction-to-multiple-linear-regression.html#confidence-intervals-for-the-coefficients",
    "href": "Lectures/introduction-to-multiple-linear-regression.html#confidence-intervals-for-the-coefficients",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Confidence Intervals for the Coefficients",
    "text": "Confidence Intervals for the Coefficients\nConfidence intervals provide a range of values which are likely to contain the population coefficients.\n\nFormula\n\\[\n\\hat{\\beta} \\pm t^* \\cdot SE(\\hat{\\beta})\n\\]"
  },
  {
    "objectID": "Lectures/introduction-to-multiple-linear-regression.html#coefficient-of-determination-r-squared",
    "href": "Lectures/introduction-to-multiple-linear-regression.html#coefficient-of-determination-r-squared",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Coefficient of Determination (R-squared)",
    "text": "Coefficient of Determination (R-squared)\nR-squared measures the proportion of the variance in the dependent variable that is predictable from the independent variables.\n\nFormula\n\\[\nR^2 = \\frac{\\sum (\\hat{y} - \\bar{y})^2}{\\sum (y_i - \\bar{y})^2}\n\\]"
  },
  {
    "objectID": "Lectures/introduction-to-multiple-linear-regression.html#adjusted-r-squared-and-f-statistic",
    "href": "Lectures/introduction-to-multiple-linear-regression.html#adjusted-r-squared-and-f-statistic",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Adjusted R-squared and F-statistic",
    "text": "Adjusted R-squared and F-statistic\n\nAdjusted R-squared: Adjusts the R-squared value based on the number of predictors and the sample size to penalize excessive use of predictors. \\[\n\\bar{R}^2 = 1 - \\frac{(1 - R^2)(n - 1)}{n - k - 1}\n\\] where:\n( n ): Sample size\n( k ): Number of predictors\nF-statistic: Tests whether at least one predictor variable has a non-zero coefficient. \\[\nF = \\frac{\\frac{SSR}{k}}{\\frac{SSE}{n - k - 1}}\n\\]"
  },
  {
    "objectID": "Lectures/introduction-to-multiple-linear-regression.html#interpreting-the-regression-results",
    "href": "Lectures/introduction-to-multiple-linear-regression.html#interpreting-the-regression-results",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Interpreting the Regression Results",
    "text": "Interpreting the Regression Results\nThe coefficients tell you the expected change in the dependent variable for one unit of change in the predictor variable, holding all other predictors constant."
  },
  {
    "objectID": "Lectures/introduction-to-multiple-linear-regression.html#identifying-and-handling-multicollinearity",
    "href": "Lectures/introduction-to-multiple-linear-regression.html#identifying-and-handling-multicollinearity",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Identifying and Handling Multicollinearity",
    "text": "Identifying and Handling Multicollinearity\n\nVariance Inflation Factor (VIF)\nMeasures how much the variance of a regression coefficient is inflated due to multicollinearity.\n\n\nFormula\n\\[\nVIF = \\frac{1}{1 - R_j^2}\n\\] where ( R_j^2 ) is the R-squared value obtained by regressing the predictor ( j ) on all other predictors.\n\n\nHandling Multicollinearity\n\nRemove highly correlated predictors\nCombine correlated predictors using techniques like PCA\nRegularization methods (e.g., Ridge Regression)"
  },
  {
    "objectID": "Lectures/introduction-to-multiple-linear-regression.html#variable-selection-techniques",
    "href": "Lectures/introduction-to-multiple-linear-regression.html#variable-selection-techniques",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Variable Selection Techniques",
    "text": "Variable Selection Techniques\n\nStepwise Regression\nA method to select significant predictors by iteratively adding or removing variables based on their statistical significance."
  },
  {
    "objectID": "Lectures/introduction-to-multiple-linear-regression.html#checking-assumptions-and-diagnostics",
    "href": "Lectures/introduction-to-multiple-linear-regression.html#checking-assumptions-and-diagnostics",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Checking Assumptions and Diagnostics",
    "text": "Checking Assumptions and Diagnostics\n\nResidual Analysis\n\nResidual vs.¬†Fitted Plot: Checks for homoscedasticity and linearity.\nNormal Q-Q Plot: Checks for normality of residuals.\nResidual vs.¬†Leverage Plot: Identifies influential observations.\n\n\n\nInfluence Measures\n\nCook‚Äôs Distance: Identifies influential data points that affect the regression model."
  },
  {
    "objectID": "Lectures/introduction-to-multiple-linear-regression.html#examples-of-multiple-linear-regression-in-nursing-research",
    "href": "Lectures/introduction-to-multiple-linear-regression.html#examples-of-multiple-linear-regression-in-nursing-research",
    "title": "Introduction to Multiple Linear Regression",
    "section": "Examples of Multiple Linear Regression in Nursing Research",
    "text": "Examples of Multiple Linear Regression in Nursing Research\n\nExample 1: Impact of Various Factors on Patient Recovery Time\n\nPredictors: Age, Medication adherence, Physiotherapy sessions\nOutcome: Recovery time\n\ndownload example data (CSV)\n\n# Example in R\n# Simulated data\nset.seed(456)\ndata &lt;- data.frame(\n  Age = rnorm(100, mean = 50, sd = 10),\n  Medication_Adherence = rnorm(100, mean = 75, sd = 10),\n  Physiotherapy_Sessions = rnorm(100, mean = 20, sd = 5),\n  Recovery_Time = rnorm(100, mean = 30, sd = 5)\n)\n\n# Multiple Linear Regression\nfit &lt;- lm(Recovery_Time ~ Age + Medication_Adherence + Physiotherapy_Sessions, data = data)\nsummary(fit)\n\n# Residual Plots\npar(mfrow = c(2, 2))\nplot(fit)\n\n\n\nExample 2: Evaluating the Effects of Lifestyle Factors on Heart Health\n\nPredictors: Exercise frequency, Diet quality, Sleep duration\nOutcome: Heart Health Index\n\ndownload example data (CSV)\n\n# Example in R\n# Simulated data\nset.seed(789)\ndata2 &lt;- data.frame(\n  Exercise_Frequency = rnorm(100, mean = 3, sd = 1),\n  Diet_Quality = rnorm(100, mean = 7, sd = 2),\n  Sleep_Duration = rnorm(100, mean = 8, sd = 1),\n  Heart_Health_Index = rnorm(100, mean = 75, sd = 10)\n)\n\n# Multiple Linear Regression\nfit2 &lt;- lm(Heart_Health_Index ~ Exercise_Frequency + Diet_Quality + Sleep_Duration, data = data2)\nsummary(fit2)\n\n# Residual Plots\npar(mfrow = c(2, 2))\nplot(fit2)"
  },
  {
    "objectID": "Lectures/introduction-to-anova.html",
    "href": "Lectures/introduction-to-anova.html",
    "title": "Introduction to ANOVA",
    "section": "",
    "text": "Download R Code for this Lecture"
  },
  {
    "objectID": "Lectures/introduction-to-anova.html#constructing-a-written-and-mathematical-hypothesis",
    "href": "Lectures/introduction-to-anova.html#constructing-a-written-and-mathematical-hypothesis",
    "title": "Introduction to ANOVA",
    "section": "Constructing a Written and Mathematical Hypothesis",
    "text": "Constructing a Written and Mathematical Hypothesis\nWhen constructing a hypothesis for ANOVA, it‚Äôs important to formulate it both in a written and mathematical format.\n\nWritten Hypothesis (Example 1):\n\nNull Hypothesis (H‚ÇÄ): The average stress in cardiac patients is not different between a placebo group and a behavioral intervention group.\nAlternative Hypothesis (H‚ÇÅ): The average stress in cardiac patients differs between the placebo and behavioral intervention groups.\n\nMathematical Hypothesis (Example 1): \\[ H_{0}: \\mu_{placebo} = \\mu_{behavior}\\]\n\n\\[H_{1}: \\mu_{placebo} \\neq \\mu_{behavior}\\]\n\nüí° R Tip: In R, we test these hypotheses using the aov() function (analysis of variance). The formula notation outcome ~ group means ‚Äúoutcome explained by group‚Äù."
  },
  {
    "objectID": "Lectures/introduction-to-anova.html#t-test-vs.-anova",
    "href": "Lectures/introduction-to-anova.html#t-test-vs.-anova",
    "title": "Introduction to ANOVA",
    "section": "T-test vs.¬†ANOVA",
    "text": "T-test vs.¬†ANOVA\nWhen comparing means between two groups, the t-test and ANOVA will yield the same results. However, ANOVA extends to cases with more than two groups.\n\nüí° R Tip: For two groups, you can use either t.test() or aov() in R. For three or more groups, you must use ANOVA."
  },
  {
    "objectID": "Lectures/introduction-to-anova.html#writing-anova-hypothesis-type-1-and-2-errors",
    "href": "Lectures/introduction-to-anova.html#writing-anova-hypothesis-type-1-and-2-errors",
    "title": "Introduction to ANOVA",
    "section": "Writing ANOVA Hypothesis, Type 1 and 2 Errors",
    "text": "Writing ANOVA Hypothesis, Type 1 and 2 Errors\nIn ANOVA, the hypotheses are:\n\nNull Hypothesis (H‚ÇÄ): All group means are equal.\nAlternative Hypothesis (H‚ÇÅ): At least one group mean is different.\n\nType 1 Error: Rejecting the null hypothesis when it is true (false positive).\nType 2 Error: Failing to reject the null hypothesis when it is false (false negative)."
  },
  {
    "objectID": "Lectures/introduction-to-anova.html#assumptions-of-anova",
    "href": "Lectures/introduction-to-anova.html#assumptions-of-anova",
    "title": "Introduction to ANOVA",
    "section": "Assumptions of ANOVA",
    "text": "Assumptions of ANOVA\n\nThe dependent variable is measured on an interval or ratio scale.\nThe independent variable is categorical.\nRandom sampling.\nNormality of Errors\n\nThe population errors should be normally distributed. We check this by looking at a histogram or Q-Q plot of the model residuals.\n\nHomogeneity of population variance.\n\n\nüí° R Tip: You can check ANOVA assumptions in R (for more detail on assumption checking, see the Preliminaries lecture): - Normality: shapiro.test() on residuals or Q-Q plot - Homogeneity of variance: leveneTest() from the car package - Visual checks: Residual plots using plot(model)"
  },
  {
    "objectID": "Lectures/introduction-to-anova.html#visualizing-using-boxplots",
    "href": "Lectures/introduction-to-anova.html#visualizing-using-boxplots",
    "title": "Introduction to ANOVA",
    "section": "Visualizing Using Boxplots",
    "text": "Visualizing Using Boxplots\nBoxplots are essential for visualizing data distribution across groups in ANOVA.\n\n# Example boxplot in R\ndata &lt;- data.frame(\n    group = rep(c(\"Placebo\", \"Behavioral\", \"Drug\"), each = 10),\n    stress = c(rnorm(10, 5, 1), rnorm(10, 7, 1), rnorm(10, 6, 1))\n)\n\n# Basic boxplot\nboxplot(stress ~ group,\n    data = data,\n    main = \"Boxplot of Stress Scores\",\n    xlab = \"Group\",\n    ylab = \"Stress Score\",\n    col = c(\"lightblue\", \"lightgreen\", \"lightcoral\")\n)\n\n# Add individual points\nstripchart(stress ~ group,\n    data = data,\n    vertical = TRUE,\n    method = \"jitter\",\n    add = TRUE,\n    pch = 19,\n    col = \"darkgray\"\n)\n\n\nüí° R Tip: The formula stress ~ group means ‚Äústress by group‚Äù. The ~ symbol separates the dependent variable (left) from the independent variable (right)."
  },
  {
    "objectID": "Lectures/introduction-to-anova.html#calculating-variation-and-degrees-of-freedom",
    "href": "Lectures/introduction-to-anova.html#calculating-variation-and-degrees-of-freedom",
    "title": "Introduction to ANOVA",
    "section": "Calculating Variation and Degrees of Freedom",
    "text": "Calculating Variation and Degrees of Freedom\n\nSum of Squares Between (SSB): Variation between groups.\nSum of Squares Within (SSW): Variation within groups.\nTotal Sum of Squares (SST): Total variation.\n\n\nDegrees of Freedom:\n\n\\[df_{between} = k - 1\\] (where k is the number of groups)\n\\[df_{within} = N - k\\] (where N is the total sample size)"
  },
  {
    "objectID": "Lectures/introduction-to-anova.html#the-f-statistic-and-p-value",
    "href": "Lectures/introduction-to-anova.html#the-f-statistic-and-p-value",
    "title": "Introduction to ANOVA",
    "section": "The F Statistic and P-Value",
    "text": "The F Statistic and P-Value\nThe F statistic is calculated using the ratio of mean squares:\n\\[\nF = \\frac{MSB}{MSW}\n\\]\n\nMSB: Mean Square Between\nMSW: Mean Square Within\n\nThe p-value is derived from the F distribution, given the degrees of freedom.\nThe F-distribution is a continuous probability distribution that arises frequently as the null distribution of test statistics, particularly in analysis of variance (ANOVA). It is characterized by two parameters: the degrees of freedom of the numerator (df_between) and the degrees of freedom of the denominator (df_within)."
  },
  {
    "objectID": "Lectures/introduction-to-anova.html#conducting-anova-in-r",
    "href": "Lectures/introduction-to-anova.html#conducting-anova-in-r",
    "title": "Introduction to ANOVA",
    "section": "Conducting ANOVA in R",
    "text": "Conducting ANOVA in R\n\nBasic ANOVA\n\n# Fit ANOVA model\nmodel &lt;- aov(stress ~ group, data = data)\n\n# View results\nsummary(model)\n\n# The output shows:\n# - Df: Degrees of freedom\n# - Sum Sq: Sum of squares\n# - Mean Sq: Mean squares\n# - F value: F statistic\n# - Pr(&gt;F): P-value\n\n\nüí° R Tip: The summary() function on an aov object gives you the ANOVA table. Look for the Pr(&gt;F) column for the p-value.\n\n\n\nExtracting Specific Values\n\n# Extract F-statistic\nf_stat &lt;- summary(model)[[1]]$`F value`[1]\n\n# Extract p-value\np_value &lt;- summary(model)[[1]]$`Pr(&gt;F)`[1]\n\n# Print results\ncat(\"F-statistic:\", f_stat, \"\\n\")\ncat(\"P-value:\", p_value, \"\\n\")\n\n\n\nChecking Assumptions\n\n# Check normality of residuals\nshapiro.test(residuals(model))\n\n# Q-Q plot for normality\nqqnorm(residuals(model))\nqqline(residuals(model), col = \"red\")\n\n# Check homogeneity of variance (requires car package)\nlibrary(car)\nleveneTest(stress ~ group, data = data)\n\n# Diagnostic plots\npar(mfrow = c(2, 2))\nplot(model)\npar(mfrow = c(1, 1))"
  },
  {
    "objectID": "Lectures/introduction-to-anova.html#post-hoc-analysis",
    "href": "Lectures/introduction-to-anova.html#post-hoc-analysis",
    "title": "Introduction to ANOVA",
    "section": "Post-hoc Analysis",
    "text": "Post-hoc Analysis\nPost-hoc analysis is essential in ANOVA to identify specific group differences following the detection of a significant F-statistic. This analysis involves comparing all possible pairs of group means to determine which differences are statistically significant.\n\nThe Problem of Multiple Comparisons\nWhen we conduct multiple statistical tests simultaneously, the probability of making at least one Type I error (a false positive) increases. This is known as Alpha Inflation or the Family-Wise Error Rate (FWER).\nIf you conduct one test at \\(\\alpha = 0.05\\), there is a 5% chance of a false positive. However, if you compare 3 groups, you have 3 possible pairwise comparisons. The probability of making at least one error is: \\[1 - (1 - 0.05)^3 \\approx 0.14 \\text{ or 14%}\\]\nTo protect against this, we must use one of two strategies:\n\nAdjust the Alpha (\\(\\alpha\\)): Lower the threshold for significance for each individual test (e.g., the Bonferroni method uses \\(\\alpha / \\text{number of tests}\\)).\nAdjust the P-values: Keep the \\(\\alpha\\) at 0.05 but ‚Äúpenalize‚Äù the p-values by making them larger based on the number of comparisons.\n\n\n\nTukey HSD vs Bonferroni\nTukey‚Äôs Honestly Significant Difference (HSD) test and the Bonferroni correction are both methods used to manage these multiple comparisons.\n\nTukey‚Äôs HSD: Specifically designed for pairwise comparisons of all group means. It adjusts the p-values and confidence intervals to maintain the family-wise error rate at exactly 0.05.\nBonferroni Correction: The most conservative method. It simply divides your overall alpha (0.05) by the number of comparisons. For 3 comparisons, you would only call a result significant if \\(p &lt; 0.0167\\).\n\n\n\n\n\nTukey HSD in R\n\n# Tukey HSD post-hoc test\ntukey_result &lt;- TukeyHSD(model)\nprint(tukey_result)\n\n# Plot the results\nplot(tukey_result)\n\n# The output shows:\n# - diff: Difference in means\n# - lwr, upr: 95% confidence interval\n# - p adj: Adjusted p-value\n\n\nüí° R Tip: If the confidence interval for a pairwise comparison does not include 0, the difference is statistically significant at the 0.05 level.\n\n\n\nPairwise t-tests with Bonferroni Correction\n\n# Pairwise t-tests with Bonferroni adjustment\npairwise.t.test(data$stress, data$group, p.adjust.method = \"bonferroni\")"
  },
  {
    "objectID": "Lectures/introduction-to-anova.html#comprehensive-example-complete-anova-workflow",
    "href": "Lectures/introduction-to-anova.html#comprehensive-example-complete-anova-workflow",
    "title": "Introduction to ANOVA",
    "section": "Comprehensive Example: Complete ANOVA Workflow",
    "text": "Comprehensive Example: Complete ANOVA Workflow\nLet‚Äôs work through a complete ANOVA analysis from start to finish:\n\n# ============================================\n# Complete ANOVA Example\n# Research Question: Does treatment type affect pain reduction?\n# ============================================\n\n# Step 1: Load required packages\nlibrary(car) # For Levene's test\n\nWarning: package 'car' was built under R version 4.5.2\n\n\nLoading required package: carData\n\n\nWarning: package 'carData' was built under R version 4.5.2\n\n# Step 2: Create or read data\nset.seed(456)\npain_data &lt;- data.frame(\n    patient_id = 1:60,\n    treatment = rep(c(\"Standard\", \"Physical Therapy\", \"Medication\"), each = 20),\n    pain_reduction = c(\n        rnorm(20, mean = 2.5, sd = 1.2), # Standard\n        rnorm(20, mean = 4.2, sd = 1.3), # Physical Therapy\n        rnorm(20, mean = 3.8, sd = 1.1) # Medication\n    )\n)\n\n# Convert treatment to factor\npain_data$treatment &lt;- factor(pain_data$treatment)\n\n# Step 3: Explore the data\ncat(\"=== Data Summary ===\\n\")\n\n=== Data Summary ===\n\nsummary(pain_data)\n\n   patient_id               treatment  pain_reduction \n Min.   : 1.00   Medication      :20   Min.   :0.771  \n 1st Qu.:15.75   Physical Therapy:20   1st Qu.:3.232  \n Median :30.50   Standard        :20   Median :3.771  \n Mean   :30.50                         Mean   :3.713  \n 3rd Qu.:45.25                         3rd Qu.:4.473  \n Max.   :60.00                         Max.   :6.560  \n\ncat(\"\\n=== Sample Sizes ===\\n\")\n\n\n=== Sample Sizes ===\n\ntable(pain_data$treatment)\n\n\n      Medication Physical Therapy         Standard \n              20               20               20 \n\ncat(\"\\n=== Descriptive Statistics by Group ===\\n\")\n\n\n=== Descriptive Statistics by Group ===\n\ncat(\"Means:\\n\")\n\nMeans:\n\ntapply(pain_data$pain_reduction, pain_data$treatment, mean)\n\n      Medication Physical Therapy         Standard \n        4.173282         3.887299         3.079626 \n\ncat(\"\\nStandard Deviations:\\n\")\n\n\nStandard Deviations:\n\ntapply(pain_data$pain_reduction, pain_data$treatment, sd)\n\n      Medication Physical Therapy         Standard \n       0.8110086        1.2574151        1.3892073 \n\n# Step 4: Visualize the data\npar(mfrow = c(1, 2))\n\n# Boxplot\nboxplot(pain_reduction ~ treatment,\n    data = pain_data,\n    main = \"Pain Reduction by Treatment\",\n    xlab = \"Treatment\",\n    ylab = \"Pain Reduction (points)\",\n    col = c(\"lightblue\", \"lightgreen\", \"lightcoral\")\n)\n\n# Add points\nstripchart(pain_reduction ~ treatment,\n    data = pain_data,\n    vertical = TRUE,\n    method = \"jitter\",\n    add = TRUE,\n    pch = 19,\n    col = \"darkgray\"\n)\n\n# Histogram of all data\nhist(pain_data$pain_reduction,\n    main = \"Distribution of Pain Reduction\",\n    xlab = \"Pain Reduction (points)\",\n    col = \"lightblue\",\n    border = \"white\"\n)\n\n\n\n\n\n\n\npar(mfrow = c(1, 1))\n\n# Step 5: Check assumptions\ncat(\"\\n=== Assumption Checks ===\\n\")\n\n\n=== Assumption Checks ===\n\n# Normality (overall)\ncat(\"\\nShapiro-Wilk Test for Normality:\\n\")\n\n\nShapiro-Wilk Test for Normality:\n\nshapiro_test &lt;- shapiro.test(pain_data$pain_reduction)\nprint(shapiro_test)\n\n\n    Shapiro-Wilk normality test\n\ndata:  pain_data$pain_reduction\nW = 0.96426, p-value = 0.07616\n\n# Homogeneity of variance\ncat(\"\\nLevene's Test for Homogeneity of Variance:\\n\")\n\n\nLevene's Test for Homogeneity of Variance:\n\nlevene_test &lt;- leveneTest(pain_reduction ~ treatment, data = pain_data)\nprint(levene_test)\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(&gt;F)\ngroup  2   2.134 0.1277\n      57               \n\n# Step 6: Conduct ANOVA\ncat(\"\\n=== ANOVA Results ===\\n\")\n\n\n=== ANOVA Results ===\n\nanova_model &lt;- aov(pain_reduction ~ treatment, data = pain_data)\nanova_summary &lt;- summary(anova_model)\nprint(anova_summary)\n\n            Df Sum Sq Mean Sq F value Pr(&gt;F)  \ntreatment    2  12.87   6.434    4.63 0.0137 *\nResiduals   57  79.21   1.390                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Extract key values\nf_value &lt;- anova_summary[[1]]$`F value`[1]\np_value &lt;- anova_summary[[1]]$`Pr(&gt;F)`[1]\n\ncat(\"\\nF-statistic:\", round(f_value, 3), \"\\n\")\n\n\nF-statistic: 4.63 \n\ncat(\"P-value:\", format.pval(p_value, digits = 3), \"\\n\")\n\nP-value: 0.0137 \n\n# Step 7: Check model diagnostics\ncat(\"\\n=== Model Diagnostics ===\\n\")\n\n\n=== Model Diagnostics ===\n\npar(mfrow = c(2, 2))\nplot(anova_model)\n\n\n\n\n\n\n\npar(mfrow = c(1, 1))\n\n# Step 8: Post-hoc tests (if ANOVA is significant)\nif (p_value &lt; 0.05) {\n    cat(\"\\n=== Post-hoc Analysis (Tukey HSD) ===\\n\")\n    tukey_results &lt;- TukeyHSD(anova_model)\n    print(tukey_results)\n\n    # Plot Tukey results\n    plot(tukey_results, las = 1)\n\n    cat(\"\\n=== Pairwise Comparisons (Bonferroni) ===\\n\")\n    pairwise_results &lt;- pairwise.t.test(pain_data$pain_reduction,\n        pain_data$treatment,\n        p.adjust.method = \"bonferroni\"\n    )\n    print(pairwise_results)\n} else {\n    cat(\"\\nANOVA not significant (p &gt;= 0.05). Post-hoc tests not needed.\\n\")\n}\n\n\n=== Post-hoc Analysis (Tukey HSD) ===\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = pain_reduction ~ treatment, data = pain_data)\n\n$treatment\n                                  diff       lwr        upr     p adj\nPhysical Therapy-Medication -0.2859827 -1.183023  0.6110579 0.7245124\nStandard-Medication         -1.0936565 -1.990697 -0.1966160 0.0131634\nStandard-Physical Therapy   -0.8076739 -1.704714  0.0893667 0.0857513\n\n\n\n\n\n\n\n\n\n\n=== Pairwise Comparisons (Bonferroni) ===\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  pain_data$pain_reduction and pain_data$treatment \n\n                 Medication Physical Therapy\nPhysical Therapy 1.000      -               \nStandard         0.014      0.103           \n\nP value adjustment method: bonferroni \n\n# Step 9: Effect size (eta-squared)\nss_between &lt;- anova_summary[[1]]$`Sum Sq`[1]\nss_total &lt;- sum(anova_summary[[1]]$`Sum Sq`)\neta_squared &lt;- ss_between / ss_total\n\ncat(\"\\n=== Effect Size ===\\n\")\n\n\n=== Effect Size ===\n\ncat(\"Eta-squared:\", round(eta_squared, 3), \"\\n\")\n\nEta-squared: 0.14 \n\ncat(\n    \"Interpretation: \",\n    ifelse(eta_squared &lt; 0.01, \"negligible\",\n        ifelse(eta_squared &lt; 0.06, \"small\",\n            ifelse(eta_squared &lt; 0.14, \"medium\", \"large\")\n        )\n    ), \"\\n\"\n)\n\nInterpretation:  medium \n\n# Step 10: Report results\ncat(\"\\n=== Summary for Reporting ===\\n\")\n\n\n=== Summary for Reporting ===\n\ncat(\"A one-way ANOVA was conducted to compare pain reduction across three treatment groups.\\n\")\n\nA one-way ANOVA was conducted to compare pain reduction across three treatment groups.\n\ncat(\n    \"The ANOVA was\", ifelse(p_value &lt; 0.05, \"significant\", \"not significant\"),\n    sprintf(\n        \"F(%d, %d) = %.2f, p %s.\\n\",\n        anova_summary[[1]]$Df[1],\n        anova_summary[[1]]$Df[2],\n        f_value,\n        ifelse(p_value &lt; 0.001, \"&lt; .001\", paste(\"=\", round(p_value, 3)))\n    )\n)\n\nThe ANOVA was significant F(2, 57) = 4.63, p = 0.014.\n\nif (p_value &lt; 0.05) {\n    cat(\"Post-hoc comparisons using Tukey HSD indicated significant differences between groups.\\n\")\n}\n\nPost-hoc comparisons using Tukey HSD indicated significant differences between groups.\n\ncat(\"\\n=== Analysis Complete ===\\n\")\n\n\n=== Analysis Complete ==="
  },
  {
    "objectID": "Lectures/introduction-to-anova.html#key-takeaways",
    "href": "Lectures/introduction-to-anova.html#key-takeaways",
    "title": "Introduction to ANOVA",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n‚úÖ ANOVA tests if means differ across 3+ groups\n‚úÖ Check assumptions before running ANOVA (normality, homogeneity of variance)\n‚úÖ Use aov() function in R with formula notation outcome ~ group\n‚úÖ If significant, conduct post-hoc tests to identify which groups differ\n‚úÖ Tukey HSD controls for multiple comparisons\n‚úÖ Always visualize your data with boxplots before and after analysis\n‚úÖ Report F-statistic, degrees of freedom, and p-value\n\nüí° R Tip: Save your ANOVA model as an object (model &lt;- aov(...)). You can then use this object for post-hoc tests, diagnostic plots, and extracting results without re-running the analysis!"
  },
  {
    "objectID": "Lectures/graphing-your-data.html",
    "href": "Lectures/graphing-your-data.html",
    "title": "Graphing Your Data",
    "section": "",
    "text": "Download R Code for this Lecture"
  },
  {
    "objectID": "Lectures/graphing-your-data.html#identifying-differences-in-types-of-data-and-how-to-graph",
    "href": "Lectures/graphing-your-data.html#identifying-differences-in-types-of-data-and-how-to-graph",
    "title": "Graphing Your Data",
    "section": "Identifying Differences in Types of Data and How to Graph",
    "text": "Identifying Differences in Types of Data and How to Graph\n\nWhy Graph Data? Benefits\nGraphs are crucial in data analysis and presentation because they help:\n\nQuick Interpretation: Graphs provide a quick overview of data trends, making them easier to interpret than tables.\nPattern Identification: They help identify patterns, relationships, and outliers.\nHypothesis Generation: Aids in forming research hypotheses.\nAudience Engagement: Captures and maintains the audience‚Äôs attention.\nDecision Support: Facilitates evidence-based decision-making.\n\n\n\nData Types\n\nCategorical Data:\n\nNominal: No inherent order or ranking (e.g., coffee, tea, water).\n\nOrdinal: Has a meaningful order or ranking (e.g., small, medium, large).\n\nPros: Easy to categorize and analyze.\nCons: Limited statistical techniques apply, and numerical differences are not meaningful.\nContinuous Data:\n\nInterval: Has equal intervals between values but no true zero (e.g., temperature, dates).\n\nRatio: Has a meaningful zero point and equal intervals (e.g., weight, strength, pressure).\n\nPros: Wide range of statistical techniques available.\nCons: Requires more complex handling due to scale.\n\n\n\nTypes of Graphs\n\nUnivariate Graphs:\n\nDefinition: Focuses on a single variable.\nExamples: Histograms, Box plots.\n\nPros:\n\nSimple and intuitive.\nProvides distributional insights.\n\nCons:\n\nLimited to understanding one variable.\n\nBivariate Graphs:\n\nDefinition: Displays the relationship between two variables.\nExamples: Scatter plots, Box plots.\n\nPros:\n\nUseful for studying relationships and trends.\n\nCons:\n\nMight not reveal hidden multivariate trends.\n\nMultivariate Graphs:\n\nDefinition: Involves multiple variables.\nExamples: Scatter plot matrices, Mosaic plots, Treemaps.\n\nPros:\n\nEffective for uncovering complex relationships.\n\nCons:\n\nInterpretation can be challenging without proper labels."
  },
  {
    "objectID": "Lectures/graphing-your-data.html#stephen-fews-graphic-data-display-key-points",
    "href": "Lectures/graphing-your-data.html#stephen-fews-graphic-data-display-key-points",
    "title": "Graphing Your Data",
    "section": "Stephen Few‚Äôs Graphic Data Display Key Points",
    "text": "Stephen Few‚Äôs Graphic Data Display Key Points\n\nKnow Your Audience: Understand how your audience processes information to tailor your visualizations effectively.\nDefine Your Message: Clearly convey your message simply and quickly.\nUse Visual Elements Appropriately: Combine words, numbers, and images meaningfully.\nPrinciples of Excellence: Based on Edward Tufte‚Äôs principles of good graphical design:\n\nEnforce Visual Comparisons: Allow comparisons between data points.\nShow Causality: Highlight causal relationships if possible.\nIntegrate All Visual Elements: Include relevant text and numbers to provide context.\nContent-Driven Design: Ensure design is driven by data quality, relevance, and integrity."
  },
  {
    "objectID": "Lectures/graphing-your-data.html#principles-of-good-and-bad-graphical-design",
    "href": "Lectures/graphing-your-data.html#principles-of-good-and-bad-graphical-design",
    "title": "Graphing Your Data",
    "section": "Principles of Good and Bad Graphical Design",
    "text": "Principles of Good and Bad Graphical Design\n\nTips and Tricks\n\nGraphical Excellence:\n\nShow Multivariate Data: Present data across multiple dimensions.\nIntegrate All Visual Elements: Include text, numbers, and images cohesively.\nUse Quality, Relevant, and Honest Data: Ensure data integrity and honesty.\n\nCommon Mistakes:\n\nDistorting Data Meaning: Misleading visuals distort interpretation.\nIncorrect Scaling: Scaling errors can misrepresent data trends.\nPoor Data-to-Ink Ratio: Avoid excessive chart junk that doesn‚Äôt add value.\n\n\nThe 27 Worst Charts Of All Time"
  },
  {
    "objectID": "Lectures/graphing-your-data.html#graph-types-and-how-to-use-them",
    "href": "Lectures/graphing-your-data.html#graph-types-and-how-to-use-them",
    "title": "Graphing Your Data",
    "section": "Graph Types and How to Use Them",
    "text": "Graph Types and How to Use Them\n\nHistogram\n\n\n\n\n\n\n\n\n\n\nDefinition: Graphical representation of data distribution using bins of equal length to count frequencies.\nPros:\n\nHelps visualize the distribution shape.\nEasy to compare different distributions.\nIdentifies outliers and skewness.\n\nCons:\n\nBin size selection can lead to over or under-smoothing.\nNot suitable for small data sets.\n\n\n\n# Create a histogram in R\n        data &lt;- rnorm(100)\n        hist(data, main = \"Histogram of Data\", xlab = \"Values\", col = \"blue\", border = \"black\")\n\n\n\nBox Plot\n\n\n\n\n\n\n\n\n\n\nDefinition: Graphically represents data distribution based on quartiles, highlighting outliers, median, and spread.\nPros:\n\nEffective for identifying outliers.\nCompares multiple groups easily.\nRobust to non-normal data.\n\nCons:\n\nLess informative for small data sets.\nNot ideal for displaying multimodal distributions.\n\n\n\n# Create a box plot in R\n        data &lt;- rnorm(100)\n        boxplot(data, main = \"Box Plot Example\")\n\n\n\nPie Chart\n\n\n\n\n\n\n\n\n\n\nDefinition: Displays relative proportions in part-to-whole relationships using slices of a circle.\nPros:\n\nVisually intuitive.\nEffective for simple categorical data.\n\nCons:\n\nDifficult to compare proportions across different charts.\nNot suitable for large numbers of categories.\nCan distort differences due to angle perception issues.\n\n\n\n# Create a pie chart in R\n        values &lt;- c(10, 20, 30, 40)\n        labels &lt;- c(\"A\", \"B\", \"C\", \"D\")\n        pie(values, labels = labels, main = \"Pie Chart Example\")\n\n\n\nScatter Plot\n\n\n\n\n\n\n\n\n\n\nDefinition: Shows the relationship between two continuous variables.\nPros:\n\nIdentifies correlations and relationships between variables.\nHighlights clusters and patterns.\nDetects outliers effectively.\n\nCons:\n\nCan suffer from overplotting with large data sets.\nRequires understanding of correlation interpretation.\n\n\n\n# Create a scatter plot in R\n        x &lt;- rnorm(100)\n        y &lt;- rnorm(100)\n        plot(x, y, main = \"Scatter Plot Example\", xlab = \"X-axis\", ylab = \"Y-axis\")\n\n\n\nMosaic Plot\n\n\n\n\n\n\n\n\n\n\nDefinition: Displays the relationships between two or more categorical variables using a stacked rectangle visualization.\nPros:\n\nEffective for identifying associations in contingency tables.\nHighlights interactions between variables.\n\nCons:\n\nInterpretation can be challenging for complex relationships.\nLess intuitive than simpler visualizations.\n\n\n\n# Create a mosaic plot in R\n        library(vcd)\n        data(Titanic)\n        mosaic(Titanic, shade = TRUE, legend = TRUE)\n\n\n\nBar/Column Chart\n\n\n\n\n\n\n\n\n\n\nDefinition: A bar or column chart compares data across categories using rectangular bars, where each bar‚Äôs length represents the value or frequency of a category. The bars can be vertical (column chart) or horizontal (bar chart).\nPros:\n\nEasily Compares Data:\n\nMakes it simple to compare data across different categories.\nHighlights significant differences between groups.\n\nQuick Insight:\n\nProvides immediate visual insights into category differences.\nSuitable for presenting data to non-technical audiences.\n\nIntuitive Interpretation:\n\nClear and straightforward representation.\nSuitable for a wide range of audiences due to its intuitive nature.\n\nFlexibility:\n\nCan represent both frequency (count data) and summary statistics (e.g., means, medians).\nCan be customized with different bar colors, stacking, grouping, etc.\n\n\nCons:\n\nMisleading Scaling:\n\nCan mislead if bar lengths, axis scales, or data representations are inconsistent.\nImproper axis truncation may exaggerate or minimize differences.\n\nOverloading with Categories:\n\nToo many categories can clutter the chart, making it hard to interpret.\nLimited space can lead to overlapping labels, hindering readability.\n\nNot Ideal for Continuous Data:\n\nWorks best with categorical data but not suitable for continuous variables.\nSummarizing continuous data into categories can lead to loss of detail or oversimplification.\n\nChart Junk:\n\nExcessive use of gridlines, 3D effects, or non-data elements can lead to ‚Äúchart junk,‚Äù distracting from the data itself.\n\nData-to-Ink Ratio:\n\nLow data-to-ink ratio due to large bars relative to the actual information conveyed.\n\n\n\nSummary:\nBar/column charts are highly effective for comparing categorical data and highlighting category differences. However, careful attention to scaling and data representation is crucial to ensure accurate and clear visualization.\n\n# Create a bar chart in R\n        categories &lt;- c(\"A\", \"B\", \"C\", \"D\")\n        values &lt;- c(10, 20, 30, 40)\n        barplot(values, names.arg = categories, main = \"Bar Chart Example\", col = \"blue\")\n\n\n\nQuantile Plot\n\n\n\n\n\n\n\n\n\n\nDefinition: Displays cumulative quantiles of a distribution versus expected quantiles (e.g., normal distribution).\nPros:\n\nIdentifies Distribution Deviations:\n\nClearly shows deviations of data distribution from a theoretical distribution.\n\nEfficient Distribution Fit Determination:\n\nQuickly determines whether the data fits a specific distribution.\n\n\nCons:\n\nRequires Statistical Knowledge:\n\nAccurate interpretation requires understanding quantile statistics.\n\nLess Intuitive:\n\nLess intuitive than histograms or box plots for non-technical audiences.\n\n\n\nSummary:\nQuantile plots are ideal for identifying distribution deviations from theoretical distributions. However, they require statistical knowledge for accurate interpretation and might be less intuitive than other visualization techniques.\n\n# Create a quantile plot in R\n        data &lt;- rnorm(100)\n        qqnorm(data)\n        qqline(data, col = \"blue\")\n\n\n\nTreemap\n\n\nWarning: package 'treemap' was built under R version 4.5.2\n\n\n\n\n\n\n\n\n\n\nDefinition: Visualizes hierarchical data using nested rectangles.\nPros:\n\nDisplays Large Amounts of Data Efficiently:\n\nSuitable for representing large hierarchical data sets.\n\nIntuitive for Showing Hierarchical Relationships:\n\nClearly shows hierarchical relationships in a visual format.\n\nHighlights Patterns and Clusters Visually:\n\nHighlights patterns, clusters, and outliers effectively.\n\n\nCons:\n\nDistorts Proportions if Sizes are Too Small:\n\nSmaller rectangles can become unreadable and distort proportions.\n\nChallenging to Interpret for High-Depth Hierarchies:\n\nDeep hierarchies can make interpretation challenging and confusing.\n\n\n\nSummary:\nTreemaps are excellent for visualizing hierarchical data efficiently and intuitively. However, careful design is crucial to avoid distortions and ensure interpretability, especially with deep hierarchies.\n\n# Create a treemap in R\n        library(treemap)\n        \n        data &lt;- data.frame(\n          category = c(\"A\", \"B\", \"C\", \"D\"),\n          subcategory = c(\"A1\", \"B1\", \"C1\", \"D1\"),\n          value = c(10, 20, 30, 40)\n        )\n        \n        treemap(\n          data,\n          index = c(\"category\", \"subcategory\"),\n          vSize = \"value\",\n          title = \"Treemap Example\"\n        )"
  },
  {
    "objectID": "Lectures/graphing-your-data.html#advanced-graphs",
    "href": "Lectures/graphing-your-data.html#advanced-graphs",
    "title": "Graphing Your Data",
    "section": "Advanced Graphs",
    "text": "Advanced Graphs\n\nTime Series Plots\n\n\n\n\n\n\n\n\n\n\nDefinition: Displays data trends over time.\nPros:\n\nIdeal for identifying trends, cycles, and seasonal patterns.\nSupports multiple time series on the same graph.\nFacilitates forecasting and future planning.\n\nCons:\n\nLess effective for non-temporal data.\nCan suffer from overplotting with too many series.\n\n\n\n# Create a time series plot in R\n        time &lt;- seq(from = as.Date(\"2022-01-01\"), by = \"month\", length.out = 12)\n        values &lt;- rnorm(12, mean = 50, sd = 10)\n        plot(time, values, type = \"l\", main = \"Time Series Plot Example\")\n\n\n\nMaps\n\n\nWarning: package 'ggplot2' was built under R version 4.5.2\n\n\nWarning: package 'maps' was built under R version 4.5.2\n\n\n\n\n\n\n\n\n\n\nDefinition: Visualizes geographic data by plotting locations on maps.\nPros:\n\nProvides spatial context to data.\nEffective for highlighting geographic patterns.\nSupports data aggregation at regional levels.\n\nCons:\n\nInterpretation can be misleading without proper scaling.\nRequires geographic knowledge for accurate interpretation.\n\n\n\n# Create a map in R\n        library(ggplot2)\n        library(maps)\n\n        world_map &lt;- map_data(\"world\")\n        ggplot(world_map, aes(x = long, y = lat, group = group)) +\n          geom_polygon(fill = \"lightblue\", color = \"white\") +\n          ggtitle(\"World Map Example\")\n\n\n\nUnstructured Text\n\nWord Cloud Example\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDefinition: Summarizes text data numerically to gain insights.\nPros:\n\nExtracts useful information from textual data.\nIdentifies patterns and trends in large text corpora.\nSupports topic modeling and sentiment analysis.\n\nCons:\n\nRequires preprocessing to handle noise and inconsistencies.\nInterpretation challenges due to language ambiguities.\n\n\n\n# Summarize unstructured text in R\n        library(tm)\n        library(wordcloud)\n\n        text &lt;- c(\"word1\", \"word2\", \"word3\", \"word1\", \"word2\")\n        corpus &lt;- Corpus(VectorSource(text))\n        tdm &lt;- TermDocumentMatrix(corpus)\n        word_freq &lt;- sort(rowSums(as.matrix(tdm)), decreasing = TRUE)\n        wordcloud(names(word_freq), word_freq, scale = c(3, 0.5), colors = brewer.pal(8, \"Dark2\"))\n\n\n\n\nReferences\n\nTufte, Edward R. The Visual Display of Quantitative Information. Graphics Press, 2001.\nFew, Stephen. Now You See It: Simple Visualization Techniques for Quantitative Analysis. Analytics Press, 2009."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to NPHD9040",
    "section": "",
    "text": "Hello and welcome to NPHD9040 - Applied Multivariable Analysis!\nI‚Äôm Dr.¬†Joshua Lambert, and I‚Äôll be your instructor for this course. I‚Äôm excited to guide you through this journey as we explore the fascinating world of advanced statistical methods and their application in nursing and healthcare research.\n\n\n\nEmail: joshua.lambert@uc.edu\n\nFeel free to reach out to me with any questions or concerns. I‚Äôm here to help you succeed in this course and deepen your understanding of the topics we will cover.\n\n\n\nNPHD9040 is designed to provide an in-depth exploration of advanced statistical methods relevant to healthcare research. The course uses R statistical software for all analyses, emphasizing practical applications and reproducible research. Topics include:\n\n\n\nNew to R? Start here! We‚Äôve created a comprehensive guide to help you get up and running with R and RStudio:\n\n\nThis module covers everything you need to know: - Installing R and RStudio - Navigating the RStudio interface\n- R fundamentals (objects, data types, functions) - Importing and manipulating data - Using R packages - Getting help and troubleshooting\n\n\n\n\nDownload R: https://cran.r-project.org/\nDownload RStudio: https://posit.co/download/rstudio-desktop/\n\n\nüí° Tip: Install R first, then RStudio. Both are completely free!\n\n\n\n\n\n\n\n\nResearch design and hypothesis formulation\nTypes of statistical inference\nUnderstanding variables, sampling, and power calculations\n\n\n\n\n\nPrinciples of graphical excellence\nUnivariate and bivariate graph types\nBest practices for data visualization\n\n\n\n\n\nOne-way ANOVA\nAssumptions, hypothesis testing, and interpretation\n\n\n\n\n\nAnalysis of Covariance\nControlling for covariates and interpreting results\n\n\n\n\n\nTwo-way ANOVA concepts\nInteractions and interpretation\n\n\n\n\n\nAnalyzing repeated measures data\nAssumptions and appropriate tests\n\n\n\n\n\nBasics of linear regression\nAssumptions and model evaluation\n\n\n\n\n\nExpanding linear models to multiple predictors\nInterpretation and model assumptions\n\n\n\n\n\nUnderstanding logistic regression models\nInterpreting odds ratios and diagnostic statistics"
  },
  {
    "objectID": "index.html#how-to-reach-me",
    "href": "index.html#how-to-reach-me",
    "title": "Welcome to NPHD9040",
    "section": "",
    "text": "Email: joshua.lambert@uc.edu\n\nFeel free to reach out to me with any questions or concerns. I‚Äôm here to help you succeed in this course and deepen your understanding of the topics we will cover."
  },
  {
    "objectID": "index.html#overview-of-nphd9040",
    "href": "index.html#overview-of-nphd9040",
    "title": "Welcome to NPHD9040",
    "section": "",
    "text": "NPHD9040 is designed to provide an in-depth exploration of advanced statistical methods relevant to healthcare research. The course uses R statistical software for all analyses, emphasizing practical applications and reproducible research. Topics include:"
  },
  {
    "objectID": "index.html#getting-started-with-r",
    "href": "index.html#getting-started-with-r",
    "title": "Welcome to NPHD9040",
    "section": "",
    "text": "New to R? Start here! We‚Äôve created a comprehensive guide to help you get up and running with R and RStudio:\n\n\nThis module covers everything you need to know: - Installing R and RStudio - Navigating the RStudio interface\n- R fundamentals (objects, data types, functions) - Importing and manipulating data - Using R packages - Getting help and troubleshooting\n\n\n\n\nDownload R: https://cran.r-project.org/\nDownload RStudio: https://posit.co/download/rstudio-desktop/\n\n\nüí° Tip: Install R first, then RStudio. Both are completely free!"
  },
  {
    "objectID": "index.html#course-topics",
    "href": "index.html#course-topics",
    "title": "Welcome to NPHD9040",
    "section": "",
    "text": "Research design and hypothesis formulation\nTypes of statistical inference\nUnderstanding variables, sampling, and power calculations\n\n\n\n\n\nPrinciples of graphical excellence\nUnivariate and bivariate graph types\nBest practices for data visualization\n\n\n\n\n\nOne-way ANOVA\nAssumptions, hypothesis testing, and interpretation\n\n\n\n\n\nAnalysis of Covariance\nControlling for covariates and interpreting results\n\n\n\n\n\nTwo-way ANOVA concepts\nInteractions and interpretation\n\n\n\n\n\nAnalyzing repeated measures data\nAssumptions and appropriate tests\n\n\n\n\n\nBasics of linear regression\nAssumptions and model evaluation\n\n\n\n\n\nExpanding linear models to multiple predictors\nInterpretation and model assumptions\n\n\n\n\n\nUnderstanding logistic regression models\nInterpreting odds ratios and diagnostic statistics"
  },
  {
    "objectID": "Flashcards/flashcards_2wanova.html",
    "href": "Flashcards/flashcards_2wanova.html",
    "title": "Flashcards: Two-Way ANOVA",
    "section": "",
    "text": "What is the purpose of Two-Way ANOVA?\n\n\nClick to reveal answer\n\n\nTwo-Way ANOVA evaluates the effects of two independent variables on a continuous dependent variable, including their interaction.\n\n\n\n\nWhat is a main effect in Two-Way ANOVA?\n\n\nClick to reveal answer\n\n\nA main effect is the impact of one independent variable on the dependent variable, ignoring the levels of the other independent variable.\n\n\n\n\nWhat is an interaction effect in Two-Way ANOVA?\n\n\nClick to reveal answer\n\n\nAn interaction effect occurs when the combined effect of two independent variables on the dependent variable is different from the sum of their individual effects.\n\n\n\n\nHow many main effects and interaction effects can be analyzed in a Two-Way ANOVA?\n\n\nClick to reveal answer\n\n\nTwo-Way ANOVA can analyze two main effects (one for each factor) and one interaction effect between them.\n\n\n\n\nWhat is the null hypothesis for the main effect of Factor A in Two-Way ANOVA?\n\n\nClick to reveal answer\n\n\nThe null hypothesis ((H_0)) for the main effect of Factor A states that all levels of Factor A have the same mean.\n\n\n\n\nWhat is the alternative hypothesis for the main effect of Factor B in Two-Way ANOVA?\n\n\nClick to reveal answer\n\n\nThe alternative hypothesis ((H_1)) for the main effect of Factor B states that at least one level of Factor B has a different mean.\n\n\n\n\nWhat is the null hypothesis for the interaction effect in Two-Way ANOVA?\n\n\nClick to reveal answer\n\n\nThe null hypothesis ((H_0)) for the interaction effect states that there is no interaction between Factors A and B.\n\n\n\n\nWhat are the assumptions of Two-Way ANOVA?\n\n\nClick to reveal answer\n\n\n&lt;ul&gt;\n  &lt;li&gt;Normality of residuals&lt;/li&gt;\n  &lt;li&gt;Homogeneity of variances&lt;/li&gt;\n  &lt;li&gt;Continuous dependent variable&lt;/li&gt;\n  &lt;li&gt;Categorical independent variables&lt;/li&gt;\n  &lt;li&gt;Random sampling&lt;/li&gt;\n&lt;/ul&gt;\n\n\n\n\nWhat is the Sum of Squares for Factor A (SSA)?\n\n\nClick to reveal answer\n\n\n\\[\nSSA = \\sum_{j=1}^{a} n_{j} (\\bar{Y}_{j\\cdot} - \\bar{Y})^2\n\\]\n\n\n\n\nHow do you calculate the Mean Square for Factor B (MSB)?\n\n\nClick to reveal answer\n\n\n\\[\nMSB = \\frac{SSB}{b - 1}\n\\]\n\n\n\n\nWhat is the formula for the F-Ratio of the main effect for Factor A?\n\n\nClick to reveal answer\n\n\n\\[\nF_A = \\frac{MSA}{MSE}\n\\]\n\n\n\n\nWhat does a significant interaction effect imply in a Two-Way ANOVA?\n\n\nClick to reveal answer\n\n\nA significant interaction effect indicates that the impact of one factor on the dependent variable differs depending on the levels of the other factor.\n\n\n\n\nWhat is eta squared (( ^2 )) in Two-Way ANOVA?\n\n\nClick to reveal answer\n\n\nEta squared (( ^2 )) is a measure of the proportion of the total variance explained by a factor or interaction effect.\n\n\n\n\nWhat post-hoc test is commonly used in Two-Way ANOVA to compare specific group means?\n\n\nClick to reveal answer\n\n\nTukey‚Äôs Honestly Significant Difference (HSD) test.\n\n\n\n\nHow do you interpret a significant main effect in Two-Way ANOVA?\n\n\nClick to reveal answer\n\n\nA significant main effect indicates that the means of different levels of one factor are not equal.\n\n\n\n\nWhat graphical method can help identify the presence of interaction effects in Two-Way ANOVA?\n\n\nClick to reveal answer\n\n\nInteraction plots can help identify the presence of interaction effects by plotting the means of different groups.\n\n\n\n\nWhat does the F-statistic represent in Two-Way ANOVA?\n\n\nClick to reveal answer\n\n\nThe F-statistic represents the ratio of the variance between groups to the variance within groups.\n\n\n\n\nWhat are the degrees of freedom for the interaction effect in Two-Way ANOVA?\n\n\nClick to reveal answer\n\n\n\\[\ndf_{AB} = (a - 1)(b - 1)\n\\]\n\n\n\n\nWhat is the purpose of a residual plot in Two-Way ANOVA?\n\n\nClick to reveal answer\n\n\nA residual plot helps check for homoscedasticity and outliers by plotting the residuals against fitted values.\n\n\n\n\nWhy is it important to check for influential observations in Two-Way ANOVA?\n\n\nClick to reveal answer\n\n\nInfluential observations can unduly affect the results of Two-Way ANOVA, leading to biased or incorrect conclusions."
  },
  {
    "objectID": "Assignments/hw5.html",
    "href": "Assignments/hw5.html",
    "title": "NPHD 9040 Homework 5",
    "section": "",
    "text": "TipNew to R Markdown?\n\n\n\nClick here for a guide on Getting Started with R Markdown"
  },
  {
    "objectID": "Assignments/hw5.html#question-1-data-and-relationship",
    "href": "Assignments/hw5.html#question-1-data-and-relationship",
    "title": "NPHD 9040 Homework 5",
    "section": "Question 1: Data and Relationship",
    "text": "Question 1: Data and Relationship\nTask: Explore two variables.\n\nLoad slr_ex1.csv.\nCreate a scatterplot of BP (y) vs BMI (x).\n\nProduce: * Code: Loading and plotting code. * Output: Scatterplot. * Interpretation: Describe the direction (positive/negative) and strength (strong/weak) of the relationship visible in the plot.\n\n\n\n\n\n\nTipHint\n\n\n\nReview Visualizing the Relationship for visualizing the relationship.\n\n\n\n# Your code here"
  },
  {
    "objectID": "Assignments/hw5.html#question-2-model-fitting",
    "href": "Assignments/hw5.html#question-2-model-fitting",
    "title": "NPHD 9040 Homework 5",
    "section": "Question 2: Model Fitting",
    "text": "Question 2: Model Fitting\nTask: Quantify the relationship.\n\nFit the linear model: lm(BP ~ BMI).\nView the summary.\n\nProduce: * Code: lm() and summary() commands. * Output: Model coefficients table. * Interpretation: * Write the regression equation: \\(BP = \\beta_0 + \\beta_1(BMI)\\) * Interpret the slope: For every 1 unit increase in BMI, BP increases by‚Ä¶ * State the statistical significance of the slope.\n\n\n\n\n\n\nTipHint\n\n\n\nSee Examples of Simple Linear Regression and Interpretation of Regression Coefficients.\n\n\n\n# Your code here"
  },
  {
    "objectID": "Assignments/hw5.html#question-3-data-import",
    "href": "Assignments/hw5.html#question-3-data-import",
    "title": "NPHD 9040 Homework 5",
    "section": "Question 3: Data Import",
    "text": "Question 3: Data Import\nTask: Prepare for multiple predictors.\n\nLoad mlr_ex1.csv.\nUse cor() to check correlations between Recovery_Time and potential predictors (Age, Medication_Adherence, Physiotherapy_Sessions).\n\nProduce: * Code: Loading and correlation commands. * Output: Correlation matrix or list of correlation values. * Interpretation: Which predictor has the strongest individual correlation with Recovery Time?\n\n\n\n\n\n\nTipHint\n\n\n\nCheck Introduction to Multiple Linear Regression.\n\n\n\n# Your code here"
  },
  {
    "objectID": "Assignments/hw5.html#question-4-model-fitting",
    "href": "Assignments/hw5.html#question-4-model-fitting",
    "title": "NPHD 9040 Homework 5",
    "section": "Question 4: Model Fitting",
    "text": "Question 4: Model Fitting\nTask: Fit the full model.\n\nFit the model: lm(Recovery_Time ~ Age + Medication_Adherence + Physiotherapy_Sessions).\nView the summary.\n\nProduce: * Code: lm() and summary() commands. * Output: Regression summary table. * Interpretation: Interpret the coefficient for Medication_Adherence. (Hint: ‚ÄúHolding Age and Physio constant, a 1 unit increase in Adherence‚Ä¶‚Äù)\n\n\n\n\n\n\nTipHint\n\n\n\nFollow the Introduction to Multiple Linear Regression steps.\n\n\n\n# Your code here"
  },
  {
    "objectID": "Assignments/hw5.html#question-5-model-evaluation",
    "href": "Assignments/hw5.html#question-5-model-evaluation",
    "title": "NPHD 9040 Homework 5",
    "section": "Question 5: Model Evaluation",
    "text": "Question 5: Model Evaluation\nTask: Assess fit and assumptions.\n\nIdentify the Adjusted R-squared.\nProduce diagnostic plots (plot(model)).\n\nProduce: * Code: Diagnostic plot command. * Output: Numeric R-squared value and the 4 diagnostic plots. * Interpretation: * What percent of variance does the model explain (R-squared)? * Do the residuals look normally distributed (Q-Q plot) and homoscedastic (Residuals vs Fitted)?\n\n\n\n\n\n\nTipHint\n\n\n\nSee Introduction to Multiple Linear Regression for interpreting these plots.\n\n\n\n# Your code here"
  },
  {
    "objectID": "Assignments/hw3.html",
    "href": "Assignments/hw3.html",
    "title": "NPHD 9040 Homework 3",
    "section": "",
    "text": "TipNew to R Markdown?\n\n\n\nClick here for a guide on Getting Started with R Markdown\n\n\n\n\n\n\n\n\nNoteDownloads\n\n\n\nDownload Assignment Template\nDownload Data: Coffee Data.csv\n\n\n\nInstructions\n\nDownload the assignment template (right-click and ‚ÄúSave Link As‚Ä¶‚Äù on the button above).\nOpen the .Rmd file in RStudio.\nComplete the assignment by adding your R code chunks and written answers where indicated.\nSubmission: Submit BOTH your completed R Markdown file (.Rmd) and the rendered output file (HTML, PDF, or Word) to Canvas.\n\nGoal: This assignment covers Two-Way ANOVA, allowing you to examine the main effects of two independent variables and their interaction on a continuous outcome.\n\n\nQuestion 1: Data Import and Exploration\nTask: Prepare the data.\n\nLoad Coffee Data.csv.\nEnsure Grind and Temperature are treated as factors.\n\nProduce: * Code: Loading and conversion code. * Output: str() or summary() showing the variables are Factors.\n\n\n\n\n\n\nTipHint\n\n\n\nRemember to use as.factor() if variables aren‚Äôt read correctly. See Data Types.\n\n\n\n# Your code here\n\n\n\nQuestion 2: Descriptive Statistics\nTask: Visualize the interaction.\n\nCalculate the Mean Strength for all combinations of Grind and Temperature (e.g., Fine/Hot, Fine/Cold, etc.).\nCreate an Interaction Plot (line plot with one variable on X and separate lines for the other).\n\nProduce: * Code: Commands for means (e.g., tapply or group_by) and plotting (e.g., interaction.plot or ggplot). * Output: The table of means and the plot. * Interpretation: Looking at the plot, do the lines cross? Does the effect of Temperature look different depending on Grind?\n\n\n\n\n\n\nTipHint\n\n\n\nSee Example 1 in Two-Way ANOVA for relevant code structures.\n\n\n\n# Your code here\n\n\n\nQuestion 3: Two-Way ANOVA Model\nTask: Test for significance.\n\nFit the Two-Way ANOVA model: Strength ~ Grind * Temperature.\nProduce the ANOVA table.\n\nProduce: * Code: aov() command and summary(). * Output: The ANOVA table showing Main Effects and Interaction. * Interpretation: * Is the Interaction effect significant? * Is the Main Effect of Grind significant? * Is the Main Effect of Temperature significant?\n\n\n\n\n\n\nTipHint\n\n\n\nFollow the syntax in Examples of Two-Way ANOVA. Note the use of * for interaction.\n\n\n\n# Your code here\n\n\n\nQuestion 4: Post-Hoc Tests (Simple Main Effects)\nTask: Deconstruct the interaction (or main effects).\n\nIf the interaction was significant, finding which temperature differs at which grind level is important. Run a Tukey HSD test on the model.\n(Optional challenge) Attempt to test ‚ÄúSimple Main Effects‚Äù (e.g., does Temperature matter specifically for ‚ÄúFine‚Äù grind?).\n\nProduce: * Code: TukeyHSD command. * Output: Pairwise comparison table. * Interpretation: Select one significant comparison from the list and explain it in plain English (e.g., ‚ÄúStrength is significantly higher for Hot vs Cold, but only when Grind is Fine‚Äù).\n\n\n\n\n\n\nTipHint\n\n\n\nFor interactions, Post-hoc Analysis explains how to interpret the complex pairwise comparisons.\n\n\n\n# Your code here"
  },
  {
    "objectID": "Assignments/hw1.html",
    "href": "Assignments/hw1.html",
    "title": "NPHD 9040 Homework 1",
    "section": "",
    "text": "TipNew to R Markdown?\n\n\n\nClick here for a guide on Getting Started with R Markdown\n\n\n\n\n\n\n\n\nNoteDownloads\n\n\n\nDownload Assignment Template\nDownload Data: Coffee Data.csv\n\n\n\nInstructions\n\nDownload the assignment template (right-click and ‚ÄúSave Link As‚Ä¶‚Äù on the button above).\nOpen the .Rmd file in RStudio.\nComplete the assignment by adding your R code chunks and written answers where indicated.\nSubmission: Submit BOTH your completed R Markdown file (.Rmd) and the rendered output file (HTML, PDF, or Word) to Canvas.\n\nGoal: This assignment is designed to ensure you are effectively set up with R and RStudio, to practice manual data entry and calculation with vectors, and to perform basic plotting.\n\n\nQuestion 1: R Setup\nTask: Demonstrate that your R environment is ready.\n\nOpen RStudio.\nIn the Console pane, type R.version.string and press Enter.\nTake a screenshot of your full RStudio window showing this output.\n\nProduce: * An image file (e.g., png or jpg) embedded below.\n\n\n\n\n\n\nTipHint\n\n\n\nUnsure where to find the console? Check the interface overview.\n\n\nReplace this text with your screenshot: ![My RStudio](path/to/image.png) or simply paste your image here if your editor supports it.\n\n\nQuestion 2: Vectors and Manual Data Entry\nTask: Create a dataset from scratch using vectors.\n\nCreate a vector called height_cm with the following values: 165, 170, 178, 160, 182\nCreate a vector called weight_kg with the following values: 68, 75, 82, 55, 90\nCreate a vector called sbp (Systolic Blood Pressure) with values: 120, 135, 140, 115, 150\n\nproduce: * Code: The R commands to create these three vectors.\n\n\n\n\n\n\nTipHint\n\n\n\nReview how to create vectors using the c() function in Getting Started with R.\n\n\n\n# Your code here\n\n\n\nQuestion 3: Calculations and Dataframes\nTask: Perform calculations on vectors and combine them.\n\nCreate a new vector height_m by dividing height_cm by 100.\nCalculate bmi using the formula: \\(BMI = \\frac{weight_{kg}}{height_m^2}\\).\nCombine height_cm, weight_kg, sbp, and bmi into a data frame called health_data.\nPrint the health_data object.\n\nProduce: * Code: Calculations and data frame creation. * Output: The printed data frame showing all 5 subjects.\n\n\n\n\n\n\nTipHint\n\n\n\nNeed help computing the math or creating a dataframe? See Functions and Data Frames.\n\n\n\n# Your code here\n\n\n\nQuestion 4: Basic Graphing\nTask: Visualize your manually created data.\n\nCreate a Histogram of the bmi variable. Give it a title ‚ÄúDistribution of BMI‚Äù and label the x-axis ‚ÄúBMI‚Äù.\nCreate a Scatterplot plotting bmi on the X-axis and sbp on the Y-axis. Title it ‚ÄúBMI vs Systolic BP‚Äù.\n\nProduce: * Code: hist() and plot() commands. * Output: The two plots. * Interpretation: Briefly describe the relationship you see in the scatterplot (e.g., as BMI increases, what happens to SBP?).\n\n\n\n\n\n\nTipHint\n\n\n\nSee Graphing Your Data for examples of histograms and scatterplots (check sections Histogram and Scatter Plot).\n\n\n\n# Your code here\n\n\n\nQuestion 5: Loading External Data\nTask: Load the course dataset Coffee Data.csv.\n\nDownload the dataset from the link at the top of the page.\nLoad it into an R object named coffee using read.csv().\nDisplay the first 6 rows using the head() function.\n\nProduce: * Code: The R commands to read the file and display the head. * Output: The standard R output showing the data frame structure.\n\n\n\n\n\n\nTipHint\n\n\n\nForgotten how to read a CSV? Review Importing Data.\n\n\n\n# Your code here\n\n\n\nQuestion 6: Research Scenarios\nTask: For each research scenario, identify the variables.\nProduce: * Written Answer: Clearly state the Independent Variable (IV) and Dependent Variable (DV) for each case.\n\n\n\n\n\n\nTipHint\n\n\n\nNeed a refresher on Independent vs Dependent variables? Check the Preliminaries Lecture.\n\n\n\nScenario: A researcher wants to study if the type of music played in a waiting room (Classical, Jazz, or No Music) affects patient anxiety levels (measured on a scale of 1-10).\n\nIV: [Your Answer Here]\nDV: [Your Answer Here]\n\nScenario: A study looks at whether the number of hours of sleep (continuous variable) predicts reaction time (milliseconds) in drivers.\n\nIV: [Your Answer Here]\nDV: [Your Answer Here]\n\nScenario: Comparing the blood pressure of patients before and after an exercise intervention.\n\nIV: [Your Answer Here]\nDV: [Your Answer Here]"
  },
  {
    "objectID": "Assignments/final.html",
    "href": "Assignments/final.html",
    "title": "Assignment Under Construction",
    "section": "",
    "text": "Coming Soon\nThis assignment is currently being updated."
  },
  {
    "objectID": "Assignments/hw2.html",
    "href": "Assignments/hw2.html",
    "title": "NPHD 9040 Homework 2",
    "section": "",
    "text": "TipNew to R Markdown?\n\n\n\nClick here for a guide on Getting Started with R Markdown\n\n\n\n\n\n\n\n\nNoteDownloads\n\n\n\nDownload Assignment Template\nDownload Data: anova_ex1.csv\n\n\n\nInstructions\n\nDownload the assignment template (right-click and ‚ÄúSave Link As‚Ä¶‚Äù on the button above).\nOpen the .Rmd file in RStudio.\nComplete the assignment by adding your R code chunks and written answers where indicated.\nSubmission: Submit BOTH your completed R Markdown file (.Rmd) and the rendered output file (HTML, PDF, or Word) to Canvas.\n\nGoal: This assignment covers the One-Way Analysis of Variance (ANOVA), including assumptions, execution in R, and interpretation of results.\n\n\nQuestion 1: Data Import and Exploration\nTask: Prepare the data for analysis.\n\nLoad anova_ex1.csv into R.\nDisplay the first few rows.\nCheck the structure of the dataframe.\n\nProduce: * Code: R commands to load and inspect data. * Output: The head() and str() (or summary()) of the dataset. * Interpretation: Briefly confirm that your grouping variable is a factor (or character) and your outcome is numeric.\n\n\n\n\n\n\nTipHint\n\n\n\nReview Reading Data if needed.\n\n\n\n# Your code here\n\n\n\nQuestion 2: Descriptive Statistics and Visualization\nTask: Explore the data visually and numerically before testing.\n\nCalculate determining summary statistics (Mean and SD) for each group.\nCreate a boxplot of stress by group.\n\nProduce: * Code: R commands for summary stats and plotting. * Output: A table (or printed output) of Means/SDs and the Boxplot image. * Interpretation: Describe any apparent differences in the boxplots (e.g., ‚ÄúThe Behavioral group appears to have higher stress‚Ä¶‚Äù).\n\n\n\n\n\n\nTipHint\n\n\n\nSee Visualizing Using Boxplots for code examples.\n\n\n\n# Your code here\n\n\n\nQuestion 3: Assumptions of ANOVA\nTask: Verify that the data meets the requirements for ANOVA.\n\nNormality: Test the normality of the residuals (Shapiro-Wilk) or visually inspect a histogram or Q-Q plot.\nHomogeneity of Variance: Test if groups have equal variances (Levene‚Äôs Test).\n\nProduce: * Code: R commands for Shapiro-Wilk and Levene‚Äôs tests. * Output: Test statistics and p-values. * Interpretation: * Normality: Is the p-value &gt; 0.05? What does that mean? * Homogeneity: Is the p-value &gt; 0.05? What does that mean?\n\n\n\n\n\n\nTipHint\n\n\n\nCheck Assumptions of ANOVA and how to test them in R.\n\n\n\n# Your code here\n\n\n\nQuestion 4: One-Way ANOVA\nTask: Perform the omnibus One-Way ANOVA test.\n\nRun the ANOVA model (aov(outcome ~ group)).\nPrint the summary table.\n\nProduce: * Code: R command to fit model and show summary. * Output: The ANOVA table. * Interpretation: Report the F-statistic, degrees of freedom, and p-value. State clearly whether the result is statistically significant and what that implies (ie. ‚ÄúAt least one group differs‚Ä¶‚Äù).\n\n\n\n\n\n\nTipHint\n\n\n\nFollow the steps in Conducting ANOVA in R.\n\n\n\n# Your code here\n\n\n\nQuestion 5: Post-Hoc Analysis\nTask: Identifying specific group differences.\n\nIf the ANOVA in Q4 was significant, conduct a Tukey HSD post-hoc test.\nIf it was not significant, note that post-hoc tests are not needed (but run the code anyway for practice).\n\nProduce: * Code: R command for TukeyHSD. * Output: The table of pairwise comparisons. * Interpretation: Identify which specific pairs of groups are significantly different from each other based on the adjusted p-values.\n\n\n\n\n\n\nTipHint\n\n\n\nSee Post-hoc Analysis for using TukeyHSD().\n\n\n\n# Your code here"
  },
  {
    "objectID": "Assignments/hw4.html",
    "href": "Assignments/hw4.html",
    "title": "NPHD 9040 Homework 4",
    "section": "",
    "text": "TipNew to R Markdown?\n\n\n\nClick here for a guide on Getting Started with R Markdown\n\n\n\n\n\n\n\n\nNoteDownloads\n\n\n\nDownload Assignment Template\nDownload Data: rm_ex.csv\n\n\n\nInstructions\n\nDownload the assignment template (right-click and ‚ÄúSave Link As‚Ä¶‚Äù on the button above).\nOpen the .Rmd file in RStudio.\nComplete the assignment by adding your R code chunks and written answers where indicated.\nSubmission: Submit BOTH your completed R Markdown file (.Rmd) and the rendered output file (HTML, PDF, or Word) to Canvas.\n\nGoal: This assignment covers One-Way Repeated Measures ANOVA.\n\n\nQuestion 1: Data Import and Structure\nTask: Load and format data.\n\nLoad rm_ex.csv.\nCrucial Step: Ensure Subject is a Factor. Ensure Time is a Factor.\n\nProduce: * Code: Loading and as.factor() conversion. * Output: Verification (str or summary).\n\n\n\n\n\n\nTipHint\n\n\n\nSubject ID must be a factor for the error term to work. See Understanding the Structure.\n\n\n\n# Your code here\n\n\n\nQuestion 2: Descriptive Statistics and Visualization\nTask: Visualize subject trajectories.\n\nCalculate Means by Time.\nCreate a ‚ÄúSpaghetti Plot‚Äù (lines connecting each subject‚Äôs data points) OR a Boxplot by Time.\n\nProduce: * Code: Plotting commands. * Output: The plot. * Interpretation: Do subjects seem to increase or decrease over time? Is there a consistent pattern?\n\n\n\n\n\n\nTipHint\n\n\n\nWhile the lecture focuses on analysis, you can see general graphing tips in Reference or check out general R resources for ‚Äúspaghetti plots‚Äù.\n\n\n\n# Your code here\n\n\n\nQuestion 3: Assumption Checking\nTask: Understand Sphericity.\n\nRepeated measures ANOVA assumes ‚ÄúSphericity‚Äù.\nProvide a written definition.\n(Optional) Run ezANOVA or anova_test (rstatix) to see Mauchly‚Äôs Test for Sphericity results.\n\nProduce: * Written Answer: What is sphericity? Why does it matter? * (Optional) Code/Output: Mauchly‚Äôs test result.\n\n\n\n\n\n\nTipHint\n\n\n\nRead about Sphericity Assumption.\n\n\n\n\nQuestion 4: Run Repeated Measures ANOVA\nTask: Determine if Time has an effect.\n\nRun the Repeated Measures ANOVA. (Hint: aov(BP ~ Time + Error(Subject/Time))).\nDisplay the summary.\n\nProduce: * Code: The aov command with the Error term. * Output: The ANOVA summary table. * Interpretation: Is the effect of Time significant? Report F, df, and p-value.\n\n\n\n\n\n\nTipHint\n\n\n\nSee Example 1 in Repeated Measures for ezANOVA usage, or standard R guides for aov.\n\n\n\n# Your code here\n\n\n\nQuestion 5: Post-Hoc Analysis\nTask: Pairwise comparisons.\n\nIf Time is significant, test differences between specific time points (Baseline vs Week 1, etc.) using pairwise.t.test with paired = TRUE and a correction method (like Bonferroni).\n\nProduce: * Code: Pairwise t-test command. * Output: Matrix of p-values. * Interpretation: Which specific time points differ significantly?\n\n\n\n\n\n\nTipHint\n\n\n\nSee Bonferroni Correction for the concept.\n\n\n\n# Your code here"
  },
  {
    "objectID": "Assignments/midterm.html",
    "href": "Assignments/midterm.html",
    "title": "Assignment Under Construction",
    "section": "",
    "text": "Coming Soon\nThis assignment is currently being updated."
  },
  {
    "objectID": "Flashcards/flashcards_anova.html",
    "href": "Flashcards/flashcards_anova.html",
    "title": "Flashcards: ANOVA",
    "section": "",
    "text": "What is a null hypothesis?\n\n\nClick to reveal answer\n\n\nThe null hypothesis (H‚ÇÄ) in hypothesis testing states that there is no significant difference or relationship between variables.\n\n\n\n\n\nWhat is the purpose of formulating both written and mathematical hypotheses?\n\n\nClick to reveal answer\n\n\nFormulating both written and mathematical hypotheses ensures clarity and precision in stating the research question and allows for statistical testing.\n\n\n\n\n\nWhat is Type 1 Error?\n\n\nClick to reveal answer\n\n\nType 1 Error occurs when the null hypothesis is incorrectly rejected, indicating a significant result when there is no true effect or relationship (false positive).\n\n\n\n\n\nWhat is Type 2 Error?\n\n\nClick to reveal answer\n\n\nType 2 Error occurs when the null hypothesis is incorrectly retained, failing to detect a true effect or relationship (false negative).\n\n\n\n\n\nWhat are the assumptions of ANOVA?\n\n\nClick to reveal answer\n\n\nAssumptions of ANOVA include: normal distribution of the residuals, homogeneity of variance, independence of observations, and categorical independent variables.\n\n\n\n\n\nHow do boxplots help in visualizing data distribution?\n\n\nClick to reveal answer\n\n\nBoxplots provide a graphical representation of the distribution of data, showing the median, quartiles, and outliers across different groups or categories.\n\n\n\n\n\nHow are degrees of freedom calculated in ANOVA?\n\n\nClick to reveal answer\n\n\nDegrees of freedom in ANOVA are calculated as the number of independent observations minus the number of parameters estimated from the sample.\n\n\n\n\n\nWhat does the F statistic represent in ANOVA?\n\n\nClick to reveal answer\n\n\nThe F statistic in ANOVA measures the ratio of variance between groups to variance within groups, indicating whether there are significant differences among group means.\n\n\n\n\n\nWhat is the purpose of post-hoc analysis in ANOVA?\n\n\nClick to reveal answer\n\n\nPost-hoc analysis in ANOVA is performed after finding a significant F-statistic to identify which specific groups differ from each other.\n\n\n\n\n\nWhy is homogeneity of variance important in ANOVA?\n\n\nClick to reveal answer\n\n\nHomogeneity of variance ensures that the variability within each group is approximately equal across all groups, which is an assumption for valid ANOVA results.\n\n\n\n\n\nHow is the p-value calculated from the F distribution?\n\n\nClick to reveal answer\n\n\nThe p-value in ANOVA is calculated based on the F statistic and the degrees of freedom, representing the probability of obtaining the observed results under the null hypothesis.\n\n\n\n\n\nWhat are Sum of Squares Between (SSB) and Sum of Squares Within (SSW) in ANOVA?\n\n\nClick to reveal answer\n\n\nSSB represents the variation between groups‚Äô means, while SSW represents the variation within each group.\n\n\n\n\n\nWhat are the null and alternative hypotheses in ANOVA?\n\n\nClick to reveal answer\n\n\nThe null hypothesis (H‚ÇÄ) states that all group means are equal, while the alternative hypothesis (H‚ÇÅ) states that at least one group mean is different.\n\n\n\n\n\nWhat assumptions should be checked before performing ANOVA?\n\n\nClick to reveal answer\n\n\nBefore performing ANOVA, it is essential to check assumptions such as normality of residuals, homogeneity of variance, independence of observations, and linearity of relationships.\n\n\n\n\n\nWhat is the difference between ANOVA and t-tests?\n\n\nClick to reveal answer\n\n\nWhile t-tests are used to compare means between two groups, ANOVA is used to compare means across multiple groups simultaneously.\n\n\n\n\n\nWhy are degrees of freedom important in statistical analysis?\n\n\nClick to reveal answer\n\n\nDegrees of freedom represent the number of independent pieces of information available for estimating statistical parameters, influencing the precision and reliability of statistical tests.\n\n\n\n\n\nHow can ANOVA results be visually represented?\n\n\nClick to reveal answer\n\n\nANOVA results can be visually represented using bar charts, boxplots, or interaction plots to illustrate group differences and statistical significance.\n\n\n\n\n\nWhen should post-hoc tests be conducted in ANOVA?\n\n\nClick to reveal answer\n\n\nPost-hoc tests should be conducted after obtaining a significant ANOVA result to determine which specific group differences contribute to the overall significance.\n\n\n\n\n\nWhat is statistical power in ANOVA?\n\n\nClick to reveal answer\n\n\nStatistical power in ANOVA represents the probability of detecting a true effect or relationship when it exists, minimizing the risk of Type 2 Error."
  },
  {
    "objectID": "Flashcards/flashcards_anova.html#understanding-hypothesis-testing",
    "href": "Flashcards/flashcards_anova.html#understanding-hypothesis-testing",
    "title": "Flashcards: ANOVA",
    "section": "",
    "text": "What is a null hypothesis?\n\n\nClick to reveal answer\n\n\nThe null hypothesis (H‚ÇÄ) in hypothesis testing states that there is no significant difference or relationship between variables."
  },
  {
    "objectID": "Flashcards/flashcards_anova.html#constructing-hypotheses",
    "href": "Flashcards/flashcards_anova.html#constructing-hypotheses",
    "title": "Flashcards: ANOVA",
    "section": "",
    "text": "What is the purpose of formulating both written and mathematical hypotheses?\n\n\nClick to reveal answer\n\n\nFormulating both written and mathematical hypotheses ensures clarity and precision in stating the research question and allows for statistical testing."
  },
  {
    "objectID": "Flashcards/flashcards_anova.html#type-1-error",
    "href": "Flashcards/flashcards_anova.html#type-1-error",
    "title": "Flashcards: ANOVA",
    "section": "",
    "text": "What is Type 1 Error?\n\n\nClick to reveal answer\n\n\nType 1 Error occurs when the null hypothesis is incorrectly rejected, indicating a significant result when there is no true effect or relationship (false positive)."
  },
  {
    "objectID": "Flashcards/flashcards_anova.html#type-2-error",
    "href": "Flashcards/flashcards_anova.html#type-2-error",
    "title": "Flashcards: ANOVA",
    "section": "",
    "text": "What is Type 2 Error?\n\n\nClick to reveal answer\n\n\nType 2 Error occurs when the null hypothesis is incorrectly retained, failing to detect a true effect or relationship (false negative)."
  },
  {
    "objectID": "Flashcards/flashcards_anova.html#assumptions-of-anova",
    "href": "Flashcards/flashcards_anova.html#assumptions-of-anova",
    "title": "Flashcards: ANOVA",
    "section": "",
    "text": "What are the assumptions of ANOVA?\n\n\nClick to reveal answer\n\n\nAssumptions of ANOVA include: normal distribution of the residuals, homogeneity of variance, independence of observations, and categorical independent variables."
  },
  {
    "objectID": "Flashcards/flashcards_anova.html#visualizing-data-distribution",
    "href": "Flashcards/flashcards_anova.html#visualizing-data-distribution",
    "title": "Flashcards: ANOVA",
    "section": "",
    "text": "How do boxplots help in visualizing data distribution?\n\n\nClick to reveal answer\n\n\nBoxplots provide a graphical representation of the distribution of data, showing the median, quartiles, and outliers across different groups or categories."
  },
  {
    "objectID": "Flashcards/flashcards_anova.html#calculating-degrees-of-freedom",
    "href": "Flashcards/flashcards_anova.html#calculating-degrees-of-freedom",
    "title": "Flashcards: ANOVA",
    "section": "",
    "text": "How are degrees of freedom calculated in ANOVA?\n\n\nClick to reveal answer\n\n\nDegrees of freedom in ANOVA are calculated as the number of independent observations minus the number of parameters estimated from the sample."
  },
  {
    "objectID": "Flashcards/flashcards_anova.html#understanding-the-f-statistic",
    "href": "Flashcards/flashcards_anova.html#understanding-the-f-statistic",
    "title": "Flashcards: ANOVA",
    "section": "",
    "text": "What does the F statistic represent in ANOVA?\n\n\nClick to reveal answer\n\n\nThe F statistic in ANOVA measures the ratio of variance between groups to variance within groups, indicating whether there are significant differences among group means."
  },
  {
    "objectID": "Flashcards/flashcards_anova.html#post-hoc-analysis",
    "href": "Flashcards/flashcards_anova.html#post-hoc-analysis",
    "title": "Flashcards: ANOVA",
    "section": "",
    "text": "What is the purpose of post-hoc analysis in ANOVA?\n\n\nClick to reveal answer\n\n\nPost-hoc analysis in ANOVA is performed after finding a significant F-statistic to identify which specific groups differ from each other."
  },
  {
    "objectID": "Flashcards/flashcards_anova.html#homogeneity-of-variance",
    "href": "Flashcards/flashcards_anova.html#homogeneity-of-variance",
    "title": "Flashcards: ANOVA",
    "section": "",
    "text": "Why is homogeneity of variance important in ANOVA?\n\n\nClick to reveal answer\n\n\nHomogeneity of variance ensures that the variability within each group is approximately equal across all groups, which is an assumption for valid ANOVA results."
  },
  {
    "objectID": "Flashcards/flashcards_anova.html#the-f-distribution",
    "href": "Flashcards/flashcards_anova.html#the-f-distribution",
    "title": "Flashcards: ANOVA",
    "section": "",
    "text": "How is the p-value calculated from the F distribution?\n\n\nClick to reveal answer\n\n\nThe p-value in ANOVA is calculated based on the F statistic and the degrees of freedom, representing the probability of obtaining the observed results under the null hypothesis."
  },
  {
    "objectID": "Flashcards/flashcards_anova.html#sum-of-squares",
    "href": "Flashcards/flashcards_anova.html#sum-of-squares",
    "title": "Flashcards: ANOVA",
    "section": "",
    "text": "What are Sum of Squares Between (SSB) and Sum of Squares Within (SSW) in ANOVA?\n\n\nClick to reveal answer\n\n\nSSB represents the variation between groups‚Äô means, while SSW represents the variation within each group."
  },
  {
    "objectID": "Flashcards/flashcards_anova.html#anova-hypotheses",
    "href": "Flashcards/flashcards_anova.html#anova-hypotheses",
    "title": "Flashcards: ANOVA",
    "section": "",
    "text": "What are the null and alternative hypotheses in ANOVA?\n\n\nClick to reveal answer\n\n\nThe null hypothesis (H‚ÇÄ) states that all group means are equal, while the alternative hypothesis (H‚ÇÅ) states that at least one group mean is different."
  },
  {
    "objectID": "Flashcards/flashcards_anova.html#anova-assumptions",
    "href": "Flashcards/flashcards_anova.html#anova-assumptions",
    "title": "Flashcards: ANOVA",
    "section": "",
    "text": "What assumptions should be checked before performing ANOVA?\n\n\nClick to reveal answer\n\n\nBefore performing ANOVA, it is essential to check assumptions such as normality of residuals, homogeneity of variance, independence of observations, and linearity of relationships."
  },
  {
    "objectID": "Flashcards/flashcards_anova.html#comparing-anova-and-t-tests",
    "href": "Flashcards/flashcards_anova.html#comparing-anova-and-t-tests",
    "title": "Flashcards: ANOVA",
    "section": "",
    "text": "What is the difference between ANOVA and t-tests?\n\n\nClick to reveal answer\n\n\nWhile t-tests are used to compare means between two groups, ANOVA is used to compare means across multiple groups simultaneously."
  },
  {
    "objectID": "Flashcards/flashcards_anova.html#understanding-degrees-of-freedom",
    "href": "Flashcards/flashcards_anova.html#understanding-degrees-of-freedom",
    "title": "Flashcards: ANOVA",
    "section": "",
    "text": "Why are degrees of freedom important in statistical analysis?\n\n\nClick to reveal answer\n\n\nDegrees of freedom represent the number of independent pieces of information available for estimating statistical parameters, influencing the precision and reliability of statistical tests."
  },
  {
    "objectID": "Flashcards/flashcards_anova.html#visualizing-anova-results",
    "href": "Flashcards/flashcards_anova.html#visualizing-anova-results",
    "title": "Flashcards: ANOVA",
    "section": "",
    "text": "How can ANOVA results be visually represented?\n\n\nClick to reveal answer\n\n\nANOVA results can be visually represented using bar charts, boxplots, or interaction plots to illustrate group differences and statistical significance."
  },
  {
    "objectID": "Flashcards/flashcards_anova.html#understanding-post-hoc-tests",
    "href": "Flashcards/flashcards_anova.html#understanding-post-hoc-tests",
    "title": "Flashcards: ANOVA",
    "section": "",
    "text": "When should post-hoc tests be conducted in ANOVA?\n\n\nClick to reveal answer\n\n\nPost-hoc tests should be conducted after obtaining a significant ANOVA result to determine which specific group differences contribute to the overall significance."
  },
  {
    "objectID": "Flashcards/flashcards_anova.html#statistical-power-in-anova",
    "href": "Flashcards/flashcards_anova.html#statistical-power-in-anova",
    "title": "Flashcards: ANOVA",
    "section": "",
    "text": "What is statistical power in ANOVA?\n\n\nClick to reveal answer\n\n\nStatistical power in ANOVA represents the probability of detecting a true effect or relationship when it exists, minimizing the risk of Type 2 Error."
  },
  {
    "objectID": "Lectures/getting-started-with-r.html",
    "href": "Lectures/getting-started-with-r.html",
    "title": "Getting Started with R",
    "section": "",
    "text": "Download R Code for this Lecture"
  },
  {
    "objectID": "Lectures/getting-started-with-r.html#why-r",
    "href": "Lectures/getting-started-with-r.html#why-r",
    "title": "Getting Started with R",
    "section": "Why R?",
    "text": "Why R?\nR offers several advantages for nursing research:\n\nFree and Open Source: No licensing fees, available to everyone\nPowerful: Can handle simple to complex statistical analyses\nReproducible: Your analysis is documented in code, making it easy to replicate\nWidely Used: Large community of users and extensive online resources\nFlexible: Can create publication-quality graphics and reports"
  },
  {
    "objectID": "Lectures/getting-started-with-r.html#installing-r-and-rstudio",
    "href": "Lectures/getting-started-with-r.html#installing-r-and-rstudio",
    "title": "Getting Started with R",
    "section": "Installing R and RStudio",
    "text": "Installing R and RStudio\nYou‚Äôll need to install two programs: R (the statistical software) and RStudio (a user-friendly interface for R).\n\nStep 1: Install R\n\nGo to https://cran.r-project.org/\nClick on the download link for your operating system:\n\nWindows: Click ‚ÄúDownload R for Windows‚Äù ‚Üí ‚Äúbase‚Äù ‚Üí Download the latest version\nMac: Click ‚ÄúDownload R for macOS‚Äù ‚Üí Download the appropriate version for your Mac\n\nRun the installer and follow the default installation options\n\n\n\nStep 2: Install RStudio\n\nGo to https://posit.co/download/rstudio-desktop/\nClick ‚ÄúDownload RStudio Desktop‚Äù (the free version)\nRun the installer and follow the default installation options\n\n\nüí° R Tip: Always install R before RStudio. RStudio needs R to be installed first to work properly."
  },
  {
    "objectID": "Lectures/getting-started-with-r.html#understanding-the-rstudio-interface",
    "href": "Lectures/getting-started-with-r.html#understanding-the-rstudio-interface",
    "title": "Getting Started with R",
    "section": "Understanding the RStudio Interface",
    "text": "Understanding the RStudio Interface\nWhen you open RStudio, you‚Äôll see four main panes:\n\n1. Script Editor (Top Left)\n\nWhere you write and save your R code\nCreate a new script: File ‚Üí New File ‚Üí R Script\nSave your work here for future use\n\n\n\n2. Console (Bottom Left)\n\nWhere R executes commands and displays results\nYou can type commands directly here, but they won‚Äôt be saved\nOutput and messages appear here\n\n\n\n3. Environment/History (Top Right)\n\nEnvironment: Shows all objects (data, variables) currently in memory\nHistory: Shows all commands you‚Äôve run\n\n\n\n4. Files/Plots/Packages/Help (Bottom Right)\n\nFiles: Browse files on your computer\nPlots: View graphs and visualizations\nPackages: Manage R packages (extensions)\nHelp: Access documentation\n\n\nüí° R Tip: You can customize the pane layout in Tools ‚Üí Global Options ‚Üí Pane Layout."
  },
  {
    "objectID": "Lectures/getting-started-with-r.html#r-basics",
    "href": "Lectures/getting-started-with-r.html#r-basics",
    "title": "Getting Started with R",
    "section": "R Basics",
    "text": "R Basics\n\nThe Assignment Operator\nIn R, we use &lt;- to assign values to objects (variables):\n\n# Assign the value 5 to an object called 'x'\nx &lt;- 5\n\n# View the value of x\nx\n\n[1] 5\n\n# You can also use = for assignment, but &lt;- is preferred in R\ny &lt;- 10\ny\n\n[1] 10\n\n\n\nüí° R Tip: The keyboard shortcut for &lt;- is Alt + - (Windows) or Option + - (Mac).\n\n\n\nData Types\nR has several basic data types:\n\n# Numeric (numbers)\nage &lt;- 45\nweight &lt;- 68.5\n\n# Character (text - always in quotes)\nname &lt;- \"Patient A\"\ndiagnosis &lt;- \"Hypertension\"\n\n# Logical (TRUE or FALSE)\nis_smoker &lt;- TRUE\nhas_diabetes &lt;- FALSE\n\n# Check the type of an object\nclass(age)\n\n[1] \"numeric\"\n\nclass(name)\n\n[1] \"character\"\n\nclass(is_smoker)\n\n[1] \"logical\"\n\n\n\n\nVectors\nVectors are collections of values of the same type. We create them using c() (combine):\n\n# Numeric vector\nages &lt;- c(25, 34, 45, 56, 67)\nages\n\n[1] 25 34 45 56 67\n\n# Character vector\ntreatments &lt;- c(\"Placebo\", \"Drug A\", \"Drug B\", \"Placebo\", \"Drug A\")\ntreatments\n\n[1] \"Placebo\" \"Drug A\"  \"Drug B\"  \"Placebo\" \"Drug A\" \n\n# Access individual elements using brackets []\nages[1]  # First element\n\n[1] 25\n\nages[3]  # Third element\n\n[1] 45\n\n# Access multiple elements\nages[c(1, 3, 5)]  # First, third, and fifth elements\n\n[1] 25 45 67\n\n\n\nüí° R Tip: R uses 1-based indexing, meaning the first element is at position 1 (not 0 like some other languages).\n\n\n\nData Frames\nData frames are like spreadsheets - they have rows and columns. This is how we typically work with data in R:\n\n# Create a simple data frame\npatient_data &lt;- data.frame(\n  patient_id = c(1, 2, 3, 4, 5),\n  age = c(25, 34, 45, 56, 67),\n  treatment = c(\"Placebo\", \"Drug A\", \"Drug B\", \"Placebo\", \"Drug A\"),\n  outcome = c(5.2, 6.8, 7.1, 5.5, 6.9)\n)\n\n# View the data frame\npatient_data\n\n  patient_id age treatment outcome\n1          1  25   Placebo     5.2\n2          2  34    Drug A     6.8\n3          3  45    Drug B     7.1\n4          4  56   Placebo     5.5\n5          5  67    Drug A     6.9\n\n# View structure of the data frame\nstr(patient_data)\n\n'data.frame':   5 obs. of  4 variables:\n $ patient_id: num  1 2 3 4 5\n $ age       : num  25 34 45 56 67\n $ treatment : chr  \"Placebo\" \"Drug A\" \"Drug B\" \"Placebo\" ...\n $ outcome   : num  5.2 6.8 7.1 5.5 6.9\n\n# View first few rows\nhead(patient_data)\n\n  patient_id age treatment outcome\n1          1  25   Placebo     5.2\n2          2  34    Drug A     6.8\n3          3  45    Drug B     7.1\n4          4  56   Placebo     5.5\n5          5  67    Drug A     6.9\n\n# Access a column using $\npatient_data$age\n\n[1] 25 34 45 56 67\n\n# Access a column using brackets\npatient_data[, \"treatment\"]\n\n[1] \"Placebo\" \"Drug A\"  \"Drug B\"  \"Placebo\" \"Drug A\" \n\n# Access a specific cell [row, column]\npatient_data[2, 3]  # Row 2, Column 3\n\n[1] \"Drug A\"\n\n\n\n\nFunctions\nFunctions perform operations. They have a name followed by parentheses containing arguments:\n\n# Calculate mean (average)\nmean(ages)\n\n[1] 45.4\n\n# Calculate standard deviation\nsd(ages)\n\n[1] 16.772\n\n# Calculate median\nmedian(ages)\n\n[1] 45\n\n# Summary statistics\nsummary(ages)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   25.0    34.0    45.0    45.4    56.0    67.0 \n\n# Count number of elements\nlength(ages)\n\n[1] 5\n\n# Create a table of frequencies\ntable(treatments)\n\ntreatments\n Drug A  Drug B Placebo \n      2       1       2 \n\n\n\nüí° R Tip: To learn about any function, type ?function_name in the console (e.g., ?mean)."
  },
  {
    "objectID": "Lectures/getting-started-with-r.html#working-with-data",
    "href": "Lectures/getting-started-with-r.html#working-with-data",
    "title": "Getting Started with R",
    "section": "Working with Data",
    "text": "Working with Data\n\nSetting Your Working Directory\nThe working directory is where R looks for files and saves output:\n\n# Check current working directory\ngetwd()\n\n# Set working directory (use your own path)\nsetwd(\"C:/Users/YourName/Documents/R_Projects\")\n\n# Or use Session ‚Üí Set Working Directory ‚Üí Choose Directory in RStudio\n\n\nüí° R Tip: Use forward slashes / in file paths, even on Windows. Or use double backslashes \\\\.\n\n\n\nReading Data from CSV Files\nCSV (Comma-Separated Values) files are common for data storage. There are three main ways to read them:\n\n1. Direct File Path\nBest for reproducibility (your script will always know where to look).\n\n# Read a CSV file by providing the path\nmy_data &lt;- read.csv(\"data/patient_data.csv\")\n\n\n\n2. Interactive Selection (file.choose)\nUseful if you don‚Äôt know the exact path or want to ‚Äúbrowse‚Äù for the file.\n\n# This will open a window for you to select the file manually\nmy_data &lt;- read.csv(file.choose())\n\n\nüí° R Tip: file.choose() is great for beginners, but for formal research, typing the path (Method 1) is better because it makes your work ‚Äúreproducible‚Äù - anyone can run your script without having to click through windows.\n\n\n\n3. RStudio ‚ÄúImport Dataset‚Äù Tool\nThe easiest way for beginners. RStudio has a built-in ‚Äúpoint-and-click‚Äù importer:\n\nIn the Environment pane (top right), click Import Dataset.\nSelect From Text (base)‚Ä¶ (for CSV) or From Excel‚Ä¶.\nBrowse to your file.\nPreview the data and check the options (e.g., Heading, Separator).\nClick Import.\n\n\nüí° R Tip: When you use the Import Tool, RStudio actually runs the read.csv() or read_excel() code in the console. You should copy that code and paste it into your script so you can re-run it later!\n\n\n\nExamining the Data\nOnce imported, always check your data:\n\n# View the first few rows\nhead(my_data)\n\n# View the structure (variable names and types)\nstr(my_data)\n\n# View the entire dataset in a spreadsheet-like viewer\nView(my_data)\n\n\n\n\nReading Data from Excel Files\nTo read Excel files, you need the readxl package:\n\n# Install the package (only needed once)\ninstall.packages(\"readxl\")\n\n# Load the package (needed each session)\nlibrary(readxl)\n\n# Read an Excel file\nmy_data &lt;- read_excel(\"data_file.xlsx\")\n\n# Read a specific sheet\nmy_data &lt;- read_excel(\"data_file.xlsx\", sheet = \"Sheet1\")"
  },
  {
    "objectID": "Lectures/getting-started-with-r.html#basic-data-manipulation",
    "href": "Lectures/getting-started-with-r.html#basic-data-manipulation",
    "title": "Getting Started with R",
    "section": "Basic Data Manipulation",
    "text": "Basic Data Manipulation\n\nSubsetting Data\n\n# Create example data\npatient_data &lt;- data.frame(\n  patient_id = 1:10,\n  age = c(25, 34, 45, 56, 67, 23, 45, 56, 78, 34),\n  treatment = rep(c(\"Placebo\", \"Drug A\"), 5),\n  outcome = c(5.2, 6.8, 7.1, 5.5, 6.9, 5.0, 7.2, 6.5, 7.8, 6.2)\n)\n\n# Select specific columns\npatient_data[, c(\"patient_id\", \"age\")]\n\n   patient_id age\n1           1  25\n2           2  34\n3           3  45\n4           4  56\n5           5  67\n6           6  23\n7           7  45\n8           8  56\n9           9  78\n10         10  34\n\n# Select rows where age &gt; 40\npatient_data[patient_data$age &gt; 40, ]\n\n  patient_id age treatment outcome\n3          3  45   Placebo     7.1\n4          4  56    Drug A     5.5\n5          5  67   Placebo     6.9\n7          7  45   Placebo     7.2\n8          8  56    Drug A     6.5\n9          9  78   Placebo     7.8\n\n# Using subset() function (easier to read)\nsubset(patient_data, age &gt; 40)\n\n  patient_id age treatment outcome\n3          3  45   Placebo     7.1\n4          4  56    Drug A     5.5\n5          5  67   Placebo     6.9\n7          7  45   Placebo     7.2\n8          8  56    Drug A     6.5\n9          9  78   Placebo     7.8\n\n# Select specific columns for subset\nsubset(patient_data, age &gt; 40, select = c(patient_id, age, outcome))\n\n  patient_id age outcome\n3          3  45     7.1\n4          4  56     5.5\n5          5  67     6.9\n7          7  45     7.2\n8          8  56     6.5\n9          9  78     7.8\n\n\n\n\nCreating New Variables\n\n# Add a new column\npatient_data$age_group &lt;- ifelse(patient_data$age &gt;= 50, \"Older\", \"Younger\")\n\n# View the updated data\npatient_data\n\n   patient_id age treatment outcome age_group\n1           1  25   Placebo     5.2   Younger\n2           2  34    Drug A     6.8   Younger\n3           3  45   Placebo     7.1   Younger\n4           4  56    Drug A     5.5     Older\n5           5  67   Placebo     6.9     Older\n6           6  23    Drug A     5.0   Younger\n7           7  45   Placebo     7.2   Younger\n8           8  56    Drug A     6.5     Older\n9           9  78   Placebo     7.8     Older\n10         10  34    Drug A     6.2   Younger\n\n# Create a new variable based on calculations\npatient_data$outcome_doubled &lt;- patient_data$outcome * 2\n\npatient_data\n\n   patient_id age treatment outcome age_group outcome_doubled\n1           1  25   Placebo     5.2   Younger            10.4\n2           2  34    Drug A     6.8   Younger            13.6\n3           3  45   Placebo     7.1   Younger            14.2\n4           4  56    Drug A     5.5     Older            11.0\n5           5  67   Placebo     6.9     Older            13.8\n6           6  23    Drug A     5.0   Younger            10.0\n7           7  45   Placebo     7.2   Younger            14.4\n8           8  56    Drug A     6.5     Older            13.0\n9           9  78   Placebo     7.8     Older            15.6\n10         10  34    Drug A     6.2   Younger            12.4\n\n\n\n\nBasic Transformations\n\n# Log transformation\npatient_data$log_outcome &lt;- log(patient_data$outcome)\n\n# Standardization (z-scores)\npatient_data$outcome_z &lt;- scale(patient_data$outcome)\n\n# View results\nhead(patient_data)\n\n  patient_id age treatment outcome age_group outcome_doubled log_outcome\n1          1  25   Placebo     5.2   Younger            10.4    1.648659\n2          2  34    Drug A     6.8   Younger            13.6    1.916923\n3          3  45   Placebo     7.1   Younger            14.2    1.960095\n4          4  56    Drug A     5.5     Older            11.0    1.704748\n5          5  67   Placebo     6.9     Older            13.8    1.931521\n6          6  23    Drug A     5.0   Younger            10.0    1.609438\n   outcome_z\n1 -1.3142022\n2  0.4093417\n3  0.7325061\n4 -0.9910377\n5  0.5170632\n6 -1.5296452"
  },
  {
    "objectID": "Lectures/getting-started-with-r.html#r-packages",
    "href": "Lectures/getting-started-with-r.html#r-packages",
    "title": "Getting Started with R",
    "section": "R Packages",
    "text": "R Packages\nPackages are collections of functions that extend R‚Äôs capabilities. Think of them as apps for R.\n\nInstalling Packages\n\n# Install a package (only needed once)\ninstall.packages(\"ggplot2\")\n\n# Install multiple packages at once\ninstall.packages(c(\"ggplot2\", \"dplyr\", \"car\"))\n\n\n\nLoading Packages\n\n# Load a package (needed each time you start R)\nlibrary(ggplot2)\n\n# Alternative way to load\nrequire(ggplot2)\n\n\n\nCommonly Used Packages in This Course\n\nggplot2: Advanced data visualization\ncar: Companion to Applied Regression (for ANOVA/regression diagnostics)\nez: Easy analysis and visualization of factorial experiments\npwr: Power analysis\nreadxl: Reading Excel files\ntidyr: Data reshaping and tidying\n\n\nüí° R Tip: You only need to install a package once, but you need to load it with library() every time you start a new R session."
  },
  {
    "objectID": "Lectures/getting-started-with-r.html#getting-help",
    "href": "Lectures/getting-started-with-r.html#getting-help",
    "title": "Getting Started with R",
    "section": "Getting Help",
    "text": "Getting Help\n\nBuilt-in Help\n\n# Get help on a function\n?mean\nhelp(mean)\n\n# Search for help on a topic\n??regression\n\n# Get examples of how to use a function\nexample(mean)\n\n\n\nUnderstanding Error Messages\nDon‚Äôt panic when you see errors! They‚Äôre R‚Äôs way of telling you something needs fixing.\nCommon errors:\n\n# Error: object not found\nprint(my_variable)\n# Fix: Make sure you've created the object and spelled it correctly\n\n# Error: could not find function\nmyfunction()\n# Fix: Check spelling, or load the package that contains the function\n\n# Error: unexpected symbol\nx &lt; - 5  # Space in assignment operator\n# Fix: Remove the space: x &lt;- 5\n\n\n\nOnline Resources\n\nRStudio Cheat Sheets: https://posit.co/resources/cheatsheets/\nStack Overflow: Search for R questions and answers\nR Documentation: https://www.rdocumentation.org/\nQuick-R: https://www.statmethods.net/"
  },
  {
    "objectID": "Lectures/getting-started-with-r.html#best-practices",
    "href": "Lectures/getting-started-with-r.html#best-practices",
    "title": "Getting Started with R",
    "section": "Best Practices",
    "text": "Best Practices\n\n1. Comment Your Code\nUse # to add comments explaining what your code does:\n\n# Calculate the mean age of patients\nmean_age &lt;- mean(patient_data$age)\n\n# This is a comment - R ignores everything after #\n\n\n\n2. Use Meaningful Names\n\n# Good\npatient_age &lt;- 45\ntreatment_group &lt;- \"Drug A\"\n\n# Not as good\nx &lt;- 45\ntg &lt;- \"Drug A\"\n\n\n\n3. Organize Your Scripts\n\n# ============================================\n# Project: Blood Pressure Study\n# Author: Your Name\n# Date: 2026-01-05\n# ============================================\n\n# Load packages\nlibrary(ggplot2)\nlibrary(car)\n\n# Read data\nbp_data &lt;- read.csv(\"blood_pressure.csv\")\n\n# Data cleaning\n# ... your code ...\n\n# Analysis\n# ... your code ...\n\n# Visualization\n# ... your code ...\n\n\n\n4. Save Your Work\n\nSave your R scripts (File ‚Üí Save) with a .R extension\nSave your data frames if needed:\n\n\n# Save data frame as CSV\nwrite.csv(patient_data, \"cleaned_data.csv\", row.names = FALSE)\n\n# Save R objects\nsave(patient_data, file = \"my_data.RData\")\n\n# Load saved R objects\nload(\"my_data.RData\")"
  },
  {
    "objectID": "Lectures/getting-started-with-r.html#comprehensive-example-complete-data-analysis-workflow",
    "href": "Lectures/getting-started-with-r.html#comprehensive-example-complete-data-analysis-workflow",
    "title": "Getting Started with R",
    "section": "Comprehensive Example: Complete Data Analysis Workflow",
    "text": "Comprehensive Example: Complete Data Analysis Workflow\nLet‚Äôs put it all together with a complete example:\n\n# ============================================\n# Example: Analyzing Patient Recovery Times\n# ============================================\n\n# Step 1: Create sample data (normally you'd read this from a file)\nrecovery_data &lt;- data.frame(\n  patient_id = 1:30,\n  age = c(45, 52, 38, 61, 49, 55, 42, 58, 47, 53,\n          39, 44, 56, 50, 43, 59, 48, 51, 46, 54,\n          41, 57, 62, 40, 60, 37, 63, 36, 64, 35),\n  treatment = rep(c(\"Standard\", \"Enhanced\", \"Intensive\"), each = 10),\n  recovery_days = c(12, 15, 10, 18, 14, 16, 11, 17, 13, 15,\n                    9, 11, 8, 12, 10, 13, 9, 11, 10, 12,\n                    7, 9, 6, 8, 7, 9, 6, 8, 7, 8)\n)\n\n# Step 2: Examine the data\nprint(\"First few rows:\")\n\n[1] \"First few rows:\"\n\nhead(recovery_data)\n\n  patient_id age treatment recovery_days\n1          1  45  Standard            12\n2          2  52  Standard            15\n3          3  38  Standard            10\n4          4  61  Standard            18\n5          5  49  Standard            14\n6          6  55  Standard            16\n\nprint(\"\\nData structure:\")\n\n[1] \"\\nData structure:\"\n\nstr(recovery_data)\n\n'data.frame':   30 obs. of  4 variables:\n $ patient_id   : int  1 2 3 4 5 6 7 8 9 10 ...\n $ age          : num  45 52 38 61 49 55 42 58 47 53 ...\n $ treatment    : chr  \"Standard\" \"Standard\" \"Standard\" \"Standard\" ...\n $ recovery_days: num  12 15 10 18 14 16 11 17 13 15 ...\n\nprint(\"\\nSummary statistics:\")\n\n[1] \"\\nSummary statistics:\"\n\nsummary(recovery_data)\n\n   patient_id         age         treatment         recovery_days  \n Min.   : 1.00   Min.   :35.00   Length:30          Min.   : 6.00  \n 1st Qu.: 8.25   1st Qu.:42.25   Class :character   1st Qu.: 8.00  \n Median :15.50   Median :49.50   Mode  :character   Median :10.00  \n Mean   :15.50   Mean   :49.50                      Mean   :10.70  \n 3rd Qu.:22.75   3rd Qu.:56.75                      3rd Qu.:12.75  \n Max.   :30.00   Max.   :64.00                      Max.   :18.00  \n\n# Step 3: Basic descriptive statistics by group\nprint(\"\\nMean recovery days by treatment:\")\n\n[1] \"\\nMean recovery days by treatment:\"\n\ntapply(recovery_data$recovery_days, recovery_data$treatment, mean)\n\n Enhanced Intensive  Standard \n     10.5       7.5      14.1 \n\nprint(\"\\nStandard deviation by treatment:\")\n\n[1] \"\\nStandard deviation by treatment:\"\n\ntapply(recovery_data$recovery_days, recovery_data$treatment, sd)\n\n Enhanced Intensive  Standard \n 1.581139  1.080123  2.601282 \n\n# Step 4: Create a new variable (age group)\nrecovery_data$age_group &lt;- ifelse(recovery_data$age &gt;= 50, \"50+\", \"Under 50\")\n\n# Step 5: Create a simple visualization\nboxplot(recovery_days ~ treatment, \n        data = recovery_data,\n        main = \"Recovery Days by Treatment\",\n        xlab = \"Treatment Type\",\n        ylab = \"Recovery Days\",\n        col = c(\"lightblue\", \"lightgreen\", \"lightcoral\"))\n\n\n\n\n\n\n\n# For more advanced visualizations, see the [Graphing Your Data](graphing-your-data.qmd) lecture.\n\n# Step 6: Basic statistical test (we'll learn more about this later)\n# ANOVA to test if recovery days differ by treatment\n# Learn more in the [Introduction to ANOVA](introduction-to-anova.qmd) lecture.\nanova_result &lt;- aov(recovery_days ~ treatment, data = recovery_data)\nprint(\"\\nANOVA Results:\")\n\n[1] \"\\nANOVA Results:\"\n\nsummary(anova_result)\n\n            Df Sum Sq Mean Sq F value Pr(&gt;F)    \ntreatment    2  218.4  109.20    31.4  9e-08 ***\nResiduals   27   93.9    3.48                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Step 7: Save the cleaned data (if this were a real analysis)\n# write.csv(recovery_data, \"recovery_data_cleaned.csv\", row.names = FALSE)"
  },
  {
    "objectID": "Lectures/getting-started-with-r.html#summary",
    "href": "Lectures/getting-started-with-r.html#summary",
    "title": "Getting Started with R",
    "section": "Summary",
    "text": "Summary\nYou now know how to:\n‚úÖ Install R and RStudio\n‚úÖ Navigate the RStudio interface\n‚úÖ Understand basic R syntax and data types\n‚úÖ Create and manipulate vectors and data frames\n‚úÖ Read data from CSV and Excel files\n‚úÖ Perform basic data manipulation\n‚úÖ Install and load packages\n‚úÖ Get help when you need it\n‚úÖ Follow best practices for reproducible research"
  },
  {
    "objectID": "Lectures/getting-started-with-r.html#next-steps",
    "href": "Lectures/getting-started-with-r.html#next-steps",
    "title": "Getting Started with R",
    "section": "Next Steps",
    "text": "Next Steps\nNow that you‚Äôre familiar with R basics, you‚Äôre ready to move on to the statistical methods covered in this course. Each lecture will build on these foundations, showing you how to use R for specific analyses.\n\nüí° R Tip: Don‚Äôt try to memorize everything! Keep this guide handy as a reference. The more you practice, the more natural R will become.\n\nHappy coding! üéâ"
  },
  {
    "objectID": "Lectures/introduction-to-ancova.html",
    "href": "Lectures/introduction-to-ancova.html",
    "title": "Introduction to ANCOVA",
    "section": "",
    "text": "Download R Code for this Lecture\n\nUnderstanding Hypothesis Testing and ANCOVA\n\nDefinition and Purpose of ANCOVA\nAnalysis of Covariance (ANCOVA) is a statistical method that combines ANOVA and regression. It assesses the main and interaction effects of categorical variables on a continuous outcome while controlling for the influence of one or more continuous covariates.\n\n\nKey Differences Between ANCOVA and ANOVA\n\nANOVA examines differences in means between groups without adjusting for other variables.\nANCOVA adjusts group means to account for the effect of covariates.\n\n\n\nAssumptions of ANCOVA\n\nThe dependent variable is measured on an interval or ratio scale.\nThe independent variable is categorical.\nCovariates are measured on an interval or ratio scale.\nRandom sampling.\nNormal distribution of the dependent variable.\nHomogeneity of variance.\nHomogeneity of regression slopes between groups.\n\n\n\nIndependent Variables and Covariates\n\nIndependent Variables: Categorical factors of interest.\nCovariates: Continuous variables used to adjust the dependent variable.\n\n\n\nVisualizing ANCOVA\nVisualizing ANCOVA often involves making line plots to show the trajectory of the independent variable (x-axis) and dependent variable (y-axis) by group (color). One of the assumptions of an ANCOVA is ‚ÄúHomogeneity of regression slopes between groups‚Äù. As we can see in this graph, there doesn‚Äôt seem to be graphical evidence for that. Use scatter plots to visualize the relationship between the predictor and outcome variables. For more on creating these visualizations in R, see the Graphing Your Data lecture.\n\n\nWarning: package 'ggplot2' was built under R version 4.5.2\n\n\n\n\n\n\n\n\n\nAs we can see here, this example shows slopes that are much more similar. Thats good because if we are going to use ANCOVA, we are assuming they are the same or atleast very similar.\n\n\n\n\n\n\n\n\n\n\n# Example visualization in R\n        library(ggplot2)\n\n        data &lt;- data.frame(\n          group = rep(c(\"Placebo\", \"Behavioral\", \"Drug\"), each = 10),\n          pre_stress = rnorm(30, 5, 1),\n          post_stress = c(rnorm(10, 5, 1), rnorm(10, 7, 1), rnorm(10, 6, 1))\n        )\n\n        # Interaction plot\n        ggplot(data, aes(x = pre_stress, y = post_stress, color = group)) +\n          geom_point() +\n          geom_smooth(method = \"lm\", se = FALSE) +\n          labs(title = \"Interaction Plot\", x = \"Pre-Stress Score\", y = \"Post-Stress Score\")\n\n\n\nCalculation of Adjusted Means\nAdjusted means, or least-squares means, are averages that account for the influence of covariates. They are particularly useful in analyses like ANCOVA to provide unbiased comparisons across groups by removing the effects of nuisance variables. This adjustment ensures that the differences between groups reflect the effect of the primary variables of interest, not the covariates. Thus, adjusted means enable a fair comparison of group differences after controlling for external influences.\n\n# Adjusted means in R\n        library(car)\n        model &lt;- lm(post_stress ~ group + pre_stress, data = data)\n        Anova(model, type = 3)\n        lsmeans &lt;- emmeans::emmeans(model, \"group\")\n        print(lsmeans)\n\n\n\nTesting Main Effects and Investigating the Interaction\nTesting main effects reveals the individual impact of each independent and covariate variable on the outcome. Investigating interaction effects uncovers how combinations of these variables jointly influence the outcome. Together, they provide a comprehensive understanding of the relationships within the data, guiding more accurate interpretations and conclusions about our ANCOVA result.\n\nMain Effects: The impact of each independent and covariate variable on the outcome.\nInteraction Effects: How combinations of independent and covariate variables influence the outcome.\n\n\n# Testing main effects and interaction in R\n        model &lt;- lm(post_stress ~ group * pre_stress, data = data)\n        Anova(model, type = 3)\n\n\n\nEffect Sizes and Significance, F Test, SSC, SSB, SSW, P-value\n\nF Test: Determines if group means are significantly different.\nSSB (Sum of Squares Between): Measures variation between groups.\nSSC (Sum of Squares Covariate): Measures the variation explained by the covariate.\nSSW (Sum of Squares Within): Measures variation within groups.\nP-value: Indicates statistical significance.\n\n\n# Effect sizes and significance in R\n        model &lt;- lm(post_stress ~ group + pre_stress, data = data)\n        Anova(model, type = 3)\n\n\n\nExamples of ANCOVA in Nursing Research\n\nPatient Recovery Rates: Comparing patient recovery rates across different treatment groups while controlling for age and baseline health status.\nStress Reduction Programs: Evaluating the effectiveness of stress reduction programs while controlling for initial stress levels.\n\n\n\nHands-on Example: Interpreting Your Results\ndownload ex. 1 data (CSV)\n\n# Example ANCOVA in R\n        model &lt;- lm(post_stress ~ group + pre_stress, data = data)\n        summary(model)\n        Anova(model, type = 3)"
  },
  {
    "objectID": "Lectures/introduction-to-logistic-regression.html",
    "href": "Lectures/introduction-to-logistic-regression.html",
    "title": "Introduction to Logistic Regression",
    "section": "",
    "text": "Download R Code for this Lecture"
  },
  {
    "objectID": "Lectures/introduction-to-logistic-regression.html#introduction",
    "href": "Lectures/introduction-to-logistic-regression.html#introduction",
    "title": "Introduction to Logistic Regression",
    "section": "Introduction",
    "text": "Introduction\nLogistic regression is a fundamental statistical method used to model the relationship between a dependent variable (often binary) and one or more independent variables. It is particularly useful in healthcare and nursing research to understand the influence of various factors on patient outcomes."
  },
  {
    "objectID": "Lectures/introduction-to-logistic-regression.html#objectives",
    "href": "Lectures/introduction-to-logistic-regression.html#objectives",
    "title": "Introduction to Logistic Regression",
    "section": "Objectives",
    "text": "Objectives\n\nUnderstand the fundamentals of logistic regression.\nLearn the key differences between logistic and linear regression.\nExplore the logistic function and its interpretation.\nCalculate and interpret odds ratios.\nFormulate the logistic regression equation using maximum likelihood estimation (MLE).\nEstimate and test the significance of the regression coefficients.\nExplore goodness-of-fit tests and the Hosmer-Lemeshow test.\nLearn about stepwise logistic regression.\nCheck assumptions and assess multicollinearity.\nProvide examples in JMP, R, Python, SPSS, and Stata."
  },
  {
    "objectID": "Lectures/introduction-to-logistic-regression.html#definition-and-purpose-of-logistic-regression",
    "href": "Lectures/introduction-to-logistic-regression.html#definition-and-purpose-of-logistic-regression",
    "title": "Introduction to Logistic Regression",
    "section": "Definition and Purpose of Logistic Regression",
    "text": "Definition and Purpose of Logistic Regression\nLogistic regression is used to predict the probability of a binary outcome (e.g., success/failure, disease/no disease) based on one or more predictor variables. It helps in answering questions like: - What are the chances that a patient has diabetes given their age, BMI, and family history? - How likely is a patient to respond to a specific treatment based on their health metrics?"
  },
  {
    "objectID": "Lectures/introduction-to-logistic-regression.html#key-differences-between-logistic-regression-and-linear-regression",
    "href": "Lectures/introduction-to-logistic-regression.html#key-differences-between-logistic-regression-and-linear-regression",
    "title": "Introduction to Logistic Regression",
    "section": "Key Differences Between Logistic Regression and Linear Regression",
    "text": "Key Differences Between Logistic Regression and Linear Regression\n\nOutcome Variable: Logistic regression deals with binary outcomes, while linear regression handles continuous outcomes.\nPrediction Interpretation: Logistic regression outputs probabilities (between 0 and 1) instead of continuous values.\nModel Fit Measure: Logistic regression uses likelihood-based measures like deviance, while linear regression relies on metrics like R-squared."
  },
  {
    "objectID": "Lectures/introduction-to-logistic-regression.html#understanding-the-logistic-function-and-its-interpretation",
    "href": "Lectures/introduction-to-logistic-regression.html#understanding-the-logistic-function-and-its-interpretation",
    "title": "Introduction to Logistic Regression",
    "section": "Understanding the Logistic Function and Its Interpretation",
    "text": "Understanding the Logistic Function and Its Interpretation\nThe logistic function transforms a linear combination of predictors into probabilities:\n\\[ p = \\frac{e^{\\beta_0 + \\beta_1X_1 + \\cdots + \\beta_kX_k}}{1 + e^{\\beta_0 + \\beta_1X_1 + \\cdots + \\beta_kX_k}} \\]\nwhere ( p ) is the predicted probability, and ( _i ) are the regression coefficients.\nThe log-odds (logit) transformation:\n\\[ \\log\\left(\\frac{p}{1 - p}\\right) = \\beta_0 + \\beta_1X_1 + \\cdots + \\beta_kX_k \\]"
  },
  {
    "objectID": "Lectures/introduction-to-logistic-regression.html#calculation-and-interpretation-of-odds-ratios",
    "href": "Lectures/introduction-to-logistic-regression.html#calculation-and-interpretation-of-odds-ratios",
    "title": "Introduction to Logistic Regression",
    "section": "Calculation and Interpretation of Odds Ratios",
    "text": "Calculation and Interpretation of Odds Ratios\nAn odds ratio (OR) is a measure of association between an exposure and an outcome. It is interpreted as the odds of the outcome occurring given the presence of a particular predictor.\n\\[ \\text{OR} = \\exp(\\beta_i) \\]\n\nOR &gt; 1: Positive association between predictor and outcome.\nOR &lt; 1: Negative association between predictor and outcome.\nOR = 1: No association."
  },
  {
    "objectID": "Lectures/introduction-to-logistic-regression.html#formulating-the-logistic-regression-equation-maximum-likelihood-estimation-mle",
    "href": "Lectures/introduction-to-logistic-regression.html#formulating-the-logistic-regression-equation-maximum-likelihood-estimation-mle",
    "title": "Introduction to Logistic Regression",
    "section": "Formulating the Logistic Regression Equation; Maximum Likelihood Estimation (MLE)",
    "text": "Formulating the Logistic Regression Equation; Maximum Likelihood Estimation (MLE)\n\nModel Specification: \\[ \\log\\left(\\frac{p}{1 - p}\\right) = \\beta_0 + \\beta_1X_1 + \\cdots + \\beta_kX_k \\]\nMaximum Likelihood Estimation (MLE): The logistic regression coefficients are estimated by maximizing the likelihood function: \\[ L(\\beta) = \\prod_{i=1}^{n} p_i^{y_i} (1 - p_i)^{1 - y_i} \\] where ( p_i ) is the predicted probability for the ( i )-th observation."
  },
  {
    "objectID": "Lectures/introduction-to-logistic-regression.html#estimating-the-regression-coefficients",
    "href": "Lectures/introduction-to-logistic-regression.html#estimating-the-regression-coefficients",
    "title": "Introduction to Logistic Regression",
    "section": "Estimating the Regression Coefficients",
    "text": "Estimating the Regression Coefficients\nThe coefficients are estimated using MLE. Most statistical software provides direct estimation."
  },
  {
    "objectID": "Lectures/introduction-to-logistic-regression.html#testing-the-significance-of-the-regression-coefficients",
    "href": "Lectures/introduction-to-logistic-regression.html#testing-the-significance-of-the-regression-coefficients",
    "title": "Introduction to Logistic Regression",
    "section": "Testing the Significance of the Regression Coefficients",
    "text": "Testing the Significance of the Regression Coefficients\n\nWald Test: Tests individual coefficients.\nLikelihood Ratio Test: Compares nested models.\nScore Test: Similar to the likelihood ratio test."
  },
  {
    "objectID": "Lectures/introduction-to-logistic-regression.html#confidence-intervals-for-the-coefficients",
    "href": "Lectures/introduction-to-logistic-regression.html#confidence-intervals-for-the-coefficients",
    "title": "Introduction to Logistic Regression",
    "section": "Confidence Intervals for the Coefficients",
    "text": "Confidence Intervals for the Coefficients\nConfidence intervals provide a range of plausible values for the coefficients.\n\\[ CI = \\hat{\\beta_i} \\pm z^* \\cdot SE(\\hat{\\beta_i}) \\]"
  },
  {
    "objectID": "Lectures/introduction-to-logistic-regression.html#deviance-and-goodness-of-fit-tests",
    "href": "Lectures/introduction-to-logistic-regression.html#deviance-and-goodness-of-fit-tests",
    "title": "Introduction to Logistic Regression",
    "section": "Deviance and Goodness-of-Fit Tests",
    "text": "Deviance and Goodness-of-Fit Tests\n\nDeviance: Measure of model fit, similar to residual sum of squares.\nLikelihood Ratio Test (Chi-Square): Compares the deviance of nested models.\nHosmer-Lemeshow Test: Assesses model calibration."
  },
  {
    "objectID": "Lectures/introduction-to-logistic-regression.html#interpretation-of-regression-coefficients-understanding-the-impact-of-predictors-on-odds",
    "href": "Lectures/introduction-to-logistic-regression.html#interpretation-of-regression-coefficients-understanding-the-impact-of-predictors-on-odds",
    "title": "Introduction to Logistic Regression",
    "section": "Interpretation of Regression Coefficients; Understanding the Impact of Predictors on Odds",
    "text": "Interpretation of Regression Coefficients; Understanding the Impact of Predictors on Odds\n\nExample\nAssume a logistic regression model predicting diabetes (yes/no) based on age and BMI:\n\\[ \\log\\left(\\frac{p}{1 - p}\\right) = -5 + 0.05 \\cdot \\text{Age} + 0.2 \\cdot \\text{BMI} \\]\nInterpretation: - Intercept (-5): Baseline log-odds of diabetes for a patient with Age = 0 and BMI = 0. - Age Coefficient (0.05): For each one-year increase in age, the odds of diabetes increase by ( e^{0.05} ) times. - BMI Coefficient (0.2): For each unit increase in BMI, the odds of diabetes increase by ( e^{0.2} ) times."
  },
  {
    "objectID": "Lectures/introduction-to-logistic-regression.html#stepwise-logistic-regression",
    "href": "Lectures/introduction-to-logistic-regression.html#stepwise-logistic-regression",
    "title": "Introduction to Logistic Regression",
    "section": "Stepwise Logistic Regression",
    "text": "Stepwise Logistic Regression\nStepwise logistic regression involves automatic selection of predictors based on criteria like AIC, BIC, or p-values.\n\nForward Selection: Starts with no variables and adds one at a time.\nBackward Elimination: Starts with all variables and removes one at a time.\nBidirectional Elimination: Combines forward and backward methods."
  },
  {
    "objectID": "Lectures/introduction-to-logistic-regression.html#interpreting-odds-ratios-for-categorical-and-continuous-predictors",
    "href": "Lectures/introduction-to-logistic-regression.html#interpreting-odds-ratios-for-categorical-and-continuous-predictors",
    "title": "Introduction to Logistic Regression",
    "section": "Interpreting Odds Ratios for Categorical and Continuous Predictors",
    "text": "Interpreting Odds Ratios for Categorical and Continuous Predictors\n\nCategorical Predictors: Interpret the OR relative to the reference category.\nContinuous Predictors: Interpret the OR per unit increase in the predictor."
  },
  {
    "objectID": "Lectures/introduction-to-logistic-regression.html#checking-assumptions-of-logistic-regression",
    "href": "Lectures/introduction-to-logistic-regression.html#checking-assumptions-of-logistic-regression",
    "title": "Introduction to Logistic Regression",
    "section": "Checking Assumptions of Logistic Regression",
    "text": "Checking Assumptions of Logistic Regression\n\nLinearity in Logit: Ensure continuous predictors are linearly related to the logit.\nAbsence of Multicollinearity: Check variance inflation factors (VIF).\nNo Outliers/Influential Observations: Use Cook‚Äôs distance or leverage plots."
  },
  {
    "objectID": "Lectures/introduction-to-logistic-regression.html#examples-of-logistic-regression-in-nursing-research",
    "href": "Lectures/introduction-to-logistic-regression.html#examples-of-logistic-regression-in-nursing-research",
    "title": "Introduction to Logistic Regression",
    "section": "Examples of Logistic Regression in Nursing Research",
    "text": "Examples of Logistic Regression in Nursing Research\n\nExample 1: Predicting Diabetes\n\n# Logistic Regression in R\n        data &lt;- read.csv(\"health_data.csv\")\n        model &lt;- glm(Diabetes ~ Age + BMI, data = data, family = \"binomial\")\n        summary(model)\n\n\n\nExample 2: Predicting Heart Disease\n\n# Logistic Regression in R\n        data &lt;- read.csv(\"heart_data.csv\")\n        model &lt;- glm(HeartDisease ~ Age + Cholesterol + Smoking, data = data, family = \"binomial\")\n        summary(model)"
  },
  {
    "objectID": "Lectures/introduction-to-logistic-regression.html#conclusion",
    "href": "Lectures/introduction-to-logistic-regression.html#conclusion",
    "title": "Introduction to Logistic Regression",
    "section": "Conclusion",
    "text": "Conclusion\nLogistic regression is a crucial tool in healthcare research, providing insights into the relationship between various factors and patient outcomes. Understanding how to interpret coefficients and use different software to fit logistic regression models enables effective decision-making and research."
  },
  {
    "objectID": "Lectures/introduction-to-repeated-measures-anova.html",
    "href": "Lectures/introduction-to-repeated-measures-anova.html",
    "title": "Introduction to Repeated Measures ANOVA",
    "section": "",
    "text": "Download R Code for this Lecture"
  },
  {
    "objectID": "Lectures/introduction-to-repeated-measures-anova.html#objectives",
    "href": "Lectures/introduction-to-repeated-measures-anova.html#objectives",
    "title": "Introduction to Repeated Measures ANOVA",
    "section": "Objectives",
    "text": "Objectives\n\nUnderstand the fundamentals of Repeated Measures ANOVA\nLearn the definition and purpose of Repeated Measures ANOVA\nIdentify the key differences between Repeated Measures ANOVA and One-Way ANOVA\nUnderstand the structure of a Repeated Measures design\nRecognize within-subjects factors and levels\nComprehend the sphericity assumption\nUnderstand the Greenhouse-Geisser correction\nCalculate Sum of Squares (SS) and Mean Squares (MS)\nConduct hypothesis testing for main effects and interaction\nMeasure effect sizes and significance\nInterpret main effects and interaction\nApply the Bonferroni correction\nCheck the assumptions of Repeated Measures ANOVA\nExplore examples of Repeated Measures ANOVA in nursing research"
  },
  {
    "objectID": "Lectures/introduction-to-repeated-measures-anova.html#definition-and-purpose-of-repeated-measures-anova",
    "href": "Lectures/introduction-to-repeated-measures-anova.html#definition-and-purpose-of-repeated-measures-anova",
    "title": "Introduction to Repeated Measures ANOVA",
    "section": "Definition and Purpose of Repeated Measures ANOVA",
    "text": "Definition and Purpose of Repeated Measures ANOVA\nRepeated Measures ANOVA is a statistical test used to examine the changes in a continuous dependent variable across multiple measurements over time or under different conditions. It is an extension of One-Way ANOVA but accounts for the correlation between repeated measures on the same subjects.\n\nKey Differences Between Repeated Measures ANOVA and One-Way ANOVA\n\nOne-Way ANOVA: Evaluates the effect of a single independent variable on a continuous outcome.\nRepeated Measures ANOVA: Evaluates the effect of a single or multiple within-subject factors over time, accounting for the correlation between repeated measurements."
  },
  {
    "objectID": "Lectures/introduction-to-repeated-measures-anova.html#understanding-the-structure-of-a-repeated-measures-design",
    "href": "Lectures/introduction-to-repeated-measures-anova.html#understanding-the-structure-of-a-repeated-measures-design",
    "title": "Introduction to Repeated Measures ANOVA",
    "section": "Understanding the Structure of a Repeated Measures Design",
    "text": "Understanding the Structure of a Repeated Measures Design\nIn a Repeated Measures design, each participant is measured multiple times under different conditions or over time. The design includes: - Within-Subjects Factors: Variables measured repeatedly on the same subjects. - Levels: The different conditions or time points for each within-subjects factor.\n\nExample Structure\n\nWithin-Subjects Factor: Time\nLevels: Baseline, Week 1, Week 2, Week 3"
  },
  {
    "objectID": "Lectures/introduction-to-repeated-measures-anova.html#sphericity-assumption",
    "href": "Lectures/introduction-to-repeated-measures-anova.html#sphericity-assumption",
    "title": "Introduction to Repeated Measures ANOVA",
    "section": "Sphericity Assumption",
    "text": "Sphericity Assumption\nSphericity refers to the assumption that the variances of the differences between all combinations of related groups are equal. If violated, it can lead to biased F-statistics and increased Type I errors.\n\nGreenhouse-Geisser Correction\nThe Greenhouse-Geisser correction adjusts the degrees of freedom to correct for violations of sphericity, providing a more conservative estimate."
  },
  {
    "objectID": "Lectures/introduction-to-repeated-measures-anova.html#calculation-of-ss-sum-of-squares-and-ms-mean-squares",
    "href": "Lectures/introduction-to-repeated-measures-anova.html#calculation-of-ss-sum-of-squares-and-ms-mean-squares",
    "title": "Introduction to Repeated Measures ANOVA",
    "section": "Calculation of SS (Sum of Squares) and MS (Mean Squares)",
    "text": "Calculation of SS (Sum of Squares) and MS (Mean Squares)\n\nSum of Squares\n\nTotal Sum of Squares (SST): \\[\nSST = \\sum_{i=1}^{n} \\sum_{j=1}^{t} (Y_{ij} - \\bar{Y})^2\n\\] where ( Y_{ij} ) is each individual observation, and ( {Y} ) is the overall mean.\nSum of Squares Within (SSW): \\[\nSSW = \\sum_{i=1}^{n} \\sum_{j=1}^{t} (Y_{ij} - \\bar{Y}_{i\\cdot})^2\n\\] where ( {Y}_{i} ) is the mean of all measurements for subject ( i ).\nSum of Squares Between (SSB): \\[\nSSB = \\sum_{j=1}^{t} n_j (\\bar{Y}_{\\cdot j} - \\bar{Y})^2\n\\] where ( {Y}_{j} ) is the mean for level ( j ), and ( n_j ) is the number of observations at level ( j ).\n\n\n\nMean Squares\n\nMean Square Within (MSW): \\[\nMSW = \\frac{SSW}{(n - 1)(t - 1)}\n\\]\nMean Square Between (MSB): \\[\nMSB = \\frac{SSB}{t - 1}\n\\]"
  },
  {
    "objectID": "Lectures/introduction-to-repeated-measures-anova.html#hypothesis-testing-for-main-effects-and-interaction",
    "href": "Lectures/introduction-to-repeated-measures-anova.html#hypothesis-testing-for-main-effects-and-interaction",
    "title": "Introduction to Repeated Measures ANOVA",
    "section": "Hypothesis Testing for Main Effects and Interaction",
    "text": "Hypothesis Testing for Main Effects and Interaction\n\nHypotheses\n\nMain Effect of Within-Subjects Factor:\n\nNull Hypothesis (( H_0 )): No difference in the means across levels.\nAlternative Hypothesis (( H_1 )): At least one level has a different mean.\n\nInteraction Effect:\n\nNull Hypothesis (( H_0 )): No interaction between within-subjects factors.\nAlternative Hypothesis (( H_1 )): An interaction exists between factors.\n\n\n\n\nF-Ratio Calculations\n\nMain Effect of Within-Subjects Factor: \\[\nF = \\frac{MSB}{MSW}\n\\]\n\n\n\nInterpretation\n\nCompare the F-ratio to the critical value from the F-distribution.\nIf the calculated F-ratio is greater than the critical value, reject the null hypothesis."
  },
  {
    "objectID": "Lectures/introduction-to-repeated-measures-anova.html#effect-sizes-and-significance",
    "href": "Lectures/introduction-to-repeated-measures-anova.html#effect-sizes-and-significance",
    "title": "Introduction to Repeated Measures ANOVA",
    "section": "Effect Sizes and Significance",
    "text": "Effect Sizes and Significance\n\nEta Squared (( ^2 ))\nRepresents the proportion of the total variance explained by the within-subjects factor.\n\nWithin-Subjects Factor: \\[\n\\eta^2 = \\frac{SSB}{SST}\n\\]"
  },
  {
    "objectID": "Lectures/introduction-to-repeated-measures-anova.html#bonferroni-correction",
    "href": "Lectures/introduction-to-repeated-measures-anova.html#bonferroni-correction",
    "title": "Introduction to Repeated Measures ANOVA",
    "section": "Bonferroni Correction",
    "text": "Bonferroni Correction\nA post-hoc correction used to reduce Type I errors when multiple comparisons are made. When conducting multiple tests, the risk of a false positive (Type I error) increases significantly. For a detailed explanation of why this happens, see the section on The Problem of Multiple Comparisons in the ANOVA lecture.\n\nFormula\n\\[\n\\alpha_{\\text{corrected}} = \\frac{\\alpha}{m}\n\\] where ( m ) is the number of comparisons."
  },
  {
    "objectID": "Lectures/introduction-to-repeated-measures-anova.html#checking-assumptions-of-repeated-measures-anova",
    "href": "Lectures/introduction-to-repeated-measures-anova.html#checking-assumptions-of-repeated-measures-anova",
    "title": "Introduction to Repeated Measures ANOVA",
    "section": "Checking Assumptions of Repeated Measures ANOVA",
    "text": "Checking Assumptions of Repeated Measures ANOVA\n\nSphericity\n\nUse Mauchly‚Äôs test to check the assumption of sphericity.\n\n\n\nNormality\n\nUse Q-Q plots to check the normality of residuals.\n\n\n\nHomogeneity of Variances\n\nEnsure variances are approximately equal across conditions."
  },
  {
    "objectID": "Lectures/introduction-to-repeated-measures-anova.html#examples-of-repeated-measures-anova-in-nursing-research",
    "href": "Lectures/introduction-to-repeated-measures-anova.html#examples-of-repeated-measures-anova-in-nursing-research",
    "title": "Introduction to Repeated Measures ANOVA",
    "section": "Examples of Repeated Measures ANOVA in Nursing Research",
    "text": "Examples of Repeated Measures ANOVA in Nursing Research\n\nExample 1: Evaluating Blood Pressure Changes Over Time\n\nResearch Question: How does blood pressure change over a 3-week intervention period?\nWithin-Subjects Factor: Time\nLevels: Baseline, Week 1, Week 3\nResponse Variable: Blood Pressure\n\ndownload example data (CSV)\n\n# Example in R\n# Simulated data\nset.seed(123)\ndata &lt;- data.frame(\n  Subject = rep(1:20, each = 3),\n  Time = factor(rep(c(\"Baseline\", \"Week1\", \"Week3\"), times = 20)),\n  BP = rnorm(60, mean = rep(c(120, 115, 110), each = 20), sd = 10)\n)\n\n# Repeated Measures ANOVA\ninstall.packages(\"ez\")\nlibrary(ez)\nanova_results &lt;- ezANOVA(\n  data = data,\n  dv = BP,\n  wid = Subject,\n  within = Time\n)\nprint(anova_results)\n\n\n\nExample 2: Evaluating Cognitive Function Changes Over Multiple Sessions\n\nResearch Question: How does cognitive function change across four training sessions?\nWithin-Subjects Factor: Session\nLevels: Session 1, Session 2, Session 3, Session 4\nResponse Variable: Cognitive Function Score\n\ndownload example 2 data (CSV)\n\n# Example in R\n# Simulated data\nset.seed(456)\ndata2 &lt;- data.frame(\n  Subject = rep(1:15, each = 4),\n  Session = factor(rep(c(\"Session1\", \"Session2\", \"Session3\", \"Session4\"), times = 15)),\n  Score = rnorm(60, mean = rep(c(80, 85, 90, 95), each = 15), sd = 5)\n)\n\n# Repeated Measures ANOVA\nlibrary(ez)\nanova_results2 &lt;- ezANOVA(\n  data = data2,\n  dv = Score,\n  wid = Subject,\n  within = Session\n)\nprint(anova_results2)"
  },
  {
    "objectID": "Lectures/introduction-to-two-way-anova.html",
    "href": "Lectures/introduction-to-two-way-anova.html",
    "title": "Introduction to Two-Way ANOVA",
    "section": "",
    "text": "Download R Code for this Lecture"
  },
  {
    "objectID": "Lectures/introduction-to-two-way-anova.html#objectives",
    "href": "Lectures/introduction-to-two-way-anova.html#objectives",
    "title": "Introduction to Two-Way ANOVA",
    "section": "Objectives",
    "text": "Objectives\n\nUnderstand the fundamentals of Two-Way ANOVA\nLearn the definition and purpose of Two-Way ANOVA\nIdentify the key differences between One-Way ANOVA and Two-Way ANOVA\nUnderstand the structure of a Two-Way ANOVA design\nRecognize main effects and interaction\nComprehend the assumptions of Two-Way ANOVA\nCalculate Sum of Squares (SS) and Mean Squares (MS)\nConduct hypothesis testing for main effects and interaction\nMeasure effect sizes and significance\nInterpret main effects and interaction\nConduct post-hoc analysis\nIdentify outliers and influential observations, normality, and homogeneity\nExplore examples of Two-Way ANOVA in nursing research"
  },
  {
    "objectID": "Lectures/introduction-to-two-way-anova.html#definition-and-purpose-of-two-way-anova",
    "href": "Lectures/introduction-to-two-way-anova.html#definition-and-purpose-of-two-way-anova",
    "title": "Introduction to Two-Way ANOVA",
    "section": "Definition and Purpose of Two-Way ANOVA",
    "text": "Definition and Purpose of Two-Way ANOVA\nTwo-Way ANOVA is a statistical test used to examine the impact of two independent variables on a continuous dependent variable. It is an extension of One-Way ANOVA but allows for the simultaneous evaluation of two factors, making it suitable for analyzing more complex experimental designs.\n\nKey Differences Between One-Way and Two-Way ANOVA\n\nOne-Way ANOVA: Evaluates the effect of a single independent variable on a continuous outcome.\nTwo-Way ANOVA: Evaluates the effects of two independent variables (factors), including any interaction between them."
  },
  {
    "objectID": "Lectures/introduction-to-two-way-anova.html#understanding-the-structure-of-a-two-way-anova-design",
    "href": "Lectures/introduction-to-two-way-anova.html#understanding-the-structure-of-a-two-way-anova-design",
    "title": "Introduction to Two-Way ANOVA",
    "section": "Understanding the Structure of a Two-Way ANOVA Design",
    "text": "Understanding the Structure of a Two-Way ANOVA Design\nIn a Two-Way ANOVA, each factor (independent variable) can have multiple levels. For example, in a clinical trial examining the effects of drug dosage (Factor 1) and diet (Factor 2), the design might include: - Factor 1 (Dosage): Low, Medium, High - Factor 2 (Diet): Control, Low-Fat, High-Fat\n\nMain Effects and Interaction\n\nMain Effect: The impact of one factor on the dependent variable, ignoring the levels of the other factor.\nInteraction Effect: The combined effect of both factors on the dependent variable that is different from the sum of their individual effects."
  },
  {
    "objectID": "Lectures/introduction-to-two-way-anova.html#assumptions-of-two-way-anova",
    "href": "Lectures/introduction-to-two-way-anova.html#assumptions-of-two-way-anova",
    "title": "Introduction to Two-Way ANOVA",
    "section": "Assumptions of Two-Way ANOVA",
    "text": "Assumptions of Two-Way ANOVA\n\nNormality of Residuals\nResiduals (errors) should be normally distributed.\n\n\nHomogeneity of Variances\nVariances should be approximately equal across all levels of the factors."
  },
  {
    "objectID": "Lectures/introduction-to-two-way-anova.html#calculation-of-ss-sum-of-squares-and-ms-mean-squares",
    "href": "Lectures/introduction-to-two-way-anova.html#calculation-of-ss-sum-of-squares-and-ms-mean-squares",
    "title": "Introduction to Two-Way ANOVA",
    "section": "Calculation of SS (Sum of Squares) and MS (Mean Squares)",
    "text": "Calculation of SS (Sum of Squares) and MS (Mean Squares)\n\nSum of Squares\n\nTotal Sum of Squares (SST): \\[\nSST = \\sum_{i=1}^{n} (Y_i - \\bar{Y})^2\n\\] where ( Y_i ) is each individual observation, and ( {Y} ) is the overall mean.\nSum of Squares for Factor A (SSA): \\[\nSSA = \\sum_{j=1}^{a} n_{j} (\\bar{Y}_{j\\cdot} - \\bar{Y})^2\n\\] where ( n_{j} ) is the number of observations in each level of Factor A, ( {Y}_{j} ) is the mean for each level of Factor\n\n\n\nSum of Squares for Factor B (SSB): \\[\nSSB = \\sum_{k=1}^{b} n_{k} (\\bar{Y}_{\\cdot k} - \\bar{Y})^2\n\\] where ( n_{k} ) is the number of observations in each level of Factor B, ( {Y}_{k} ) is the mean for each level of Factor B.\nSum of Squares for Interaction (SSAB): \\[\nSSAB = \\sum_{j=1}^{a} \\sum_{k=1}^{b} n_{jk} (\\bar{Y}_{jk} - \\bar{Y}_{j\\cdot} - \\bar{Y}_{\\cdot k} + \\bar{Y})^2\n\\] where ( {Y}_{jk} ) is the mean of each combination of levels in Factors A and B.\nSum of Squares for Error (SSE): \\[\nSSE = \\sum_{j=1}^{a} \\sum_{k=1}^{b} \\sum_{i=1}^{n_{jk}} (Y_{ijk} - \\bar{Y}_{jk})^2\n\\]\n\n\n\nMean Squares\nMean Squares are obtained by dividing each Sum of Squares by the corresponding degrees of freedom.\n\nMean Square for Factor A (MSA): \\[\nMSA = \\frac{SSA}{a - 1}\n\\]\nMean Square for Factor B (MSB): \\[\nMSB = \\frac{SSB}{b - 1}\n\\]\nMean Square for Interaction (MSAB): \\[\nMSAB = \\frac{SSAB}{(a - 1)(b - 1)}\n\\]\nMean Square for Error (MSE): \\[\nMSE = \\frac{SSE}{ab(n - 1)}\n\\]"
  },
  {
    "objectID": "Lectures/introduction-to-two-way-anova.html#hypothesis-testing-for-main-effects-and-interaction",
    "href": "Lectures/introduction-to-two-way-anova.html#hypothesis-testing-for-main-effects-and-interaction",
    "title": "Introduction to Two-Way ANOVA",
    "section": "Hypothesis Testing for Main Effects and Interaction",
    "text": "Hypothesis Testing for Main Effects and Interaction\n\nHypotheses\n\nFactor A (Main Effect):\n\nNull Hypothesis (( H_0 )): All levels of Factor A have the same mean.\nAlternative Hypothesis (( H_1 )): At least one level of Factor A has a different mean.\n\nFactor B (Main Effect):\n\nNull Hypothesis (( H_0 )): All levels of Factor B have the same mean.\nAlternative Hypothesis (( H_1 )): At least one level of Factor B has a different mean.\n\nInteraction Effect:\n\nNull Hypothesis (( H_0 )): No interaction between Factors A and\n\n\n\nAlternative Hypothesis (( H_1 )): Interaction exists between Factors A and B.\n\n\n\n\nF-Ratio Calculations\n\nFactor A: \\[\nF_A = \\frac{MSA}{MSE}\n\\]\nFactor B: \\[\nF_B = \\frac{MSB}{MSE}\n\\]\nInteraction (A x B): \\[\nF_{AB} = \\frac{MSAB}{MSE}\n\\]\n\n\n\nInterpretation\n\nCompare the F-ratios to the critical values from the F-distribution.\nIf the calculated F-ratio is greater than the critical value, reject the null hypothesis."
  },
  {
    "objectID": "Lectures/introduction-to-two-way-anova.html#effect-sizes-and-significance",
    "href": "Lectures/introduction-to-two-way-anova.html#effect-sizes-and-significance",
    "title": "Introduction to Two-Way ANOVA",
    "section": "Effect Sizes and Significance",
    "text": "Effect Sizes and Significance\n\nEta Squared (( ^2 ))\nRepresents the proportion of the total variance explained by each factor.\n\nFactor A: \\[\n\\eta^2_A = \\frac{SSA}{SST}\n\\]\nFactor B: \\[\n\\eta^2_B = \\frac{SSB}{SST}\n\\]\nInteraction (A x B): \\[\n\\eta^2_{AB} = \\frac{SSAB}{SST}\n\\]"
  },
  {
    "objectID": "Lectures/introduction-to-two-way-anova.html#post-hoc-analysis",
    "href": "Lectures/introduction-to-two-way-anova.html#post-hoc-analysis",
    "title": "Introduction to Two-Way ANOVA",
    "section": "Post-Hoc Analysis",
    "text": "Post-Hoc Analysis\nIf significant main or interaction effects are found, post-hoc tests (e.g., Tukey‚Äôs HSD) can identify which specific groups differ.\n\nTukey‚Äôs HSD\n\\[\nHSD = q \\sqrt{\\frac{MSE}{n}}\n\\] where ( q ) is the studentized range statistic, and ( n ) is the sample size per group."
  },
  {
    "objectID": "Lectures/introduction-to-two-way-anova.html#identifying-outliers-and-influential-observations",
    "href": "Lectures/introduction-to-two-way-anova.html#identifying-outliers-and-influential-observations",
    "title": "Introduction to Two-Way ANOVA",
    "section": "Identifying Outliers and Influential Observations",
    "text": "Identifying Outliers and Influential Observations\n\nNormality\n\nUse Q-Q plots to check the normality of residuals.\n\n\n\nHomogeneity of Variances\n\nUse Levene‚Äôs test or Bartlett‚Äôs test.\n\n\n\nOutliers\n\nUse residual plots or Cook‚Äôs distance to identify influential points."
  },
  {
    "objectID": "Lectures/introduction-to-two-way-anova.html#examples-of-two-way-anova-in-nursing-research",
    "href": "Lectures/introduction-to-two-way-anova.html#examples-of-two-way-anova-in-nursing-research",
    "title": "Introduction to Two-Way ANOVA",
    "section": "Examples of Two-Way ANOVA in Nursing Research",
    "text": "Examples of Two-Way ANOVA in Nursing Research\n\nExample 1: Evaluating Drug Dosage and Diet Effects\n\nResearch Question: How do drug dosage and diet affect blood pressure levels in patients?\nFactors:\n\nDosage (Low, Medium, High)\nDiet (Control, Low-Fat, High-Fat)\n\nResponse Variable: Blood Pressure Levels\n\n\n# Example in R\n# Simulated data\nset.seed(123)\ndata &lt;- data.frame(\n  Dosage = factor(rep(c(\"Low\", \"Medium\", \"High\"), each = 30)),\n  Diet = factor(rep(c(\"Control\", \"Low-Fat\", \"High-Fat\"), times = 30)),\n  BP = rnorm(90, mean = rep(c(120, 115, 130), each = 30), sd = 10)\n)\n\n# Two-Way ANOVA\nmodel &lt;- aov(BP ~ Dosage * Diet, data = data)\nsummary(model)\n\n\n\nExample 2: Nursing Intervention and Patient Demographics\n\nResearch Question: How do a nursing intervention and patient demographics affect recovery time?\nFactors:\n\nIntervention (Control, Intensive)\nGender (Male, Female)\n\nResponse Variable: Recovery Time\n\n\n# Example in R\n# Simulated data\nset.seed(456)\ndata2 &lt;- data.frame(\n  Intervention = factor(rep(c(\"Control\", \"Intensive\"), each = 50)),\n  Gender = factor(rep(c(\"Male\", \"Female\"), times = 50)),\n  RecoveryTime = rnorm(100, mean = rep(c(14, 12), each = 50), sd = 3)\n)\n\n# Two-Way ANOVA\nmodel2 &lt;- aov(RecoveryTime ~ Intervention * Gender, data = data2)\nsummary(model2)"
  },
  {
    "objectID": "Lectures/QI_and_EBP.html",
    "href": "Lectures/QI_and_EBP.html",
    "title": "Statistical Q&A for EBP and QI Projects",
    "section": "",
    "text": "Download R Code for this Lecture\nThis page presents frequently asked statistics questions by students related to QI and EBP final projects. Llinks for the t-test or chi-square. Please email joshua.lambert@uc.edu with more questions."
  },
  {
    "objectID": "Lectures/QI_and_EBP.html#questions",
    "href": "Lectures/QI_and_EBP.html#questions",
    "title": "Statistical Q&A for EBP and QI Projects",
    "section": "Questions",
    "text": "Questions\nQ1: What‚Äôs the best statistical test to compare CRNA autonomy levels (supervised vs collaborative) between different types of counties (urban vs rural)? I was thinking chi square, but I want to make sure that makes sense.\nA1: Yes, Chi-square is appropriate. You‚Äôre comparing two categorical variables (autonomy level: supervised vs.¬†collaborative, and county type: urban vs.¬†rural), so Chi-square is the best fit.\nUse this tool: Chi-square Calculator\n\nQ2: Since I‚Äôm not doing a clinical intervention, just collecting current state data from hospitals, is it okay to stick with descriptive stats (like percentages and means), or do I need to run inferential tests too?\nA2: No, you don‚Äôt need inferential stats. Descriptive statistics (percentages, averages) are totally fine for quality improvement (QI) projects focused on current state. Only use inferential stats if you‚Äôre comparing groups or time points and trying to generalize beyond your sample.\n\nQ3: If I‚Äôm collecting both CRNA-level responses (autonomy and perception) and hospital level info (billing model and policy), should all that data be on one Excel sheet or split into two?\nA3: Use one Excel file but two separate tabs (worksheets):\n\nOne tab for CRNA responses (autonomy, perception, etc.)\nOne tab for hospital-level data (billing model, policy, etc.)\n\nIf you‚Äôre linking them, include a shared column like ‚ÄúHospital ID.‚Äù\n\nQ4: Do I need to assign unique identifiers if I‚Äôm not doing a pre/post design just one time surveys?\nA4: You do not need unique identifiers for one-time anonymous surveys. But include one if you think you might later want to link responses (like if doing subgroup analysis by site or unit).\n\nQ5: I want to include Likert scale questions about autonomy, efficiency, and OR delays. Is there a recommended number of questions to include so I can run an analysis later?\nA5: Aim for 3‚Äì5 questions per topic (e.g., 3 for autonomy, 3 for efficiency, etc.). This helps you measure a concept more reliably while keeping the survey short.\n\nQ6: Any tips on picking unique identifiers that allows participants to be anonymous, but still allows me to track pre and post answers?\nA6: Create a self-generated code from a mix of personal but not-identifying elements. For example:\n\nFirst 2 letters of mother‚Äôs first name + last 2 digits of birth year + last letter of city born in (e.g., ‚ÄúMa89o‚Äù)\n\nAlways test it to make sure it creates unique results across your sample.\n\nQ7: Do you have a recommendation on statistical tests for qualitative data?\nA7: Qualitative data isn‚Äôt analyzed with statistical tests. Instead, use thematic analysis or coding. You can present counts of how often certain themes appear, or quotes to highlight key points.\n\nQ8: How do we obtain statistical software? Does the type of project matter pertaining to software?\nA8: Yes. If you‚Äôre doing QI (not formal research), Excel and online calculators are usually enough. If you‚Äôre doing complex stats, you may need SPSS or JMP. Use tools you‚Äôre comfortable with.\n\nQ9: Chi-square‚ÄîSo would this test be used for how a patient questionnaire affects rate of x (screenings, diagnosis, referral rates)?\nA9: Yes, if both variables are categorical. For example:\n\nPatient said yes/no on questionnaire (yes/no)\nScreening completed (yes/no)\n\nThen a Chi-square test works great.\n\nQ10: Best YouTube/instructional videos for learning statistics in Excel?\nA10: Try:\n\nLeila Gharani (excellent Excel tutorials)\nStatQuest with Josh Starmer (stats made simple)\nUniversity of Cincinnati‚Äôs own tools:\n\nT-test Tool\nChi-square Tool\n\n\n\nQ11: Keeping track of unique identifiers if we use something like an EMR, MyChart, etc. to administer whatever tool is being used for the project?\nA11: Don‚Äôt use names or MRNs. Instead:\n\nGenerate a study-specific code tied to a non-identifying feature (e.g., date/time stamp + 2-digit code)\nMake sure data is exported de-identified\n\n\nQ12: How would you run multiple tests with one table?\nA12: Create a table with one row per variable or question, and columns for:\n\nGroup 1 result\nGroup 2 result\np-value\n\nLabel clearly and use footnotes to explain test types.\n\nQ13: When working with different types of data like yes/no results and average scores how do we choose the right statistical test for a small-scale quality improvement cycle?\nA13: - For yes/no or categories ‚Üí Chi-square or McNemar‚Äôs (if paired) - For average scores ‚Üí T-test (independent or paired)\nUse descriptive stats first. Inferential only if you compare groups or time points.\n\nQ14: If we only have a small amount of data during early testing, how can we still draw useful conclusions especially without doing a formal power analysis?\nA14: Focus on:\n\nTrends or patterns\nPercent change\n\nUse confidence intervals if possible. Even without formal power, describe improvements qualitatively and use graphs for impact.\n\nQ15: What are the best ways to deal with missing answers in surveys or gaps in chart audit data especially when it could affect results like process or balancing measures?\nA15: - For surveys: Note missing % and don‚Äôt replace unless critical - For chart audits: Add a column like ‚ÄúData Present (Y/N)‚Äù. You can report how often data was missing to show transparency.\n\nQ16: When we look at quiz scores before and after a training module, how can we make sure any improvements show actual learning and not just remembering the questions from before?\nA16: Use a Paired t-test if comparing pre/post scores. To reduce memory bias:\n\nChange question order\nUse different but equivalent questions if possible\n\n\nQ17: When using a Likert scale, does it impact the validity of your pre- and post-test (utilizing a paired t-test for analysis) if the Likert scale used was created by you, as compared to using a Likert scale that has already proven validity?\nA17: Yes, it can affect validity, but not your ability to run a paired t-test. You can still analyze it. Just be transparent that it‚Äôs a new tool, and consider pilot testing it for clarity.\n\nQ18: I ask this question because I am examining the confidence of OR RNs in managing difficult airway situations through a pre- and post-test to determine how education affects their confidence. Given that my project is very specific, I believe it is necessary to create my own version of a Likert scale to tailor it to what I am attempting to evaluate.\nA18: Use one Excel file with separate tabs:\n\nTab 1: Survey responses\nTab 2: Simulation scores\n\nKeep consistent ID columns across tabs to match participants.\n\nQ19: For my project I am looking to do multiple analyses of my population, like a Likert-scale survey, and a scoring system for performance in completion of a simulation. Since I am having multiple variables that I am analyzing would I need to store the results in separate excel files and run the analysis separately?\nA19: Yes, either:\n\nWrite the word (e.g., ‚ÄúStrongly Agree‚Äù)\nOr assign a number (e.g., 1‚Äì5)\n\nJust be consistent. Add a key on your sheet to explain what each number means.\n\nQ20: If a Likert scale is used, do you just write out which category into the response column for that question?\nA20: Yes, that works or you can convert to a number system, although it may be difficult later to understand what number means. I would recommend using the label or a shortened version of the label as the category in the data row and column.\n\nQ21: What is the best way to get consent to add study at clinical site?\nA21: Check if IRB approval is needed. Then:\n\nUse a brief consent script or form\nInclude who you are, what the study is, that participation is voluntary and confidential\n\n\nQ22: If unable to have intervention at clinical site is there a specific project change you recommend?\nA22: If intervention isn‚Äôt allowed:\n\nFocus on current state assessment\nAdd interviews or surveys\nDo a policy comparison, or education evaluation\n\n\nQ23: What is the most effective way to organize the data from our study as it is being collected without the amount of data becoming overwhelming?\nA23: - Use Excel with clear headers (no spaces in names). First row is name of variable. - Keep each row = one participant or one encounter - Add tabs for demographics, survey, audit data, etc.\nLabel everything and back up your file often.\n\nQ24: To protect patient/practitioner privacy, what is the recommended or best way to code the data that will adhere to IRB standards?\nA24: - Remove all direct identifiers (name, DOB, MRN) - Use non-identifying study codes - Save ID key separately and securely (if needed)\n\nQ25: After initial data collection and evaluation, how long should we give to collect further data in order to make sure that we have covered enough ground in our collection process? How do you know that you have an adequate amount to move forward in your project‚Äôs progression vs knowing when to pause and continue to collect more data?\nA25: Enough to:\n\nReach your target number\nCapture full QI cycle\n\nYou‚Äôre ready to stop if:\n\nYou‚Äôre not seeing new themes\nData is consistent\nYou met your aim or timeline\n\n\nQ26: When creating the collection instrument and methodology of collection, what platforms did students in the past find to have provided most useful for analysis outside of Excel?\nA26: - REDCap (best for surveys + audit) - SurveyMonkey or Google Forms (simpler) - JMP or SPSS (for complex stats, if needed)\n\nQ27: Can Unique Identifiers be email addresses if you are using google forms to collect data?\nA27: No ‚Äî emails are not anonymous. Use self-generated codes instead.\n\nQ28: Can you use a mix of question style like interviewing format and several word based question if its consistent for both pre and post survey questions?\nA28: Yes, as long as:\n\nThe same format is used in pre and post\nIt‚Äôs clearly matched and organized\n\n\nQ29: How many questions on the pre and post survey is ideal?\nA29: Aim for 5‚Äì10 focused questions. More than that can lower response quality. Group by theme (e.g., 3 for confidence, 3 for knowledge).\n\nQ30: I plan on using descriptive statistics to show demographic data. My intervention is going to be screening patients for depression and anxiety again at 12-14 weeks postpartum to determine if they feel more comfortable disclosing symptoms at that point. I plan on doing an interview with these patients as well. To show the results, would percentages be okay to show the answers for the screening tool? Or would there be another statistical test that would be more appropriate?\nA30: Yes, absolutely. Use percentages and bar graphs to show change over time. If you want to compare pre/post, and you used the same patients, you could consider McNemar‚Äôs test.\n\nQ31: My EBP project focuses on using mindfulness to reduce stress in parents of children with ADHD. Even though it‚Äôs not research, can I still use surveys and interviews for my community needs assessment? Are there any special considerations I should keep in mind for analyzing or reporting that data?\nA31: Yes. For QI, both are great. Just keep:\n\nSurveys focused\nInterviews transcribed and thematically coded\n\nYou don‚Äôt need formal stats, but you can use counts or charts to support findings.\n\nQ32: Best contact for questions? Will we get access to the tools she put in the recorded chat, for our usage?\nA32: Please either reach out to me directly: Joshua.lambert@uc.edu or submit a request here: https://redcap.research.cchmc.org/surveys/?s=FR3YH89KT8\n\nQ33: The only question I have is that she shared links to the T-test calculator and tookkit for excel, where can we find these links? Are they on the DNP community page?\nA33: Yes, they are on the DNP community page and they can be found here:\n\nT-test Tool\nChi-square Tool\n\n\nQ34: My DNP project involves developing a clinical practice guideline using the AGREE II tool. The second domain of the AGREE II tool, Stakeholder Involvement, emphasizes the importance of representing the views of the intended users, which for this project is advanced practice nurses (APNs). I plan to create and collect survey responses from APNs regarding the barriers they encounter to conducting comprehensive, whole-person assessments and evaluations in the ambulatory setting. This information will help guide the development of the CPG. Do you have any advice on using a survey to support CPG development?\nA34: - Identify barriers APNs face in conducting whole-person assessments - Understand workflow, time, resource, or training issues - Gather input for tailoring your CPG to be practical and relevant - Demonstrate that your CPG reflects end-user needs (supports AGREE II)\n\nQ35: The effectiveness of the CPG will be assessed using the Whole Person Health Index, an integrated, self-report measure that captures key health components. Is a patient outcome measure suitable for evaluating a CPG, or should I use an instrument to determine whether APNs find the CPG useful in practice?\nA35: - Patient outcomes show clinical impact - APN feedback shows usability\nUse what aligns best with your project goals.\n\nQ36: Do you have any other general recommendations on stats and evaluation for DNP projects that involve developing CPGs?\nA36: - Use a validated tool (like AGREE II) - Get stakeholder input - Keep results organized tool specific category\n\nQ37: What are the best practices for determining the appropriate number of questions for pre- and post-tests in statistical evaluation, and how might this influence the reliability of the results?\nA37: 5‚Äì10 solid, well-designed questions are better than 20 unclear ones. Focus on clarity and alignment with your outcome.\n\nQ38: How can I leverage tools like Excel‚Äôs Analysis Toolpak and other statistical platforms like the t-test calculator to perform accurate T-tests, and what are the pros and cons of each method in practical settings?\nA38: - Excel‚Äôs Analysis Toolpak is more manual but lets you keep data in one place - The T-test Tool is faster and gives a summary statement\nUse the calculator if you‚Äôre unsure how to run stats in Excel.\n\nQ39: In what ways can I improve my statistical literacy to ensure proper evaluation of program outcomes and instructional effectiveness even as I get ready to work on my project and work on becoming a future nurse educator?\nA39: You can always enroll in our PhD statistics classes as electives as time permits. There are lots of great YouTube videos and free resources online. StatQuest (YouTube) or Leila Gharani (excellent Excel tutorials)\n\nQ40: How does one obtain unique identifiers?\nA40: - Ask participants to create one using personal, non-identifying info - Or assign sequential IDs (001, 002, 003‚Ä¶)\n\nQ41: How do you really determine the right software or tool to utilize for data collection and analysis?\nA41: This can be difficult for beginners. Ultimately, picking one that matches your current ability is important. For beginners I recommend: Microsoft Forms, or Survey Monkey. For more advanced users Qualtrics and REDCap are great options. Choose based on what your time allows for.\nAnalysis is similar. Beginners should stick to excel, online DNP calculators and descriptive statistics. Advanced users can choose JMP (free), SPSS (paid), R or Python.\nIf you don‚Äôt have much time to commit to learning advanced software then I‚Äôd choose MF or SM and Excel, online calculators and descriptive statistics.\n\nQ42: Do you have any advice about choosing a scale for pre and post test? I have selected a scale that seems to measure my endpoint and is validated, but wanted to see if there is anything additional I should be considering?\nA42: If you‚Äôve already picked a validated scale aligned with your endpoint, you‚Äôre in great shape. Just make sure it has:\n\nClear scoring\nGood reliability (check prior studies)\n\n\nQ43: Bailey had mentioned that she would not necessarily expect a statistically significant result with a small sample size. Would you still recommend calculating a p value with a quality improvement project on a single nursing unit?\nA43: You can, but be cautious about over-interpreting. Focus more on direction of change and clinical relevance.\n\nQ44: Would you recommend any specific types of graphs or ways to present statistical data for the dissemination of results?\nA44: - Bar charts for categorical comparisons - Box plots for score changes - Line graphs for trends over time - Pie charts for demographics (use sparingly)"
  },
  {
    "objectID": "Other/syl.html",
    "href": "Other/syl.html",
    "title": "NPHD9040 - Syllabus",
    "section": "",
    "text": "Download Full Syllabus (PDF)\n\n\nClass Meeting Time: Tuesdays 9:30 AM - 12:20 PM\n\n\n\n#\nDate\nTopic\nReading\nAssignment Assigned\nAssignment Due (Canvas)\nNote\n\n\n\n\n1\nJan 13\nWelcome and Introduction to R\n\nHW1\n\nClass Starts\n\n\n2\nJan 20\nANOVA\n\n\n\n\n\n\n3\nJan 27\nANOVA\n\nHW2\nHW1\n\n\n\n4\nFeb 3\nANCOVA\n\n\n\n\n\n\n5\nFeb 10\n2-Way ANOVA\n\nHW3\nHW2\n\n\n\n6\nFeb 17\n2-Way ANOVA\n\n\n\n\n\n\n7\nFeb 24\nRepeated Measures ANOVA\n\nHW4\nHW3\n\n\n\n8\nMar 3\nWork Day\n\n\n\n\n\n\n9\nMar 10\nProject 1 Presentation\n\n\n\n\n\n\n‚Äì\nMar 17\nNO CLASS\n\n\nHW4\nSpring Break\n\n\n10\nMar 24\nLinear Regression\n\nHW5\n\n\n\n\n11\nMar 31\nMultiple Linear Regression\n\n\n\n\n\n\n12\nApr 7\nLogistic Regression\n\n\n\n\n\n\n13\nApr 14\nWork Day\n\n\nHW5\n\n\n\n14\nApr 21\nFinal Project\n\n\n\nLast Class\n\n\n15\nApr 28\nFinals Week\n\n\n\n\n\n\n\n\n\n\n\nFaculty Name:\n\nJoshua W Lambert, PhD, MS, MS\n\nEmail:\n\nJoshua.lambert@uc.edu\n\nStudent First Office Hours:\n\nBy appointment (please email) in person or online via Teams"
  },
  {
    "objectID": "Other/syl.html#class-schedule",
    "href": "Other/syl.html#class-schedule",
    "title": "NPHD9040 - Syllabus",
    "section": "",
    "text": "Class Meeting Time: Tuesdays 9:30 AM - 12:20 PM\n\n\n\n#\nDate\nTopic\nReading\nAssignment Assigned\nAssignment Due (Canvas)\nNote\n\n\n\n\n1\nJan 13\nWelcome and Introduction to R\n\nHW1\n\nClass Starts\n\n\n2\nJan 20\nANOVA\n\n\n\n\n\n\n3\nJan 27\nANOVA\n\nHW2\nHW1\n\n\n\n4\nFeb 3\nANCOVA\n\n\n\n\n\n\n5\nFeb 10\n2-Way ANOVA\n\nHW3\nHW2\n\n\n\n6\nFeb 17\n2-Way ANOVA\n\n\n\n\n\n\n7\nFeb 24\nRepeated Measures ANOVA\n\nHW4\nHW3\n\n\n\n8\nMar 3\nWork Day\n\n\n\n\n\n\n9\nMar 10\nProject 1 Presentation\n\n\n\n\n\n\n‚Äì\nMar 17\nNO CLASS\n\n\nHW4\nSpring Break\n\n\n10\nMar 24\nLinear Regression\n\nHW5\n\n\n\n\n11\nMar 31\nMultiple Linear Regression\n\n\n\n\n\n\n12\nApr 7\nLogistic Regression\n\n\n\n\n\n\n13\nApr 14\nWork Day\n\n\nHW5\n\n\n\n14\nApr 21\nFinal Project\n\n\n\nLast Class\n\n\n15\nApr 28\nFinals Week\n\n\n\n\n\n\n\n\n\n\n\nFaculty Name:\n\nJoshua W Lambert, PhD, MS, MS\n\nEmail:\n\nJoshua.lambert@uc.edu\n\nStudent First Office Hours:\n\nBy appointment (please email) in person or online via Teams"
  }
]